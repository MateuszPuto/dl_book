<!DOCTYPE html> 
<html lang="en" xml:lang="en" > 
<head><title></title> 
<meta  charset="iso-8859-1" /> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" /> 
<link rel="stylesheet" type="text/css" href="main.css" /> 
<meta name="src" content="main.tex" /> 
</head><body 
>
                                                                                    
                                                                                    
<!--l. 23--><p class="indent" >
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p><!--l. 10--><p class="indent" >
                                                                                    
                                                                                    
</p><!--l. 10--><p class="indent" >   -422.52342
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p><!--l. 25--><p class="indent" >
                                                                                    
                                                                                    
</p>
   <h2 class="likechapterHead"><a 
 id="x1-1000"></a>Spis tre&#347;ci</h2>
   <div class="tableofcontents">
   <span class="chapterToc" ><a 
href="#x1-20001" id="QQ2-1-2">Wst&#281;p</a></span>
<br />   &#x00A0;<span class="sectionToc" >1.1 <a 
href="#x1-30001" id="QQ2-1-3">Cele...</a></span>
<br />   &#x00A0;<span class="sectionToc" >1.2 <a 
href="#x1-40002" id="QQ2-1-4">... i jak je osi&#261;gn&#261;&#263;</a></span>
<br />   &#x00A0;<span class="sectionToc" >1.3 <a 
href="#x1-50003" id="QQ2-1-5">W&#322;a&#347;ciwy wst&#281;p</a></span>
<br />   &#x00A0;<span class="sectionToc" >1.4 <a 
href="#x1-60004" id="QQ2-1-6">Jakie tematy poruszymy w tym kursie</a></span>
<br />   <span class="chapterToc" ><a 
href="#x1-70002" id="QQ2-1-7">Optymalizacja matematyczna</a></span>
<br />   &#x00A0;<span class="sectionToc" >2.1 <a 
href="#x1-80001" id="QQ2-1-8">Metoda prób i b&#322;&#281;dów</a></span>
<br />   &#x00A0;<span class="sectionToc" >2.2 <a 
href="#x1-90002" id="QQ2-1-9">Wspinaczka górska</a></span>
<br />   &#x00A0;<span class="sectionToc" >2.3 <a 
href="#x1-100003" id="QQ2-1-10">Metoda gradientu prostego</a></span>
<br />   &#x00A0;<span class="sectionToc" >2.4 <a 
href="#x1-110004" id="QQ2-1-11">Plus wielko&#347;&#263; kroku</a></span>
<br />   &#x00A0;<span class="sectionToc" >2.5 <a 
href="#x1-120005" id="QQ2-1-12">Plus momentum</a></span>
<br />   &#x00A0;<span class="sectionToc" >2.6 <a 
href="#x1-130006" id="QQ2-1-13">SGD</a></span>
<br />   <span class="chapterToc" ><a 
href="#x1-140003" id="QQ2-1-14">Sieci neuronowe</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.1 <a 
href="#x1-150001" id="QQ2-1-15">Perceptron</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.2 <a 
href="#x1-160002" id="QQ2-1-16">Neurony</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.3 <a 
href="#x1-170003" id="QQ2-1-17">Funkcje aktywacji</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.4 <a 
href="#x1-180004" id="QQ2-1-18">Wszystko razem</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.5 <a 
href="#x1-190005" id="QQ2-1-19">Propagacja wsteczna</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.6 <a 
href="#x1-200006" id="QQ2-1-20">Zaawansowane tematy w zagadnienu</a></span>
<br />   <span class="chapterToc" ><a 
href="#x1-210004" id="QQ2-1-21">Symboliczne AI</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.1 <a 
href="#x1-220001" id="QQ2-1-22">Rozwi&#261;zywanie poprzez wyszukiwanie</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.2 <a 
href="#x1-230002" id="QQ2-1-23">Drzewa poszukiwa&#324;</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.3 <a 
href="#x1-240003" id="QQ2-1-24">Poszukiwanie na g&#322;&#281;boko&#347;&#263; i rozpi&#281;to&#347;&#263;</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.4 <a 
href="#x1-250004" id="QQ2-1-25">Minimax</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.5 <a 
href="#x1-260005" id="QQ2-1-26">A*</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.6 <a 
href="#x1-270006" id="QQ2-1-27">MCTS</a></span>
<br />   <span class="chapterToc" ><a 
href="#x1-280005" id="QQ2-1-28">Uczenie ze wzmocnieniem</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.1 <a 
href="#x1-290001" id="QQ2-1-29">Problem uczenia ze wzmocnieniem</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.2 <a 
href="#x1-300002" id="QQ2-1-30">Wielor&#281;czny bandyta</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.3 <a 
href="#x1-310003" id="QQ2-1-31">MDP</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.4 <a 
href="#x1-320004" id="QQ2-1-32">Uczenie Monte-Carlo</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.5 <a 
href="#x1-330005" id="QQ2-1-33">Uczenie TD</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.6 <a 
href="#x1-340006" id="QQ2-1-34">Uczenie TD(lambda)</a></span>
<br />   <span class="chapterToc" ><a 
href="#x1-350006" id="QQ2-1-35">Gry i wi&#281;cej</a></span>
<br />   &#x00A0;<span class="sectionToc" >6.1 <a 
href="#x1-360001" id="QQ2-1-36">AlphaGo (rok 2016)</a></span>
<br />   &#x00A0;<span class="sectionToc" >6.2 <a 
href="#x1-370002" id="QQ2-1-37">AlphaZero (rok 2017)</a></span>
<br />   &#x00A0;<span class="sectionToc" >6.3 <a 
href="#x1-380003" id="QQ2-1-38">MuZero (rok 2019)</a></span>
<br />   &#x00A0;<span class="sectionToc" >6.4 <a 
href="#x1-390004" id="QQ2-1-39">AGI</a></span>
   </div>
                                                                                    
                                                                                    
                                                                                    
                                                                                    
<!--l. 4--><p class="indent" >
                                                                                    
                                                                                    
</p><!--l. 6--><p class="indent" >   &#x00A0;
</p><!--l. 8--><p class="indent" >
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p><!--l. 10--><p class="indent" >
                                                                                    
                                                                                    
</p>
   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;1</span><br /><a 
 id="x1-20001"></a>Wst&#281;p</h2>
<a 
 id="x1-2001r1"></a>
<h3 class="sectionHead"><span class="titlemark">1.1   </span> <a 
 id="x1-30001"></a>Cele...</h3>
<!--l. 17--><p class="noindent" >Cel jest intuicyjnie zdefiniowany jako pragnienie, &#380;yczenie lub co&#347; w kierunku czego
d&#261;&#380;ymy. W codziennym &#380;yciu cz&#281;sto mówimy o naszych celach. S&#261; one tym, wokó&#322;
czego skupiaj&#261; si&#281; nasze my&#347;li i rozmowy. Dzieje si&#281; tak, poniewa&#380; cele ze wzgl&#281;du na to,
&#380;e nie mo&#380;emy ich zrealizowa&#263; od razu, s&#261; zwi&#261;zane z pewnym komponentem czasowym.
To znaczy, &#380;e nasze cele nie zmieniaj&#261; si&#281; wraz z up&#322;ywem czasu. Dok&#322;adniej mówi&#261;c, cele
nadrz&#281;dne nie ulegaj&#261; zmianie, podczas gdy cele podrz&#281;dne, s&#322;u&#380;&#261;ce realizacji
tych wa&#380;niejszych dla nas celów, s&#261; dostosowywane do zmieniaj&#261;cej si&#281; sytuacji.
Mówimy np. &#380;e naszym celem jest zrobienie lub osi&#261;gni&#281;cie czego&#347;, co s&#261;dzimy, &#380;e
przyniesie nam pewn&#261; korzy&#347;&#263;, lecz cz&#281;sto nie sama korzy&#347;&#263; jest tym, czego
pragniemy, a raczej d&#261;&#380;enie do zrealizowania celu nadrz&#281;dnego, który ma dla
nas ponadprzeci&#281;tn&#261; warto&#347;&#263;. Ze wzgl&#281;du na d&#322;ugotrwa&#322;o&#347;&#263; i stosunkow&#261;
rzadko&#347;&#263; wyst&#281;powania, pewne cele s&#261; nam bliskie, jeste&#347;my z nimi z&#380;yci i
uto&#380;samiamy si&#281; z nimi. Mimo tego istnieje te&#380; rodzaj celów, których u&#380;ywamy
instrumentalnie. Te cele s&#322;u&#380;&#261; nam zazwyczaj tylko przez krótki czas, wyst&#281;puj&#261;
cz&#281;&#347;ciej i s&#261; jedynie wykonawcami celów nadrz&#281;dnych. Tak samo, jak my mamy
rozbudowane relacje i metody radzenia sobie z celami, w podobny sposób powinno si&#281;
to odbywa&#263; w dziedzinie sztucznej inteligencji. Jednak, ze wzgl&#281;du na ogromne
skomplikowanie naszych metod wyszukiwania i rozwi&#261;zywania problemów, próba
imitacji ludzkiego zachowania wydaje si&#281; ponad nasze si&#322;y. Pomy&#347;lmy o tym, &#380;e
przecie&#380; nawet dok&#322;adnie nie wiemy jakie procesy bior&#261; udzia&#322; w naszym w&#322;asnym
rozumowaniu. Czy w chwili kiedy mamy moment &#8216;Aha&#8217; wiemy jakie procesy nas do niego
doprowadzi&#322;y? Tak&#380;e nauka pozostawia nas z ograniczonymi metodami badania
mózgu z powodu jego odizolowania w czaszce. Pomimo wprowadzenia nowych
metod obrazowania, opracowywanych coraz to nowych leków dzia&#322;aj&#261;cych na
mózg, czy operacji na nim, wci&#261;&#380; niewiele wiadomo o sposobach jego dzia&#322;ania.
Nie jeste&#347;my tak&#380;e jeszcze pewni, w jaki sposób prze&#322;o&#380;y&#263; to, co wiemy na
algorytmy, a to jest co&#347;, co b&#281;dzie nas najbardziej interesowa&#263; w kontek&#347;cie
dziedziny sztucznej inteligencji. W konsekwencji nie pozostaje nam nic innego
jak pój&#347;&#263; drog&#261; matematyki i spróbowa&#263; nieco sformalizowa&#263; znaczenia
s&#322;owa &#8222;cel&#8221;. Tak samo, jak my mamy, cz&#281;sto burzliwe, relacje z naszymi celami, tak
samo powinni&#347;my poda&#263; osob&#281;, rzecz czy byt, który b&#281;dzie odpowiedzialny za
realizowanie zadanego mu przez nas celu. Ten byt b&#281;dzie w specjalnej relacji ze swoim
celem, to znaczy po&#322;&#261;czymy go z nim raz na zawsze, tak aby w ka&#380;dej chwili by&#322;
skupiony na swoim celu. Takie po&#322;&#261;czenie przypomina ma&#322;&#380;e&#324;stwo, i tak jak
ma&#322;&#380;e&#324;stwo tak&#261; relacj&#281; mo&#380;na zerwa&#263;, lecz nie obejdzie si&#281; to bez pewnych
                                                                                    
                                                                                    
perturbacji. Mo&#380;e si&#281; okaza&#263; &#380;e je&#347;li zamienimy cel, to nasz byt nie b&#281;dzie go
realizowa&#322; tak samo dobrze. Mo&#380;e si&#281; te&#380; okaza&#263;, &#380;e b&#281;dzie go realizowa&#263;
w sposób lepszy ni&#380; losowy, co b&#281;dziemy mogli wykorzysta&#263;. Nie wnikaj&#261;c
teraz jednak w szczegó&#322;y, skupimy si&#281; na definicji. Wykonawc&#281;, inaczej mówi&#261;c,
istot&#281;, która posiada pewien cel, nazwiemy zgodnie z literatur&#261; RL, <span 
class="aeb10-x-x-120">aktorem </span>(ang.
agent). Dalej, aby pokaza&#263; rzeczywiste dzia&#322;anie prezentowanych systemów,
b&#281;dziemy wprowadza&#263; co jaki&#347; czas definicje. Powiedzieli&#347;my, &#380;e do realizowania
celu jest nam potrzebny aktor, jak go nazwali&#347;my. Na razie pos&#322;ugiwali&#347;my
si&#281; mglist&#261; definicj&#261; samego celu. Teraz podamy bardziej formaln&#261; definicj&#281;: Cel
okre&#347;limy jako warto&#347;&#263; numeryczn&#261;, która jest dost&#281;pna dla aktora w pewnych
momentach czasu. Aktor chce równie&#380;, aby ta warto&#347;&#263; by&#322;a jak najwi&#281;ksza. Jest to
jednoznaczne z matematyczn&#261; definicj&#261; maksymalizacji, wi&#281;c mo&#380;emy zapisa&#263;,
&#380;e:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-3001r1"></a>
<!--l. 19--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                    <mi 
>v</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>a</mi><mi 
>x</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>z</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(1.1)</td></tr></table>
<!--l. 23--><p class="noindent" >Gdzie <!--l. 23--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> jest
celem, a <!--l. 23--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>z</mi></mstyle></mstyle></math>
jest zmienn&#261; warto&#347;ci&#261;, która zale&#380;y od pewnych znanych lub nieznanych czynników.
<!--l. 23--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>V</mi> </mstyle></mstyle></math>
nazwiemy funkcj&#261; warto&#347;ci.<br 
class="newline" />
</p><!--l. 25--><p class="noindent" ><span 
class="aeb10-x-x-120">Funkcja warto</span><span 
class="aeb10-x-x-120">&#347;</span><span 
class="aeb10-x-x-120">ci </span>(ang. value function) jest pewn&#261; funkcj&#261;, która okre&#347;la, w jakim
stopniu aktor zrealizowa&#322; swój cel. Mówi nam ona, ile nagrody otrzyma on w wyniku
swoich dzia&#322;a&#324; i jak dobrze radzi on sobie w danej sytuacji, przypisuj&#261;c jak&#261;&#347; liczb&#281;,
okre&#347;laj&#261;c&#261; jak bardzo dana sytuacja jest po&#380;&#261;dan&#261;, do ka&#380;dej mo&#380;liwej sytuacji.
Oczywi&#347;cie funkcja warto&#347;ci mo&#380;e si&#281; zmienia&#263; wraz z up&#322;ywem czasu i ta zmiana
b&#281;dzie nam mówi&#263; o poprawie lub pogorszeniu sytuacji aktora. O celu mo&#380;emy
równocze&#347;nie my&#347;le&#263; intuicyjnie tak, jak w codziennym &#380;yciu. Tu celem mo&#380;e by&#263;
bogactwo, mi&#322;o&#347;&#263; czy te&#380; wiedza, a odpowiadaj&#261;c&#261; tym celom funkcj&#261; warto&#347;ci mo&#380;e
by&#263; kolejno ilo&#347;&#263; pieni&#281;dzy na koncie, si&#322;a uczucia drugiej osoby i ilo&#347;&#263; przeczytanych
ksi&#261;&#380;ek. Dost&#281;p do funkcji warto&#347;ci mo&#380;emy sobie wyobrazi&#263; jako odczuwanie, tak
                                                                                    
                                                                                    
jak sami mo&#380;emy odczuwa&#263; czy jest nam dobrze, czy &#378;le, zimno czy ciep&#322;o
itd.<br 
class="newline" />
</p><!--l. 27--><p class="noindent" >Podajmy jeszcze jeden przyk&#322;ad:<br 
class="newline" />
</p><!--l. 29--><p class="noindent" >Powiedzieliby&#347;my, &#380;e celem istoty w uj&#281;ciu darwinistycznym jest przetrwanie i
reprodukcja. Tak wi&#281;c spróbujmy to zapisa&#263; formalnie za pomoc&#261; naszej definicji.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-3002r2"></a>
<!--l. 31--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <mi 
>v</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>a</mi><mi 
>x</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>p</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>k</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>r</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(1.2)</td></tr></table>
<!--l. 35--><p class="noindent" >Gdzie <!--l. 35--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>p</mi></mstyle></mstyle></math>
jest zmienn&#261; zwi&#261;zan&#261; z przetrwaniem (wyra&#380;on&#261; np. w latach &#380;ycia),
<!--l. 35--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>r</mi></mstyle></mstyle></math> jest
zmienn&#261; zwi&#261;zan&#261; z reprodukcj&#261; (np. liczba potomstwa) i poniewa&#380; mo&#380;emy
ceni&#263; potomstwo bardziej lub mniej ni&#380; rok &#380;ycia dodajemy kurs wymiany
<!--l. 35--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>k</mi></mstyle></mstyle></math>
mi&#281;dzy tymi dwoma zmiennymi. Równanie (1.2) pokazuje jeden z mo&#380;liwych celów,
którymi mog&#261; kierowa&#263; si&#281; aktorzy. W ci&#261;gu czytania tego tekstu poznamy ró&#380;ne inne
cele, które mog&#261; zosta&#263; u&#380;yte w innych okoliczno&#347;ciach.
<a 
 id="x1-3003r3"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">1.2   </span> <a 
 id="x1-40002"></a>... i jak je osi&#261;gn&#261;&#263;</h3>
<!--l. 39--><p class="noindent" >Powiedzieli&#347;my, &#380;e realizatorem celów s&#261; aktorzy. Jednak ta definicja pomija
najwa&#380;niejsze pytanie, a mianowicie: Jak aktorzy realizuj&#261; swoje cele? Pod tym problemem
kryje si&#281; najwi&#281;cej trudno&#347;ci i to jest w&#322;a&#347;nie g&#322;ówny cel sztucznej inteligencji
(albo krócej: AI od ang. artificial intelligence), jakim jest tworzenie aktorów,
którzy osi&#261;gaj&#261; jaki&#347; cel, a wi&#281;c maksymalizuj&#261; jak&#261;&#347; zadan&#261; warto&#347;&#263;. Cz&#281;sto
ci, którzy tworz&#261; takie rozwi&#261;zania nie my&#347;l&#261; nawet o aktorach, bo rozumiej&#261;
bez zastanawiania si&#281;, &#380;e potrzebuj&#261; pewnego modelu rzeczywisto&#347;ci, który
b&#281;dzie wyja&#347;nia&#322; dzia&#322;anie systemu, którym si&#281; zajmuj&#261;. Takim modelem b&#281;d&#261;
w&#322;a&#347;nie procesy my&#347;lowe aktora. Tak wi&#281;c g&#322;ówny nacisk jest po&#322;o&#380;ony na
                                                                                    
                                                                                    
osi&#261;ganie jasno zdefiniowanych celów, czyli takich, które da si&#281; mierzy&#263;, za
pomoc&#261; komputerów. To bardzo ogólne podej&#347;cie, za pomoc&#261; którego mo&#380;emy
próbowa&#263; rozwi&#261;za&#263; wszelakie ci&#281;&#380;kie problemy. Jedynymi ograniczeniami s&#261; nasza
zdolno&#347;&#263; zdefiniowania problemu i umiej&#281;tno&#347;&#263; przekazania rozwi&#261;zania w j&#281;zyku
zrozumia&#322;ym dla komputerów. Oczywi&#347;cie mo&#380;emy te&#380; nie zna&#263; rozwi&#261;zania
problemu, który zdefiniowali&#347;my i wtedy dodatkow&#261; trudno&#347;ci&#261; jest to, &#380;e nasz
system musi by&#263; w stanie znale&#378;&#263; zadowalaj&#261;ce nas rozwi&#261;zanie. Znajdywanie
tych rozwi&#261;za&#324;, b&#281;dzie najwa&#380;niejsz&#261; cz&#281;&#347;ci&#261; wiedzy o systemach sztucznej
inteligencji. W pewnym wi&#281;c sensie badanie AI jest nauk&#261; nakierowan&#261; na rozwi&#261;zanie
wszystkich istniej&#261;cych problemów. W pierwszej chwili mo&#380;e wydawa&#263; si&#281; to nam
my&#347;leniem &#380;yczeniowym albo nawet, &#380;e jest to nieosi&#261;galne, przecie&#380; je&#347;li istnia&#322;by
prosty, definiowalny matematycznie sposób radzenia sobie z ka&#380;d&#261; napotykan&#261;
sytuacj&#261; to na pewno kto&#347; odkry&#322;by go ju&#380; dawno temu. Jednak co ciekawe, mimo
i&#380; pewne intuicje na temat dzia&#322;ania mózgu by&#322;y obecne od dawna, to próby
systematycznego opisu jego dzia&#322;ania rozpoczynaj&#261; si&#281; w XIX w. w psychologii i na prze&#322;omie
wieków w matematyce jako logika. W nast&#281;puj&#261;cym potem okresie psychologia
pos&#322;u&#380;y&#322;a jako inspiracja, do badania procesów wyst&#281;puj&#261;cych w mózgu a logika
dostarczy&#322;a, poza systemem rozumowania, podstawy do stworzenia g&#322;ównego
obiektu do przeprowadzania eksperymentów, jakim okaza&#322; si&#281; komputer. Mimo i&#380;
rozwi&#261;zania tu opisane korzystaj&#261; szczodrze z rozwi&#261;za&#324; znanych w matematyce od
wieków, to mog&#322;y one zosta&#263; zastosowane dzi&#281;ki rozleg&#322;ej mocy obliczeniowej
dostarczonej przez nowoczesne komputery. Nie oznacza to, jednak &#380;e wszystko
by&#322;o gotowe i czeka&#322;o na zastosowanie. Chocia&#380;by sieci neuronowe, wed&#322;ug naszej
wiedzy, nie &#347;ni&#322;y si&#281; nikomu przed wynalezieniem komputerów. Jest to bardzo
ciekawe gdy&#380; model sieci neuronowej lub chocia&#380;by samego neuronu, zdaje si&#281;
bardzo prosty, po jego zrozumieniu. Okazuje si&#281;, &#380;e nasza wyobra&#378;nia mimo
swojej mocy jest ograniczona, wi&#281;c wi&#281;kszo&#347;&#263; rozwi&#261;za&#324;, o których tu mowa
zosta&#322;o opracowanych dopiero w ci&#261;gu kilkudziesi&#281;ciu ostatnich lat. W&#322;a&#347;ciwie, jak
zobaczysz w ostatnim rozdziale, ten proces nadal trwa. Prawdopodobnie zosta&#322;o nam
jeszcze wiele do odkrycia, zanim b&#281;dziemy mogli uzna&#263; problem za ca&#322;kowicie
rozwi&#261;zany. A je&#347;li chodzi o nadmiern&#261; &#322;atwo&#347;&#263; takiego podej&#347;cia do AI, to
jak to bywa, wiele rozwi&#261;za&#324;, które mog&#261; si&#281; wydawa&#263; &#322;atwe na pocz&#261;tku,
okazuje si&#281; niezmiernie skomplikowane i trudne w wykonaniu. Chocia&#380; d&#322;uto mo&#380;e
ociosa&#263; kamie&#324; w dowolnym kszta&#322;cie, to stworzenie katedry za pomoc&#261; d&#322;uta jest
wielkim wyzwaniem. Zobaczymy, i&#380; formalizowanie pewnych intuicyjnych koncepcji
mo&#380;e by&#263; zawi&#322;e i &#380;e dyscyplina sztucznej inteligencji jest w istocie dziedzin&#261;
in&#380;ynieryjn&#261;.
<a 
 id="x1-4001r4"></a>
</p>
                                                                                    
                                                                                    
<h3 class="sectionHead"><span class="titlemark">1.3   </span> <a 
 id="x1-50003"></a>W&#322;a&#347;ciwy wst&#281;p</h3>
<!--l. 43--><p class="noindent" >Powiedzieli&#347;my ju&#380;, czym zajmuje si&#281; dziedzina sztucznej inteligencji, jednak nie
wspomnieli&#347;my, &#380;e bardzo podobn&#261; dziedzin&#261; wykorzystuj&#261;c&#261; komputery do
rozwi&#261;zywania problemów jest informatyka. Jaka jest ró&#380;nica mi&#281;dzy dziedzin&#261;
informatyki a dziedzin&#261; sztucznej inteligencji? Sztuczna inteligencja wywodzi si&#281; z
informatyki na wiele sposobów. Zazwyczaj ci sami ludzie pracuj&#261;cy w wydzia&#322;ach
informatyki zajmowali si&#281; te&#380; problemami sztucznej inteligencji, u&#380;ywali do tego znanych
przez siebie metod, czyli metod przetwarzania informacji. Czytelnik móg&#322;by nawet
powiedzie&#263;, &#380;e rozwi&#261;zania, które kiedy&#347; uwa&#380;ane by&#322;y za AI, obecnie uchodz&#261; za
zwyczajne algorytmy. Jednak zwyczajow&#261; dat&#261; uznawan&#261; za pocz&#261;tek AI jest rok 1956, kiedy
to odby&#322; si&#281; tzw. warsztat w Dartmouth. W nocie proponuj&#261;cej ten warsztat napisano m.in.
&#380;e proponuj&#261;cy warsztat, czyli McCarthy, Minsky, Rochester i Shannon, nazwiska wa&#380;ne
dla dziedziny, my&#347;l&#261;, &#380;e dziesi&#281;&#263; osób pracuj&#261;cych przez lato jest w stanie dokona&#263;
znacz&#261;cych post&#281;pów. Pomimo wielkich planów efektem by&#322;y raczej przyja&#378;nie i
ekscytacja nowymi mo&#380;liwo&#347;ciami ni&#380; realne post&#281;py. Jak wi&#281;c sami uczestnicy
tego warsztatu definiuj&#261; poj&#281;cie AI? John McCarthy: [AI to] &#8222;nauka i in&#380;ynieria
tworzenia inteligentnych maszyn&#8221;. Mogliby&#347;my podej&#347;&#263; do sprawy w ten sam
sposób, przyjmuj&#261;c, &#380;e AI jako dziedzina zajmuje si&#281; badaniem zagadnienia, jak
stworzy&#263; sztuczn&#261; wersj&#281; prawdziwej inteligencji, jak mog&#322;aby to sugerowa&#263; sama
nazwa. Ale b&#281;dziemy przeciwni takiej interpretacji, cz&#281;&#347;ciowo z powodu braku
jasno&#347;ci takiego postawienia sprawy. W ko&#324;cu czy na pewno wiemy, czym jest
inteligencja? Oczywi&#347;cie McCarthy dzia&#322;a&#322; prawdopodobnie celowo, proponuj&#261;c
rozmyt&#261; definicj&#281; na pocz&#261;tku istnienia dziedziny, tak aby nie by&#322;a ona przeszkod&#261;
dla naukowców. Jednak obecnie, definicja, któr&#261; uwa&#380;amy za lepsz&#261;, brzmi
nast&#281;puj&#261;co:<br 
class="newline" />
</p><!--l. 45--><p class="noindent" ><span 
class="aeb10-x-x-120">Sztuczna inteligencja </span>to dziedzina wiedzy zajmuj&#261;ca si&#281; badaniem programów
komputerowych, które w nietrywialny sposób u&#380;ywaj&#261; wcze&#347;niej zdefiniowanych zasad,
&#380;eby tworzy&#263; nowe niezdefiniowane wcze&#347;niej zasady, które pomagaj&#261; w osi&#261;ganiu
zadanych celów.<br 
class="newline" />
</p><!--l. 47--><p class="indent" >   Z definicji tej wynika, &#380;e aby program zosta&#322; uznany za sztuczn&#261; inteligencj&#281;, musi w
znacz&#261;cym stopniu wykazywa&#263; si&#281; zmian&#261; swoich decyzji w zale&#380;no&#347;ci od napotkanych
sytuacji. Wyobra&#378;my sobie np. gr&#281; w kamie&#324;-papier-no&#380;yce. Tworz&#261;c program graj&#261;cy
w t&#281; gr&#281;, mogliby&#347;my zaprogramowa&#263; zasad&#281;, &#380;e je&#347;li przeciwnik u&#380;ywa
ponadprzeci&#281;tnej ilo&#347;ci &#8222;kamieni&#8221; to zawsze gramy w odpowiedzi &#8222;papier&#8221;, podobnie dla
innych mo&#380;liwo&#347;ci. Teraz, je&#347;li przeciwnik zacznie nadu&#380;ywa&#263; której&#347;
mo&#380;liwo&#347;ci to program go za to ukara. Jest to jednak podej&#347;cie proceduralne,
wyliczaj&#261;ce wszystkie mo&#380;liwo&#347;ci. Alternatyw&#261; by&#322;oby zastosowanie ogólnej zasady z
                                                                                    
                                                                                    
kilkoma przypadkami. Mo&#380;emy stworzy&#263; zasad&#281;: je&#347;li przeciwnik nadu&#380;ywa
<!--l. 47--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> to graj
<!--l. 47--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math> które
pokonuje <!--l. 47--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>.
Teraz wystarczy, &#380;e system podstawi odpowiednie warto&#347;ci zgodnie z kolejno&#347;c&#261;:
kamie&#324;, papier, no&#380;yce. W ten sposób mamy uniwersaln&#261; zasad&#281; z trzema przypdkami, a
wi&#281;c spe&#322;niamy definicj&#281; sztucznej inteligencji, je&#347;li uznamy to dzia&#322;anie za nietrywialne.
G&#322;ównym problemem tej definicji jest w&#322;a&#347;nie pojawiaj&#261;ce si&#281; tam s&#322;owo &#8216;nietrywialne&#8217;,
które mo&#380;emy rozumie&#263; tylko intuicyjnie. W pewnym sensie jednak to, co b&#281;dzie si&#281;
kry&#263; pod tym wyrazem, b&#281;dzie zwi&#261;zane z nasz&#261; wiedz&#261; w tej dziedzinie.
<a 
 id="x1-5001r5"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">1.4   </span> <a 
 id="x1-60004"></a>Jakie tematy poruszymy w tym kursie</h3>
<!--l. 51--><p class="noindent" >Podstaw&#261; zrozumienia tego kursu jest pewna znajomo&#347;&#263; matematyki. Jednak jest on tak
pomy&#347;lany, aby osoba nieposiadaj&#261;ca cz&#281;&#347;ci niezb&#281;dnej wiedzy, takiej jak np. podstawy
ró&#380;niczkowania, mog&#322;a zrozumie&#263; jak najwi&#281;cej. Zaawansowane tematy nie b&#281;d&#261;
zawarte w tym tek&#347;cie i nie to by&#322;o my&#347;l&#261; autora. Raczej ni&#380; wprowadza&#263;
jak najwi&#281;cej tematów, autor jest przekonany, &#380;e lepiej jest posi&#261;&#347;&#263; g&#322;&#281;bokie
zrozumienie podstaw ni&#380; mie&#263; nik&#322;e poj&#281;cie o przeró&#380;nych pomys&#322;ach, nie
b&#281;d&#261;c w stanie ich odtworzy&#263;. Autor chce zawrze&#263; w tym kursie matematyczn&#261;
optymalizacj&#281;, sieci neuronowe, drzewa poszukiwa&#324; oraz uczenie przez wzmacnianie.
Dla osoby pierwszy raz stykaj&#261;cej si&#281; z tematem mo&#380;e si&#281; to wyda&#263; niedu&#380;&#261;
ilo&#347;ci&#261; materia&#322;u, ekspert mo&#380;e my&#347;le&#263;, &#380;e pokryjemy ka&#380;dy temat &#378;le. W
umy&#347;le autora wszystkie te obiekcje s&#261; wa&#380;ne, ale tematy zosta&#322;y wybrane ze
wzgl&#281;du na tworzenie jak najbardziej zawieraj&#261;cej si&#281; w sobie historii, która by&#322;aby
interesuj&#261;ca dla czytelnika i jednocze&#347;nie prezentowa&#322;a najpot&#281;&#380;niejsze istniej&#261;ce
techniki.
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p>
   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;2</span><br /><a 
 id="x1-70002"></a>Optymalizacja matematyczna</h2>
<!--l. 5--><p class="noindent" >Optymalizacja matematyczna jest dziedzin&#261; rozpoczynaj&#261;c&#261; si&#281; od najwi&#281;kszych nazwisk w
matematyce, m.in. Newton i Gauss odkryli pierwsze iteracyjne metody poruszania si&#281; w
stron&#281; optimum, a Fermat i Lagrange znale&#378;li sposoby wynikaj&#261;ce z rachunku
ró&#380;niczkowego na znajdywanie tych maksimów i minimów. Innym wa&#380;nym
nazwiskiem dla dziedziny jest Dantzig, który stworzy&#322; algorytm Simplex, myl&#261;c
nierozwi&#261;zany problem z zadaniem domowym. Mimo i&#380; optymalizacja ma d&#322;ugi rodowód,
to nadal jest rosn&#261;c&#261; dziedzin&#261; z wieloma osobliwo&#347;ciami. Obecnie wykorzystuje si&#281; w niej
zaawansowany aparat matematyczny, który pozwala na tworzenie lepszych metod
optymalizacyjnych. Rozwi&#261;zania z tej dziedziny s&#261; wykorzystywane w mechanice do
projektowania budynków czy przedmiotów, w ekonomii do modelowania zachowa&#324; ludzi
czy te&#380; w elektrotechnice. Widzimy wi&#281;c, &#380;e dziedzina ta istnia&#322;a przed powstaniem
sztucznej inteligencji i posiada wiele zastosowa&#324;. My spojrzymy na ni&#261; w wymiarze, w
którym pozwoli nam ona osi&#261;gn&#261;&#263;, to czego potrzebujemy do dzia&#322;ania naszych systemów
oraz poka&#380;emy kluczowe pomys&#322;y. Nale&#380;y jednak zaznaczy&#263;, &#380;e wi&#281;kszo&#347;&#263;
ludzi pracuj&#261;cych w AI u&#380;ywa bibliotek, które zawieraj&#261; znane, najlepsze wersje
optymalizatorów. Jednak aby stosowa&#263; opisane metody z sukcesem, kluczowym jest
zrozumienie wewn&#281;trznego dzia&#322;ania tych technik.<br 
class="newline" />
</p><!--l. 7--><p class="indent" >   Podstawowym pomys&#322;em stoj&#261;cym za u&#380;yciem metod optymalizacyjnych w AI jest to,
&#380;e cz&#281;sto mamy rozleg&#322;y zasób mo&#380;liwo&#347;ci, z którego nie potrafimy w jasny sposób
wybra&#263; najlepszej mo&#380;liwo&#347;ci bez ekstensywnej eksploracji. Pomy&#347;lmy np. o wyborze
dania w restauracji szybkiej obs&#322;ugi. Chcemy wybra&#263; jedzenie do 500 kcal, które b&#281;dzie
nam najbardziej smakowa&#322;o. Mogliby&#347;my np. zje&#347;&#263; BigMac&#8217;a, który ma 495 kcal i
wyczerpuje za jednym razem ca&#322;y nasz limit, jednak równie dobrze mo&#380;emy wybra&#263; ma&#322;e
frytki, ma&#322;y shake i sos jogurtowo-koperkowy co sprawi, &#380;e zmie&#347;cimy si&#281; w
limicie tym razem z 485 kcal. Takich mo&#380;liwo&#347;ci jest naprawd&#281; du&#380;o. Zamiast
sosu mogliby&#347;my wzi&#261;&#263;, chocia&#380;by kaw&#281; albo zamiast shake&#8217;a du&#380;&#261; col&#281;. W
takich przypadkach przydaje si&#281; znajomo&#347;&#263; technik optymalizacji. Pozwalaj&#261;
nam one na przetestowanie du&#380;ej liczby mo&#380;liwo&#347;ci i wybranie takiej, która
najbardziej nam odpowiada. Do tego problemu powrócimy pó&#378;niej. Zazwyczaj
jednak skupiamy si&#281; na sytuacjach ci&#261;g&#322;ych, w których mo&#380;emy wybra&#263; dowoln&#261;
ilo&#347;&#263; danej rzeczy. To tak jakby&#347;my mogli zamówi&#263; 1,2 frytek lub 0,56 sosu.
Poniewa&#380; zazwyczaj restauracje nie pozwalaj&#261; nam na tak&#261; ekstrawagancj&#281;, to
skupimy si&#281; na troch&#281; innym przyk&#322;adzie. Pomy&#347;lmy o sytuacji, w której chcemy
wybra&#263; najlepsze miejsce na wybudowanie domu. Oczywi&#347;cie w teorii mo&#380;emy
uszeregowa&#263; wszystkie dost&#281;pne miejsca i wybra&#263; najlepsze, ale mo&#380;e by&#263;
takich mo&#380;liwo&#347;ci nazbyt wiele. Mogliby&#347;my przecie&#380; postawi&#263; nasz dom
nad morzem lub w górach, na obrze&#380;u miasta lub w wiosce, na p&#322;askim lub
                                                                                    
                                                                                    
nierównym terenie, w ko&#324;cu na skale lub na piasku. Poniewa&#380; nie jeste&#347;my
w stanie sprawdzi&#263; wszystkich tych mo&#380;liwo&#347;ci, ze wzgl&#281;du na ich ilo&#347;&#263;,
to z pomoc&#261; przychodzi nam optymalizacja matematyczna. Odpowiada ona na
pytanie: jaki jest najlepszy sposób, aby bada&#263; t&#281; przestrze&#324; mo&#380;liwo&#347;ci? Nasza
przestrze&#324; ma pewn&#261; korzystn&#261; w&#322;a&#347;ciwo&#347;&#263;, a mianowicie mo&#380;e by&#263; opisana
matematycznie. Je&#347;li we&#378;miemy pod uwag&#281; po&#322;o&#380;enie domu na mapie, to otrzymujemy
przestrze&#324; kartezja&#324;sk&#261; z zaznaczonymi na niej punktami, które odzwierciedlaj&#261;
mo&#380;liwe po&#322;o&#380;enie domu. Mamy wi&#281;c dwie potrzebne rzeczy dla optymalizatora, a
mianowicie przestrze&#324; oraz mo&#380;liwe po&#322;o&#380;enia do testowania. Brakuje nam
jednak jeszcze jednego. Metoda, której u&#380;yjemy, musi wiedzie&#263;, jak bardzo
cenimy dane po&#322;o&#380;enie, aby by&#263; w stanie da&#263; nam coraz to lepsze rezultaty.
Tak wi&#281;c za&#322;ó&#380;my, &#380;e dla ka&#380;dego pojawiaj&#261;cego si&#281; po&#322;o&#380;enia b&#281;dziemy
wpisywa&#263; warto&#347;&#263; r&#281;cznie. Z takim przygotowaniem mo&#380;emy u&#380;y&#263; metod
optymalizacyjnych. Jak to b&#281;dzie dzia&#322;a&#263;? Je&#347;li poruszymy si&#281;, powiedzmy w pierwszym
kroku w stron&#281; morza, a my wolimy góry, to przypiszemy nowemu po&#322;o&#380;eniu
ni&#380;sz&#261; warto&#347;&#263;. Optymalizator sam &#8216;zorientuje si&#281;&#8217;, &#380;e nale&#380;y kierowa&#263;
si&#281; w przeciwnym kierunku i w nast&#281;pnych krokach zmieni sposób poruszania
si&#281;.
<a 
 id="x1-7001r6"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">2.1   </span> <a 
 id="x1-80001"></a>Metoda prób i b&#322;&#281;dów</h3>
<!--l. 11--><p class="noindent" >Spróbujemy teraz sformalizowa&#263;, to co opisali&#347;my w poprzednim podrozdziale.
Mo&#380;esz nadal my&#347;le&#263; o wyborze najkorzystniejszego po&#322;o&#380;enia na dom, nie b&#281;dzie to
kolidowa&#263; z formaln&#261; definicj&#261;. Problem jest okre&#347;lony nast&#281;puj&#261;co: Mamy zmienn&#261;
<!--l. 11--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math> któr&#261;
chcemy optymalizowa&#263;, to znaczy sprawi&#263;, aby by&#322;a jak najwi&#281;ksza. Zmienna
<!--l. 11--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math> zale&#380;y od
zmiennej <!--l. 11--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
w jaki&#347; nieznany nam sposób. Jednak mo&#380;emy wp&#322;ywa&#263; na
<!--l. 11--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
poprzez podejmowanie akcji. Wyobra&#378;my sobie, &#380;e mo&#380;emy go zmienia&#263;, tak jak
zmieniali&#347;my po&#322;o&#380;enie domu.<br 
class="newline" />
</p>
   <table class="equation"><tr><td> <a 
 id="x1-8001r1"></a>
                                                                                    
                                                                                    
<!--l. 13--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                   <mi 
>m</mi><mi 
>a</mi><mi 
>x</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>y</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(2.1)</td></tr></table>
<!--l. 17--><p class="indent" >   Gdzie <!--l. 17--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> jest zmienn&#261;,
na któr&#261; mamy wp&#322;yw, <!--l. 17--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>f</mi></mstyle></mstyle></math>
jest transformacj&#261;, której zazwyczaj nieznamy, <span 
class="aeb10-x-x-120">max(y) </span>mówi nam, &#380;e
<!--l. 17--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math> jest
celem, inaczej mówi&#261;c wielko&#347;ci&#261;, któr&#261; chcemy maksymalizowa&#263;.<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-8002r1"></a>
                                                                                    
                                                                                    
<!--l. 21--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 21--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-8003"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;2.1:</span><span  
class="content">Metoda prób i b&#322;&#281;dów</span></figcaption><!--tex4ht:label?: x1-8002r2 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 27--><p class="indent" >   <span 
class="aeb10-x-x-120">Metoda pr</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">b i b&#322;&#281;d</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">w </span>proponuje nam, aby&#347;my zgadli warto&#347;&#263;
<!--l. 27--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> i zapisali zwi&#261;zan&#261;
z ni&#261; warto&#347;&#263; <!--l. 27--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>.
Nast&#281;pnie wielokrotnie powtarzamy faz&#281; zgadywania i zapisu. Po jakim&#347; czasie takiego zgadywania
wybieramy <!--l. 27--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
które posiada&#322;o zwi&#261;zan&#261; z ni&#261; najwy&#380;sz&#261; warto&#347;&#263;
<!--l. 27--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>.<br 
class="newline" />
</p><!--l. 29--><p class="indent" >   Jest to najprostsza mo&#380;liwa metoda optymalizacji. &#379;eby j&#261; stosowa&#263;, wystarczy
utrzymywa&#263; w pami&#281;ci najlepsze rozwi&#261;zanie, na które napotkali&#347;my do tej pory i
zgadywa&#263; kolejne rozwi&#261;zania, które mog&#261; by&#263; lepsze, czyli najlepiej takie, których
poprzednio nie sprawdzali&#347;my. T&#261; metod&#261; mo&#380;emy sprawdzi&#263; ka&#380;d&#261; mo&#380;liw&#261; sytuacj&#281;,
je&#347;li tylko przestrze&#324; akcji, któr&#261; badamy, jest sko&#324;czona. Mapa, na której szukamy
miejsca na dom, powinna by&#263; ograniczona np. s&#261;siaduj&#261;cymi krajami i posiada&#263;
ograniczenie ma&#322;&#261; wielko&#347;&#263; kroku. W takiej sytuacji, je&#347;li damy tej metodzie
wystarczaj&#261;co du&#380;o czasu to doprowadzi nas ona do najlepszego istniej&#261;cego rozwi&#261;zania.
Jest to niew&#261;tpliwie silna strona tego podej&#347;cia, która pokazuje generalno&#347;&#263; tej metody.
Ta prosta metoda ma jednak równie&#380; pewne problemy, jak niesko&#324;czone przestrzenie
powoduj&#261;ce, &#380;e wyszukiwanie potrzebuje niesko&#324;czonego czasu, aby znale&#378;&#263; najlepsze
rozwi&#261;zanie. Tak&#380;e z regu&#322;y, czas, który zajmuje ta metoda, w porównaniu do innych
jest daleki od najlepszych. Co powoduje tak&#261; nieefektywno&#347;&#263;? Metoda prób
i b&#322;&#281;dów nie posiada &#380;adnej metryki, która pokazywa&#322;aby nam, jak bardzo
poprawia si&#281; nasz wynik w miar&#281; szukania. Mo&#380;na to porówna&#263; do szukania
przycisku do zapalania &#347;wiat&#322;a po omacku. Nie jest to &#322;atwe zadanie, chocia&#380; po
pewnym czasie si&#281; nam to uda. Sytuacj&#281; z wy&#322;&#261;cznikiem &#347;wiat&#322;a poprawia na
dodatek fakt, &#380;e zazwyczaj wiemy, mniej wi&#281;cej, w jakim kierunku si&#281; on znajduje.
Jednak je&#347;li trafiliby&#347;my do zupe&#322;nie nowego pokoju, to problem ten by&#322;by o
wiele trudniejszy. Z takimi trudno&#347;ciami boryka si&#281; metoda prób i b&#322;&#281;dów. Aby
poprawi&#263; szybko&#347;&#263; szukania, potrzebujemy jakiej&#347; miary, która b&#281;dzie nam
mówi&#263;, czy poprawiamy nasz wynik, czy nie. Tak samo gra w szukanie wy&#322;&#261;cznika
staje si&#281; du&#380;o &#322;atwiejsza, kiedy kto&#347; mówi nam &#8216;ciep&#322;o&#8217; lub &#8217;zimno&#8217; wraz z
poruszaniem si&#281; po pokoju. Z podobnego rodzaju informacji powinien korzysta&#263; nasz
algorytm.<br 
class="newline" />
<a 
 id="x1-8004r8"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">2.2   </span> <a 
 id="x1-90002"></a>Wspinaczka górska</h3>
<!--l. 33--><p class="noindent" >Pomy&#347;lmy, jak mogliby&#347;my prowadzi&#263; nasze poszukiwania, tak aby nie sprawdza&#263; tak
                                                                                    
                                                                                    
wielu z&#322;ych rozwi&#261;za&#324;. Jakiego rodzaju informacji mogliby&#347;my u&#380;y&#263;? Jedn&#261; z metod,
która mog&#322;aby nam pomóc, jest lepszy wybór punktów do sprawdzenia. Je&#347;li
przestrze&#324; jest wystarczaj&#261;co ci&#261;g&#322;a, to znaczy punkty le&#380;&#261;ce nieopodal siebie maj&#261;
podobne w&#322;a&#347;ciwo&#347;ci, to mogliby&#347;my u&#380;y&#263; wiedzy o punktach le&#380;&#261;cych blisko, &#380;eby
przybli&#380;a&#263; warto&#347;&#263; szukanego punktu. Zupe&#322;nie jak w grze ciep&#322;o-zimno, je&#347;li wiemy,
&#380;e jeste&#347;my w miejscu, w którym niedaleko by&#322;o &#8216;zimno&#8217;, to prawdopodobnie tu gdzie
jeste&#347;my, te&#380; b&#281;dzie &#8216;zimno&#8217;. Tak wi&#281;c mo&#380;emy skupi&#263; nasze poszukiwania jedynie na
punktach, w których jest &#8216;ciep&#322;o&#8217;, czy mówi&#261;c inaczej na punktach, które daj&#261; nam dobr&#261;
warto&#347;&#263; numeryczn&#261; funkcji warto&#347;ci. Poniewa&#380; chcemy prowadzi&#263; nasze
poszukiwania na dowolnie du&#380;ych przestrzeniach, we&#378;miemy pod uwag&#281; tylko
poszukiwanie lokale, czyli takie, które skupia si&#281; na wyszukiwaniu optimów lokalnych.
Zazwyczaj taki rodzaj poszukiwania ma w danym momencie tylko jednego kandydata na
rozwi&#261;zanie.<br 
class="newline" />
</p><!--l. 35--><p class="indent" >   Tu mo&#380;emy wspomnie&#263;, &#380;e istniej&#261; te&#380; tak zwane poszukiwania globalne takie, jak
np. algorytm mrówkowy, który bierze swoj&#261; nazw&#281; od symulowania zachowania
owadów, jakimi s&#261; mrówki. Tworzy on wiele &#8216;mrówek&#8217;, ka&#380;da ze swoim osobnym
zachowaniem. Akcje poszczególnych mrówek wp&#322;ywaj&#261; na siebie tak, &#380;e zachowanie
ca&#322;ego roju jest bardziej inteligentne ni&#380; poszczególnych osobników. Algorytm
ten dzia&#322;a na zasadzie zaobserwowanej w &#347;wiece zwierz&#261;t. Mrówki poruszaj&#261;
si&#281; po losowych &#347;cie&#380;kach, chyba &#380;e znajd&#261; po&#380;ywienie. Wtedy wracaj&#261; do
mrowiska, pozostawiaj&#261;c za sob&#261; &#347;lad z feromonów. Inne mrówki napotykaj&#261;c na
&#347;lad z feromonów, zaczynaj&#261; nim pod&#261;&#380;a&#263;, w efekcie samemu wydzielaj&#261;c
feromony. W ten sposób ucz&#281;szczana &#347;cie&#380;ka jest wzmacniana. Kiedy jednak
jedzenie si&#281; ko&#324;czy, wydzielanie feromonów zostaje zaprzestane, a &#347;cie&#380;ka
naturalnie zanika. Podobnego sposobu mo&#380;emy u&#380;y&#263; do znajdywania najlepszych
&#347;cie&#380;ek na grafie. To nazywane jest poszukiwaniem globalnym, poniewa&#380; próbuje
znale&#378;&#263; globalnie najlepsze rozwi&#261;zanie, czyli takie, które jest najlepsze dla
ca&#322;ej przestrzeni. Takie poszukiwanie cz&#281;sto utrzymuje w pami&#281;ci wiele punktów
zwi&#261;zanych z danym problemem i próbuje znale&#378;&#263; rozwi&#261;zanie, bior&#261;c pod uwag&#281; je
wszystkie. W przeciwie&#324;stwie do poszukiwania globalnego poszukiwanie lokalne
szuka najlepszego rozwi&#261;zania tylko w pewnej okolicy. Zazwyczaj utrzymuje te&#380;
w pami&#281;ci informacje o tylko jednym punkcie. Mog&#322;oby si&#281; nam wydawa&#263;, &#380;e
poszukiwanie globalne b&#281;dzie nam bardziej przydatne ni&#380; lokalne, jednak najpowszechniej
wykorzystywanymi algorytmami w dziedzinie sztucznej inteligencji s&#261; algorytmy
wyszukiwania lokalnego. To podej&#347;cie ma jedn&#261; wa&#380;n&#261; korzy&#347;&#263;, a mianowicie
mo&#380;liwo&#347;&#263; u&#380;ycia informacji o gradiencie. Na razie nie musimy si&#281; jednak o to
martwi&#263;.<br 
class="newline" />
</p><!--l. 37--><p class="indent" >   O takim sposobie lokalnego poszukiwania mo&#380;emy my&#347;le&#263; jak o wspinaczce
                                                                                    
                                                                                    
górskiej. Wyobra&#378;my sobie, &#380;e znajdujemy si&#281; u podnó&#380;a góry, na której
szczyt chcemy si&#281; wspi&#261;&#263;. Mamy jednak jeden problem. Nie widzimy wierzcho&#322;ka,
gdy&#380; ca&#322;a góra zosta&#322;a pokryta mg&#322;&#261;. Teraz, aby dosta&#263; si&#281; na szczyt, mo&#380;emy
podj&#261;&#263; nast&#281;puj&#261;c&#261; metod&#281; dzia&#322;ania. Patrzymy si&#281; na punkty w widocznej okolicy
i wybieramy ten, który znajduje si&#281; najwy&#380;ej. W jego kierunku si&#281; udajemy.
Powtarzamy ten proces, dopóki wszystkie punkty znajduj&#261;ce si&#281; obok nas s&#261; ni&#380;ej
po&#322;o&#380;one i wtedy stwierdzamy, &#380;e znale&#378;li&#347;my si&#281; na szczycie i ko&#324;czymy
poszukiwania. Oczywi&#347;cie nie jest powiedziane, &#380;e w efekcie dzia&#322;ania tej metody
znajdziemy si&#281; na oczekiwanym szczycie. Mo&#380;e si&#281; np. okaza&#263;, &#380;e wejdziemy na
gór&#281; znajduj&#261;ca si&#281; obok. Mo&#380;e te&#380; si&#281; sta&#263; tak, &#380;e nie wejdziemy na &#380;aden
szczyt, tylko utkniemy na pagórku. Ta w&#322;a&#347;ciwo&#347;&#263; tego poszukiwania nazywana
jest problemem maksimum lokalnego. Kiedy&#347; uwa&#380;ano, &#380;e maksima lokalne s&#261;
g&#322;ówn&#261; przeszkod&#261; w osi&#261;ganiu najlepszego rozwi&#261;zania. Obecnie pogl&#261;dy na ten
temat uleg&#322;y zmianie i za najgorsze s&#261;&#x00A0;uwa&#380;ane p&#322;askie przestrzenie, jednak nie
ulega w&#261;tpliwo&#347;ci, &#380;e mo&#380;liwym jest utkni&#281;cie w maksimum lokalnym. Aby
temu zapobiega&#263;, wymy&#347;lono metod&#281; losowego resetu (ang. random-restart),
która wykonuje wspinaczk&#281; górsk&#261; wielokrotnie za ka&#380;dym razem z losowo
wybranego stanu pocz&#261;tkowego. Ma to s&#322;u&#380;y&#263; omijaniu minimów lokalnych. Jednak
wybiegli&#347;my do przodu, powiedzmy najpierw, czym w ogóle jest algorytm wspinaczki
górskiej.<br 
class="newline" />
</p><!--l. 39--><p class="indent" >
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-9001r2"></a>
                                                                                    
                                                                                    
<!--l. 41--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 41--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-9002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;2.2:</span><span  
class="content">Algorytm wspinaczki górskiej</span></figcaption><!--tex4ht:label?: x1-9001r2 -->
                                                                                    
                                                                                    
   </figure>
<!--l. 45--><p class="indent" >
                                                                                    
                                                                                    
</p><!--l. 47--><p class="noindent" >Algorytm <span 
class="aeb10-x-x-120">wspinaczki g</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">rskiej </span>(ang. hill climbing) utrzymuje w pami&#281;ci jedno
obecnie najlepsze rozwi&#261;zanie, sprawdza punkty wokó&#322; i porusza si&#281; w kierunku
najwi&#281;kszej poprawy warto&#347;ci, tak d&#322;ugo, jak jakakolwiek mo&#380;e by&#263; otrzymana.
W tym algorytmie wybór punktów do sprawdzenia odbywa si&#281; w pewien
specyficzny sposób. Wyobra&#378;my sobie, &#380;e zamiast wybiera&#263; najwy&#380;szy punkt,
sprawdzamy cztery kierunki &#347;wiata i udajemy si&#281; w kierunku, w którym poprawa
jest najwi&#281;ksza. Analogiczne dzia&#322;anie ma algorytm wspinaczki górskiej. W
<!--l. 47--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
wymiarach przed zmian&#261; pozycji powinni&#347;my sprawdzi&#263; 2 *
<!--l. 47--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
ortogonalnych kierunków. To znaczy kierunków, które znajduj&#261; si&#281; wobec siebie pod k&#261;tem
prostym w <!--l. 47--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
wymiarach.<br 
class="newline" />
</p><!--l. 49--><p class="indent" >   Ten problem tego podej&#347;cia wydaje si&#281; oczywisty, wraz ze wzrostem ilo&#347;ci wymiarów
ilo&#347;&#263; mo&#380;liwo&#347;ci, które musimy sprawdzi&#263;, ro&#347;nie w ogromny sposób. Równie&#380;
niekoniecznie poruszamy si&#281; w najlepszym kierunku, poniewa&#380; mo&#380;e on le&#380;e&#263;
pomi&#281;dzy kierunkami, które sprawdzali&#347;my. Wybieramy tylko jeden spo&#347;ród 2 *
<!--l. 49--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
kierunków, który jest najbli&#380;ej optymalnego kierunku wchodzenia w gór&#281;. Nie
u&#380;yli&#347;my te&#380; &#380;adnych informacji na temat tak zwanego gradientu.<br 
class="newline" />
<a 
 id="x1-9003r9"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">2.3   </span> <a 
 id="x1-100003"></a>Metoda gradientu prostego</h3>
<!--l. 55--><p class="noindent" >Rozmawiali&#347;my o poruszaniu si&#281; w gór&#281; zbocza, zwi&#281;kszaj&#261;c jak&#261;&#347; warto&#347;&#263;, ale ludzie
ze &#347;rodowiska optymalizacyjnego z niezbyt jasnych powodów (prawdopodobnie chodzi o
jasno&#347;&#263; notacji) zazwyczaj mówi&#261; o poruszaniu si&#281; w dó&#322;, zmniejszaj&#261;c jak&#261;&#347;
warto&#347;&#263;. Te pomys&#322;y s&#261; identyczne poza zmian&#261; znaku. Je&#347;li konceptualnie odwrócimy
przestrze&#324; na g&#322;owie, to mo&#380;emy zamieni&#263; wspinanie si&#281; ze schodzeniem w dó&#322; i na
odwrót.<br 
class="newline" />
</p><!--l. 57--><p class="indent" >   Mówili&#347;my o problemach, jakie s&#261; zwi&#261;zane z algorytmem wspinaczki górskiej.
G&#322;ównym problemem jest jednak to, &#380;e pomija on pewien rodzaj informacji. Czy mo&#380;esz
wskaza&#263; jaki&#347; rodzaj takich informacji, które pozostaj&#261; nieu&#380;yte, a mog&#322;yby nam
pomóc? Jednym z problemów jest to, &#380;e nie patrzyli&#347;my si&#281; na ró&#380;nic&#281; mi&#281;dzy
warto&#347;ci&#261; naszej funkcji warto&#347;ci w poprzednim punkcie a obecnym, &#380;eby znale&#378;&#263;
lepszy kierunek schodzenia. Jak mog&#322;aby nam ta ró&#380;nica pomóc? Wyobra&#378;my sobie, &#380;e
                                                                                    
                                                                                    
jest ona du&#380;a. Oznacza&#322;oby to, &#380;e poruszamy si&#281; w dobrym kierunku. Je&#347;li jednak ta
ró&#380;nica jest niewielka, to mo&#380;e powinni&#347;my si&#281; porusza&#263; w innym kierunku, który
móg&#322;by nam potencjalnie da&#263; wi&#281;kszy zysk funkcji warto&#347;ci. Teraz we&#378;my pod uwag&#281;
kilka kolejnych kroków i odpowiadaj&#261;ce im zmiany funkcji warto&#347;ci. Chcemy wymy&#347;li&#263;
sposób wykorzystania tych informacji do wybrania kolejnego kierunku, który
b&#281;dzie potencjalnie najlepszy. Takie po&#322;&#261;czenie jednych informacji z innymi jest
nazywane korelacj&#261;. Je&#347;li mieliby&#347;my metod&#281; korelacji kierunków, w których
poruszali&#347;my si&#281; z funkcj&#261; warto&#347;ci, to mogliby&#347;my powiedzie&#263; &#380;e kiedy wybierzemy
kierunek o historycznie najwi&#281;kszym spadku to jest to wed&#322;ug naszej wiedzy najlepszy
kierunek. Tak&#261; korelacj&#281; mo&#380;na znale&#378;&#263; w bardzo prosty sposób. Wystarczy
podzieli&#263; zmian&#281; funkcji warto&#347;ci poprzez warto&#347;&#263; kroku w danym kierunku, a
pó&#378;niej wszystko doda&#263; do odpowiednich kierunków, &#380;eby otrzyma&#263; pewne
przybli&#380;enie zmiany w ka&#380;dym kierunku. Nast&#281;pnie wybieramy kierunek o najwi&#281;kszej
historycznej poprawie funkcji warto&#347;ci. Poniewa&#380; jednak krzywizna przestrzeni
b&#281;dzie si&#281; zmienia&#263;, to taka procedura b&#281;dzie jedynie pewnym przybli&#380;eniem.
Najpro&#347;ciej jest jednak za&#322;o&#380;y&#263;, &#380;e zmiana w danym kierunku pozostanie taka sama i
zachowywa&#263; si&#281; jak gdyby by&#322;o to prawd&#261;. Metoda ta mo&#380;e by&#263; przydatna
nawet w &#380;yciu codziennym. Wyobra&#378;my sobie, &#380;e robimy w ci&#261;gu dnia ró&#380;ne
rzeczy i zapisujemy, jak dobrze czujemy si&#281; danego dnia. Pó&#378;niej, aby uzyska&#263;
ranking rzeczy, które b&#281;dziemy robi&#263;, mogliby&#347;my rozdzieli&#263; to jak dobrze si&#281;
czuli&#347;my w proporcjach do tego jak du&#380;o wykonywali&#347;my danej czynno&#347;ci
dla ka&#380;dego dnia i doda&#263; wyniki z ró&#380;nych dni. To da&#322;oby nam numeryczne
warto&#347;ci okre&#347;laj&#261;ce po&#380;&#261;danie danych zachowa&#324;, dzi&#281;ki którym mogliby&#347;my je
uszeregowa&#263;.<br 
class="newline" />
</p><!--l. 59--><p class="indent" >
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-10001r3"></a>
                                                                                    
                                                                                    
<!--l. 61--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 61--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-10002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;2.3:</span><span  
class="content">Metoda gradientu prostego</span></figcaption><!--tex4ht:label?: x1-10001r2 -->
                                                                                    
                                                                                    
   </figure>
<!--l. 65--><p class="indent" >
                                                                                    
                                                                                    
</p><!--l. 67--><p class="noindent" >Spójrzmy teraz na bardziej matematyczny przyk&#322;ad w 2-dim (dwóch wymiarach):<br 
class="newline" />Zaczynamy w punkcie <mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>6</mn></math></mstyle>
<span 
class="aeb10-x-x-120">= (</span><mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>6</mn></math></mstyle><span 
class="aeb10-x-x-120">,</span>
<mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>y</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>6</mn></math></mstyle><span 
class="aeb10-x-x-120">)</span>
i poruszamy si&#281; o wektor <span 
class="aeb10-x-x-120">(1, 2)</span>. Ko&#324;czymy w punkcie
<mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>7</mn></math></mstyle> =
(<mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>6</mn></math></mstyle> + 1,
<mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>y</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>6</mn></math></mstyle> + 2) albo w innej
metodzie zapisu w punkcie <mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>7</mn></math></mstyle>
= (<mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>7</mn></math></mstyle>,
<mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>y</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>7</mn></math></mstyle>).
Powiedzmy teraz, &#380;e poprawili&#347;my nasz&#261; funkcj&#281; warto&#347;ci z <span 
class="aeb10-x-x-120">y =</span>
<mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>y</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>6</mn></math></mstyle> do <span 
class="aeb10-x-x-120">y</span>
<span 
class="aeb10-x-x-120">= </span><mstyle mathvariant="bold-italic"><!--l. 67--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>y</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>2</mn><mn>5</mn><mn>7</mn></math></mstyle>.<br 
class="newline" />
</p><!--l. 69--><p class="noindent" ><span 
class="aeb10-x-x-120">Metoda gradientu prostego </span>mówi nam, &#380;e nasz nast&#281;pny kierunek, w którym b&#281;dziemy
si&#281; porusza&#263;, powinien by&#263; proporcjonalny do poprawy naszej funkcji warto&#347;ci (a wi&#281;c w
przyk&#322;adzie do <mstyle mathvariant="bold-italic"><!--l. 69--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>y</mi></math></mstyle>
<span 
class="aeb10-x-x-120">= y1 &#8211; y0</span>) i tak&#380;e odwrotnie proporcjonalny do kierunku, w którym si&#281; poruszali&#347;my
(wi&#281;c wektora <span 
class="aeb10-x-x-120">(1, 2)</span>). W przyk&#322;adzie nast&#281;pny wektor ruchu b&#281;dzie równy
<span 
class="aeb10-x-x-120">(</span><mstyle mathvariant="bold-italic"><!--l. 69--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>y</mi></math></mstyle> <span 
class="aeb10-x-x-120">/ 1,</span>
<mstyle mathvariant="bold-italic"><!--l. 69--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>y</mi></math></mstyle> <span 
class="aeb10-x-x-120">/ 2) </span>a
ogólnie:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-10003r2"></a>
<!--l. 71--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x0394;</mi><mi 
>y</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>&#x0394;</mi><mi 
>x</mi>
</math></td><td class="eq-no">(2.2)</td></tr></table>
<!--l. 75--><p class="noindent" >Gdzie <span 
class="aeb10-x-x-120">gradient </span>oznacza, ogólnie mówi&#261;c kierunek najwi&#281;kszego spadku,
<mstyle mathvariant="bold-italic"><!--l. 75--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>y</mi></math></mstyle> to zmiana funkcji
warto&#347;ci, a <mstyle mathvariant="bold-italic"><!--l. 75--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>x</mi></math></mstyle>
oznacza przesuni&#281;cie, o które poprzednio si&#281; poruszali&#347;my.<br 
class="newline" />
</p><!--l. 77--><p class="indent" >   Co prawda pokazali&#347;my przyk&#322;ad dzia&#322;ania na gradiencie empirycznym otrzymanym z wykonania
                                                                                    
                                                                                    
kroku optymalizacyjnego, lecz lepsz&#261;&#x00A0;metod&#261;&#x00A0;osi&#261;gni&#281;cia tego samego celu jest znalezienie
pochodnej funkcji, któr&#261;&#x00A0;optymalizujemy. Pochodna jest tu sposobem na obliczenie równania
(2.2) dla <mstyle mathvariant="bold-italic"><!--l. 77--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>y</mi></math></mstyle>
oraz <mstyle mathvariant="bold-italic"><!--l. 77--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>x</mi></math></mstyle>, dla
których <mstyle mathvariant="bold-italic"><!--l. 77--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x0394;</mi><mi 
>x</mi></math></mstyle>
d&#261;&#380;y do zera, a wi&#281;c intuicyjnie jest to najlepszy kierunek poruszania si&#281; dla niesko&#324;czenie
ma&#322;ego kroku.<br 
class="newline" />
</p>
   <table class="equation"><tr><td> <a 
 id="x1-10004r3"></a>
<!--l. 79--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                  <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi> <mo 
class="MathClass-rel">=</mo> <msup><mrow 
><mi 
>f</mi></mrow><mrow 
><mi 
>&#x2032;</mi></mrow></msup 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(2.3)</td></tr></table>
<!--l. 83--><p class="noindent" >Gdzie <mstyle mathvariant="bold-italic"><!--l. 83--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>f</mi><mi 
>&#x2032;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></math></mstyle> oznacza pochodn&#261;&#x00A0;pierwszego
stopnia z funkcji <mstyle mathvariant="bold-italic"><!--l. 83--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>f</mi></math></mstyle>
w punkcie <mstyle mathvariant="bold-italic"><!--l. 83--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>x</mi></math></mstyle>.
Powinni&#347;my korzysta&#263; z tego równania zamiast (2.2) zawsze kiedy umiemy wyznaczy&#263; pochodn&#261;
&#x00A0;optymalizowanej funkcji.<br 
class="newline" />
</p><!--l. 85--><p class="indent" >   Aby otrzyma&#263; nowy punkt do sprawdzenia, musimy wzi&#261;&#263; informacje o poprzednim
punkcie i informacje o gradiencie i przetworzy&#263; je w taki sposób, aby otrzyma&#263; nowy
punkt. Najprostszym sposobem na to jest odj&#261;&#263; gradient od starego punktu. Pami&#281;tamy
przy tym, &#380;e szukamy najwi&#281;kszego spadku. Je&#347;li to zrobimy, to otrzymamy tak zwan&#261;
formu&#322;&#281; rekursywn&#261; (co znaczy, &#380;e stosujemy j&#261; wielokrotnie na wyniku tej samej formu&#322;y)
dla znajdywania lepszych punktów:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-10005r4"></a>
                                                                                    
                                                                                    
<!--l. 88--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">-</mo> <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi>
</math></td><td class="eq-no">(2.4)</td></tr></table>
<!--l. 92--><p class="noindent" >Gdzie <mstyle mathvariant="bold-italic"><!--l. 92--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
></math></mstyle>
jest nowym punktem, z którego b&#281;dziemy kontynuowa&#263; poszukiwania,
<mstyle mathvariant="bold-italic"><!--l. 92--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>&#x0393;</mi></mrow></msub 
><mn>3</mn><mn>0</mn><mn>5</mn><mn>7</mn><mn>4</mn></math></mstyle> jest
starym punktem, a <span 
class="aeb10-x-x-120">gradient </span>jest kierunkiem najwi&#281;kszego spadku, w którym si&#281;
poruszamy.<br 
class="newline" />
</p><!--l. 94--><p class="indent" >   Najwi&#281;kszym pomys&#322;em, którego tutaj u&#380;ywamy, jest fakt &#380;e mo&#380;emy u&#380;y&#263;
przesz&#322;ej informacji na temat zakrzywienia przestrzeni któr&#261; badamy &#380;eby prowadzi&#263;
nasze wyszukiwania w najlepszym kierunku. Korzystamy z tego, i&#380; niedalekie
punkty s&#261; cz&#281;sto podobne do siebie, np. je&#347;li jeste&#347;my w p&#322;askim regionie, to
spodziewamy si&#281; &#380;e je&#347;li przesuniemy si&#281; kawa&#322;ek dalej to teren nadal b&#281;dzie
p&#322;aski. Ten algorytm wraz z pewnymi dodatkami, cz&#281;&#347;&#263;, z których zostanie
opisana w kolejnych rozdzia&#322;ach stanowi podstawowy i najcz&#281;&#347;ciej u&#380;ywany
algorytm dla optymalizacji w okoliczno&#347;ciach spotykanych w dziedzinie sztucznej
inteligencji.<br 
class="newline" />
<a 
 id="x1-10006r10"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">2.4   </span> <a 
 id="x1-110004"></a>Plus wielko&#347;&#263; kroku</h3>
<!--l. 98--><p class="noindent" >Powiedzieli&#347;my troch&#281; o wyborze kierunku ruchu, ale nie skupiali&#347;my si&#281; do tej pory na
metodach wyboru wielko&#347;ci kroku. Czytaj&#261;c poprzedni podrozdzia&#322;, mog&#322;e&#347; my&#347;le&#263;
czytelniku, &#380;e gradient jest pewnym idealnym krokiem, o który nale&#380;y si&#281; poruszy&#263;
niezale&#380;nie od sytuacji. Jest prawd&#261;, &#380;e gradient podaje nam kierunek najwi&#281;kszego
spadku, lecz nic nie powiedzieli&#347;my o tym, czy wskazuje on na optymaln&#261; odleg&#322;o&#347;&#263;. Tak
nie b&#281;dzie. Metody gradientu s&#261; wi&#281;c prawie zawsze, u&#380;ywane wraz z rozwi&#261;zaniami,
które wybieraj&#261; wielko&#347;&#263; kroku, który mówi nam, jak daleko powinni&#347;my
si&#281; przesun&#261;&#263; w kierunku gradientu. Potrzebujemy wi&#281;c jakiego&#347; sposobu na
okre&#347;lenie wielko&#347;ci potrzebnego kroku. Najprostszym rozwi&#261;zaniem jest doda&#263; do
równa&#324; pewn&#261; zmienn&#261;, która b&#281;dzie okre&#347;la&#263; wielko&#347;&#263; kroku. Mo&#380;emy j&#261;
nawet nazwa&#263; wielko&#347;ci&#261; kroku. Poprzednie równania zmieni&#261; si&#281; w nast&#281;puj&#261;cy
sposób:<br 
class="newline" />
</p>
                                                                                    
                                                                                    
   <table class="equation"><tr><td> <a 
 id="x1-11001r5"></a>
<!--l. 100--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>y</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>x</mi>
</math></td><td class="eq-no">(2.5)</td></tr></table>
   <table class="equation"><tr><td> <a 
 id="x1-11002r6"></a>
<!--l. 103--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                          <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">-</mo> <mi 
>s</mi><mi 
>t</mi><mi 
>e</mi><mi 
>p</mi><mstyle 
class="text"><mtext  >_</mtext></mstyle><mi 
>s</mi><mi 
>i</mi><mi 
>z</mi><mi 
>e</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi>
</math></td><td class="eq-no">(2.6)</td></tr></table>
<!--l. 107--><p class="noindent" >Gdzie równanie (2.4) jest identyczne z równaniem (2.3), a w równaniu (2.5) które jest
analogiczne do równania (2.4), pojawia si&#281; jednak nowa warto&#347;&#263; zwana <span 
class="aeb10-x-x-120">step_size </span>czyli
wielko&#347;&#263; kroku, ta wielko&#347;&#263; skalarna b&#281;dzie nam mówi&#263;, jak daleko przesuniemy si&#281;
za ka&#380;dym razem.<br 
class="newline" />
</p><!--l. 109--><p class="indent" >   Nale&#380;y zaznaczy&#263;, &#380;e dodanie wielko&#347;ci kroku nie zamyka problemu, konieczno&#347;ci
odpowiedniego jego wybrania. Teraz mo&#380;esz si&#281; zastanowi&#263;, jak powinni&#347;my dokona&#263;
wyboru wielko&#347;ci kroku. Czy istnieje optymalny sposób na dokonanie tego? Odpowied&#378;
brzmi: Nie, nie ma jednej najlepszej metody wyboru kroku dla ka&#380;dego problemu. Ta
w&#322;a&#347;ciwo&#347;&#263; jest spowodowana faktem, &#380;e problemy, które mo&#380;emy chcie&#263;
próbowa&#263; rozwi&#261;za&#263;, mog&#261; by&#263; od siebie bardzo ró&#380;ne. Wyobra&#378;my sobie,
&#380;e mo&#380;emy chcie&#263; wspina&#263; si&#281; na Babi&#261; Gór&#281; lub na Rysy, dla ka&#380;dej z
tych gór wielko&#347;&#263; kroku, który b&#281;dziemy robi&#263;, b&#281;dzie inny, dopasowany
do nachylenia zbocza oraz ilo&#347;ci przeszkód. Od podobnych czynników b&#281;dzie
zale&#380;e&#263; optymalna wielko&#347;&#263; kroku w systemach AI. Taka sytuacja jest cz&#281;sta w
tej dziedzinie i je&#347;li b&#281;dziesz kontynuowa&#322; poszerzanie swojej wiedzy o niej, to
napotkasz na t&#281; w&#322;a&#347;ciwo&#347;&#263; wielokrotnie. Jedn&#261; z rzeczy, która odró&#380;nia
fizyk&#281; i sztuczn&#261; inteligencj&#281; jest fakt, &#380;e w AI nie ma znanych sta&#322;ych jak np.
<span 
class="aeb10-x-x-120">step_size </span>= 0.234&#x2026; czy co&#347; podobnego. To tak&#380;e oznacza, &#380;e kto&#347; próbuj&#261;cy
wytrenowa&#263; model, na przyk&#322;ad, taki o jakim b&#281;dzie mowa w rozdziale o sieciach
                                                                                    
                                                                                    
neuronowych, b&#281;dzie zmienia&#263; tak&#261; zmienn&#261;, &#380;eby zobaczy&#263; czy poprawia to dzia&#322;anie
systemu. Trzeba w tym miejscu zaznaczy&#263;, &#380;e takie nudne zmienianie pewnych
warto&#347;ci jest znacz&#261;c&#261; cz&#281;&#347;ci&#261; pracy kogo&#347;, kto zajmuje si&#281; tym zagadnieniem.
Ostatecznie, kiedy pewna metoda zostanie opracowana to to, co pozostaje praktyk&#261; to
dostosowanie jej do swojego konkretnego przypadku, na co zazwyczaj sk&#322;ada si&#281; w&#322;a&#347;nie
precyzyjny dobór wielu parametrów. Mimo i&#380; nie ma jednego najlepszego kroku, to
istniej&#261; sposoby, które mog&#261; nam pomóc w wyborze takiej sta&#322;ej. Jak my&#347;lisz, w
jakim przedziale powinna si&#281; znale&#378;&#263; wielko&#347;&#263; kroku? Zwyczajna odpowied&#378;
to gdzie&#347; pomi&#281;dzy 0,2 a 0,000001 co jest jednak dosy&#263; du&#380;ym przedzia&#322;em.
Czy mo&#380;esz pomy&#347;le&#263; o dodatkowej technice, która mog&#322;aby nam pomóc w
wyborze kroku? Jednym z istniej&#261;cych rozwi&#261;za&#324; jest tzw. <span 
class="aeb10-x-x-120">planowane zmniejszanie</span>
<span 
class="aeb10-x-x-120">kroku </span>(ang. learning rate scheduling) Istot&#261; tego podej&#347;cia jest zmniejszanie kroku
wraz z up&#322;ywem czasu. Powoduje to du&#380;&#261; eksploracj&#281; na pocz&#261;tku uczenia i coraz
dok&#322;adniejsze przeczesywanie najlepszych cz&#281;&#347;ci przestrzeni pod koniec nauki.
Wielko&#347;&#263; kroku ma te&#380; inn&#261; nazw&#281;, a mianowicie <span 
class="aeb10-x-x-120">wska</span><span 
class="aeb10-x-x-120">&#378;</span><span 
class="aeb10-x-x-120">nik uczenia </span>(ang.
learning rate), poniewa&#380; wp&#322;ywa na tempo nauki. Zatrzymajmy si&#281; nad tym na
chwil&#281;, poniewa&#380; jest to bardzo wa&#380;na zale&#380;no&#347;&#263;. Kiedy dokonujemy du&#380;ych
kroków, to poruszamy si&#281; przez przestrze&#324; szybciej ni&#380; gdyby&#347;my wybrali
mniejszy krok, mo&#380;emy wi&#281;c powiedzie&#263;, &#380;e szybko si&#281; uczymy. Nie odbywa si&#281; to
jednak bez kosztu. Robi&#261;c szybkie post&#281;py, mo&#380;emy nie zauwa&#380;y&#263; drobnych
niedok&#322;adno&#347;ci, jakie maj&#261; miejsce przy okazji. Dlatego, gdy post&#281;p zaczyna male&#263;
najlepiej zmniejszy&#263; wska&#378;nik uczenia i dokona&#263; koniecznych poprawek na
mniejsz&#261; skal&#281;. W naszym przypadku du&#380;y wska&#378;nik uczenia da nam szybk&#261;
popraw&#281;, ale mo&#380;e przeskoczy&#263; ponad pewnymi dobrymi miejscami. Za to ma&#322;y
wska&#378;nik uczenia da nam wolniejsz&#261; popraw&#281;, ale sprawi, &#380;e nie ominiemy &#380;adnych
dobrych regionów. Jedn&#261; z metod po&#322;&#261;czenia tych dwóch korzy&#347;ci jest planowane
zmniejszanie kroku, gdzie wraz z up&#322;ywem czasu lub po zobaczeniu pewnej ilo&#347;ci
przyk&#322;adów wska&#378;nik uczenia zostaje pomniejszony. Mo&#380;emy w pewien sposób
my&#347;le&#263; o tym procesie jak o zmniejszaniu temperatury. Przy du&#380;ej temperaturze
cz&#261;steczka porusza si&#281; bardzo gwa&#322;townie, a wraz ze zmniejszaniem temperatury
cz&#261;stka ogranicza si&#281; do do&#322;ków energetycznych, czyli regionów gdzie jej energia
jest zminimalizowana. Podobny proces mo&#380;emy zaobserwowa&#263; w hutnictwie
gdzie wy&#380;arzanie, polegaj&#261;ce na podgrzaniu i nast&#281;pnym sch&#322;odzeniu materia&#322;u
jest wykorzystywane w celu sprawienia, aby materia&#322; by&#322; bardziej podatny dalszej
obróbce.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-11003r4"></a>
                                                                                    
                                                                                    
<!--l. 114--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 114--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-11004"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;2.4:</span><span  
class="content">Wybór wielko&#347;ci kroku</span></figcaption><!--tex4ht:label?: x1-11003r2 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-11005r11"></a>
<h3 class="sectionHead"><span class="titlemark">2.5   </span> <a 
 id="x1-120005"></a>Plus momentum</h3>
<!--l. 121--><p class="noindent" >Problemem metod gradientu prostego jest to, &#380;e cz&#281;sto nie jest wydajna. &#379;eby
zobaczy&#263; dlaczego, zastanówmy si&#281; nad nast&#281;puj&#261;cym przyk&#322;adem. Znajdujemy
si&#281; w w&#261;skim lekko pochylonym w jedn&#261; stron&#281; w&#261;wozie, z dwóch stron mamy
strome &#347;ciany. &#379;eby zrobi&#263; post&#281;p w takim miejscu, trzeba i&#347;&#263; dnem w&#261;wozu,
ale wyobra&#378;my sobie, &#380;e znajdujemy si&#281; na &#347;cianie takiego w&#261;wozu. Teraz
logicznym wydaje si&#281;, &#380;e trzeba zej&#347;&#263; na dno i i&#347;&#263; dnem takiego w&#261;wozu.
Zobaczmy jednak, jak zachowuje si&#281; algorytm gradientu prostego w takiej sytuacji.
Jak my&#347;lisz, co b&#281;dzie wynikiem jego dzia&#322;ania? Odpowied&#378; brzmi: algorytm
gradientu prostego b&#281;dzie si&#281; porusza&#322; w kierunku przeciwnym do kierunku biegu
w&#261;wozu, poniewa&#380; je&#347;li jest on odpowiednio w&#261;ski, to b&#281;dziemy przeskakiwa&#263; od
razu na przeciwn&#261; &#347;cian&#281;. Kiedy ju&#380; znajdziemy si&#281; na przeciwnej &#347;cianie to
podobnie, w nast&#281;pnej iteracji, przeskoczymy z powrotem na &#347;cian&#281;, z której
zacz&#281;li&#347;my. &#379;eby zobaczy&#263;, dlaczego tak si&#281; dzieje, pomy&#347;l, w jakim kierunku porusza
si&#281; algorytm gradientu prostego. Porusza si&#281; on zawsze w kierunku najwi&#281;kszego
gradientu, inaczej mówi&#261;c w kierunku najwi&#281;kszego spadku. Dla &#347;ciany w&#261;wozu
najwi&#281;kszy spadek jest w dó&#322; w&#261;wozu, a nie w kierunku biegu w&#261;wozu. Niestety
nie b&#281;dziemy si&#281; porusza&#263; w kierunku prawdziwej poprawy warto&#347;ci, a raczej
tymczasowej, która zostanie wymazana poprzez nast&#281;puj&#261;cy za chwil&#281; niechybny
powrót na &#347;cian&#281;, z której zaczynali&#347;my. Nasza droga b&#281;dzie przypomina&#263;
powolne zygzakowanie w poprawnym kierunku. Pochy&#322;o&#347;&#263; w&#261;wozu sprawi co
prawda, &#380;e b&#281;dziemy si&#281; poruszali w dobr&#261; stron&#281;, ale b&#281;dzie to bardzo powolny
post&#281;p. &#379;eby zapobiega&#263; takiemu niekorzystnemu zjawisku wprowadzono p&#281;d (ang.
momentum).<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-12001r5"></a>
                                                                                    
                                                                                    
<!--l. 126--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 126--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-12002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;2.5:</span><span  
class="content">Zachowanie optymalizatora bez dodatku p&#281;du</span></figcaption><!--tex4ht:label?: x1-12001r2 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 131--><p class="noindent" >W fizyce p&#281;d jest zdefiniowany jako:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12003r7"></a>
<!--l. 133--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                     <mi 
>R</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>v</mi>
</math></td><td class="eq-no">(2.7)</td></tr></table>
<!--l. 137--><p class="noindent" >Gdzie <!--l. 137--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>R</mi></mstyle></mstyle></math>
oznacza p&#281;d, <!--l. 137--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>m</mi></mstyle></mstyle></math>
mas&#281; a <!--l. 137--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math>
pr&#281;dko&#347;&#263;.<br 
class="newline" />
</p><!--l. 139--><p class="noindent" >Si&#322;a zdefiniowana jest jako:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12004r8"></a>
<!--l. 141--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                   <mi 
>F</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>m</mi><mi 
>v</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>t</mi>
</math></td><td class="eq-no">(2.8)</td></tr></table>
<!--l. 145--><p class="noindent" >A wi&#281;c jest pochodn&#261; p&#281;du po czasie.<br 
class="newline" />
</p><!--l. 147--><p class="noindent" >Teraz wiedz&#261;c, &#380;e si&#322;a jest zmian&#261; p&#281;du, wyobra&#378;my sobie, &#380;e czas podzielony jest na
ma&#322;e cz&#281;&#347;ci. Wtedy, &#380;eby dosta&#263; p&#281;d w n-tym kroku, nale&#380;a&#322;oby obliczy&#263; warto&#347;&#263;
nast&#281;puj&#261;cego rekursywnego równania:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12005r9"></a>
                                                                                    
                                                                                    
<!--l. 149--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                  <msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <mi 
>F</mi>
</math></td><td class="eq-no">(2.9)</td></tr></table>
<!--l. 153--><p class="noindent" >Poniewa&#380; <!--l. 153--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>F</mi></mstyle></mstyle></math>
jest zmian&#261; w <!--l. 153--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>R</mi></mstyle></mstyle></math>.<br 
class="newline" />
</p><!--l. 155--><p class="noindent" >Jest jeszcze jeden ma&#322;y szczegó&#322;, którego nie bierzemy pod uwag&#281;. W prawdziwym &#347;wiecie
obserwujemy tarcie, które sprawia, &#380;e ka&#380;dy ruch traci swój p&#281;d w miar&#281; up&#322;ywu czasu. To tarcie
nazwiemy <!--l. 155--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x03B1;</mi></mstyle></mstyle></math>
i b&#281;dzie ono opisywa&#263; procent p&#281;du, który nie jest wytracany w jednym kroku czasu.
Równanie zmienia si&#281; nast&#281;puj&#261;co:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12006r10"></a>
<!--l. 157--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03B1;</mi> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <mi 
>F</mi>
</math></td><td class="eq-no">(2.10)</td></tr></table>
<!--l. 161--><p class="noindent" >To jest równanie na p&#281;d w metodzie gradientu, je&#347;li tylko podstawimy odpowiednie warto&#347;ci
za <!--l. 161--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>R</mi></mstyle></mstyle></math> i
<!--l. 161--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>F</mi></mstyle></mstyle></math>.
Przypomnijmy sobie teraz równanie s&#322;u&#380;&#261;ce do znajdywania lepszych punktów
(2.5):
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12007r11"></a>
                                                                                    
                                                                                    
<!--l. 163--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                          <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">-</mo> <mi 
>s</mi><mi 
>t</mi><mi 
>e</mi><mi 
>p</mi><mstyle 
class="text"><mtext  >_</mtext></mstyle><mi 
>s</mi><mi 
>i</mi><mi 
>z</mi><mi 
>e</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi>
</math></td><td class="eq-no">(2.11)</td></tr></table>
<!--l. 167--><p class="noindent" >Teraz, zamiast u&#380;ywa&#263; zmiany <span 
class="aeb10-x-x-120">step_size </span>* <span 
class="aeb10-x-x-120">gradient </span>zast&#261;pmy j&#261; p&#281;dem.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12008r12"></a>
<!--l. 169--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
>
</math></td><td class="eq-no">(2.12)</td></tr></table>
<!--l. 173--><p class="noindent" >Nast&#281;pnie rozwi&#324;my <!--l. 173--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
></mstyle></mstyle></math>
przy pomocy równania (2.9):
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12009r13"></a>
<!--l. 175--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                              <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <mi 
>&#x03B1;</mi> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <mi 
>F</mi>
</math></td><td class="eq-no">(2.13)</td></tr></table>
<!--l. 179--><p class="indent" >   Jak mówili&#347;my, musimy podstawi&#263; odpowiednie warto&#347;ci. P&#281;d
<!--l. 179--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math>
zast&#261;pimy zmienn&#261;, która b&#281;dzie oznacza&#263; zmian&#281; warto&#347;ci punktu
<!--l. 179--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math> dla
poprzedniej iteracji. Jednak ta zmiana jest zale&#380;na od drugiej cz&#281;&#347;ci równania
(<!--l. 179--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x03B1;</mi></mstyle></mstyle> <mo 
class="MathClass-bin">*</mo><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math> +
<!--l. 179--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>F</mi></mstyle></mstyle></math>),
które opisuje t&#281; zmian&#281;, wi&#281;c jak mo&#380;emy zauwa&#380;y&#263; p&#281;d
<!--l. 179--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>R</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
></mstyle></mstyle></math> b&#281;dzie
zale&#380;ny od siebie samego w poprzedniej iteracji. Tak wi&#281;c musimy utrzymywa&#263; w
                                                                                    
                                                                                    
pami&#281;ci drug&#261; cz&#281;&#347;&#263; równania, aby u&#380;y&#263; go ponownie w nast&#281;pnej. Za to
<!--l. 179--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>F</mi></mstyle></mstyle></math> które w
fizyce jest zmian&#261; w p&#281;dzie, zast&#261;pimy zmian&#261; zmiany warto&#347;ci punktu czy inaczej zmian&#261; p&#281;du
dla punktu. <!--l. 179--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>F</mi></mstyle></mstyle></math>
b&#281;dzie wi&#281;c równe gradientowi, który b&#281;dzie okre&#347;la&#322; t&#281; zmian&#281; tak, aby p&#281;d zbli&#380;a&#322; si&#281;
do optymalnego p&#281;du. Równanie (2.9) ze zmienionymi zmiennymi prezentuje si&#281;
nast&#281;puj&#261;co:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12010r14"></a>
<!--l. 181--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                            <mi 
>&#x0394;</mi><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03B1;</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>&#x0394;</mi><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">-</mo> <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi>
</math></td><td class="eq-no">(2.14)</td></tr></table>
<!--l. 185--><p class="noindent" >A równanie (2.12) otrzyma ostateczn&#261; form&#281;:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-12011r15"></a>
<!--l. 187--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                          <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-bin">-</mo> <mi 
>g</mi><mi 
>r</mi><mi 
>a</mi><mi 
>d</mi><mi 
>i</mi><mi 
>e</mi><mi 
>n</mi><mi 
>t</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>&#x03B1;</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>&#x0394;</mi><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
>
</math></td><td class="eq-no">(2.15)</td></tr></table>
<!--l. 191--><p class="noindent" >Gdzie <!--l. 191--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math>
jest warto&#347;ci&#261; wyszukiwania w n-tej iteracji, <span 
class="aeb10-x-x-120">gradient </span>jest gradientem,
<!--l. 191--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x03B1;</mi></mstyle></mstyle></math> jest parametrem &#8216;tarcia&#8217;,
a <!--l. 191--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x0394;</mi><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math> okre&#347;la zmian&#281;
w <!--l. 191--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>p</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math> dla poprzedniej
iteracji. Tu znowu <!--l. 191--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x03B1;</mi></mstyle></mstyle></math>
jest sta&#322;&#261;, któr&#261; mo&#380;emy zmienia&#263;, bo nie ma dla niej jednej najlepszej warto&#347;ci dla
ka&#380;dego problemu. Wszystko co nast&#281;puje po minusie jest identyczne jak prawa strona
równania (2.13) okre&#347;laj&#261;cego nasz p&#281;d.<br 
class="newline" />
                                                                                    
                                                                                    
</p><!--l. 193--><p class="indent" >   Zauwa&#380;my jeszcze jedn&#261; rzecz, która mog&#322;a ci&#281; zaniepokoi&#263;. Przed gradientem
postawili&#347;my znak minus. Wynika to z tego, &#380;e gradient okre&#347;la kierunek najwi&#281;kszego
wzrostu funkcji. Poniewa&#380; my chcemy j&#261; minimalizowa&#263;, to powinni&#347;my si&#281; uda&#263; w
przeciwnym kierunku. Je&#347;li jeszcze kiedy&#347;&#x00A0;zaniepokoisz si&#281; znakiem, to pomy&#347;l czy nie
wynika to w&#322;a&#347;nie z tej zale&#380;no&#347;ci. Wracaj&#261;c do metafory w&#261;wozu, równanie (2.13)
sprawia, &#380;e b&#281;d&#261;c w w&#261;skim przesmyku, b&#281;dziemy dodawa&#263; poprzedni p&#281;d do obecnego.
B&#281;d&#261; si&#281; one nawzajem niwelowa&#263;, poniewa&#380; b&#281;d&#261; skierowane w przeciwnych
kierunkach, a to, co zostanie, b&#281;dzie kierowa&#322;o nas w dó&#322; w&#261;wozu, wyg&#322;adzaj&#261;c nasz&#261;
podró&#380;.<br 
class="newline" />
<a 
 id="x1-12012r12"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">2.6   </span> <a 
 id="x1-130006"></a>SGD</h3>
<!--l. 197--><p class="noindent" >W rozdziale dotycz&#261;cym gradientu prostego ukryli&#347;my jedn&#261; wa&#380;n&#261; informacj&#281;. Chodzi
nam tu o sposób obliczania gradientu. Aby obliczy&#263; gradient, potrzebujemy pewnego
przyk&#322;adu, który da nam przestrze&#324;, nad któr&#261; b&#281;dziemy mogli optymalizowa&#263; nasz
punkt. Jednak cz&#281;sto spotykamy si&#281; z sytuacj&#261;, gdy nie chcemy dopasowa&#263; naszej warto&#347;ci
do jednego przyk&#322;adu, ale jest tych przyk&#322;adów wi&#281;cej. Pomocny w tym procesie jest zbiór
danych.<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-13001r6"></a>
                                                                                    
                                                                                    
<!--l. 202--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 202--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-13002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;2.6:</span><span  
class="content">mini-batch SGD</span></figcaption><!--tex4ht:label?: x1-13001r2 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 207--><p class="noindent" ><span 
class="aeb10-x-x-120">Zbi</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">r danych </span>jest kolekcj&#261; pewnych danych, które maj&#261; ze sob&#261; co&#347; wspólnego. Np.
mo&#380;emy mówi&#263; o zbiorze zdj&#281;&#263; ze &#347;lubu lub o zbiorze nazw ksi&#261;&#380;ek na twojej pó&#322;ce
albo o zbiorze cen pewnych produktów.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-13003r16"></a>
<!--l. 209--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                  <mi 
>D</mi> <mo 
class="MathClass-rel">=</mo> <mrow ><mo 
class="MathClass-open">[</mo><mrow><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mn>3</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>&#x2026;</mi></mrow><mo 
class="MathClass-close">]</mo></mrow>
</math></td><td class="eq-no">(2.16)</td></tr></table>
<!--l. 213--><p class="indent" >   Mo&#380;emy sobie wyobrazi&#263; sytuacj&#281;, w której chcieliby&#347;my, powiedzmy znale&#378;&#263;
najlepsze po&#322;o&#380;enie nie tylko dla naszego domu, ale te&#380; dla wybudowania ca&#322;ego osiedla
mieszkaniowego. Musimy wtedy wzi&#261;&#263; pod uwag&#281; preferencje wszystkich naszych klientów,
a nie tylko nasze w&#322;asne. U&#380;ywaj&#261;c zbioru danych, mogliby&#347;my przechowywa&#263;
preferencje dla wszystkich klientów. Aby zrobi&#263; jeden krok naszego algorytmu gradientu
prostego, musieliby&#347;my obliczy&#263; gradient, u&#380;ywaj&#261;c wszystkich przyk&#322;adów ze zbioru
danych, wi&#281;c liczba oblicze&#324; wzros&#322;aby proporcjonalnie do wielko&#347;ci zbioru danych. W tym
wypadku gradient dla pojedynczego kroku by&#322;by sum&#261; gradientów dla ka&#380;dego przyk&#322;adu.
Mo&#380;esz sobie wyobrazi&#263;, &#380;e mo&#380;e to by&#263; do&#347;&#263; niepraktyczne, je&#347;li zbiór
sk&#322;ada si&#281; z tysi&#281;cy, a nawet milionów przyk&#322;adów. Jak rozwi&#261;za&#263; ten problem,
zmniejszaj&#261;c liczb&#281; koniecznych oblicze&#324;, a jednocze&#347;nie zachowuj&#261;c generalizacj&#281;?
Rozwi&#261;zaniem jest tu wykonanie pojedynczego kroku z jednym przyk&#322;adem, a
nast&#281;pnie przej&#347;cie do innego przyk&#322;adu i wykonanie kroku ju&#380; na nim. Tym
sposobem w pewnym momencie korzystamy z informacji na temat ka&#380;dego przyk&#322;adu,
jednocze&#347;nie oszcz&#281;dzaj&#261;c na obliczeniach. W&#322;a&#347;ciwie takie podej&#347;cie nazywa si&#281;
<span 
class="aeb10-x-x-120">metod&#261; gradientu stochastycznego </span>(ang. stochastic gradient descent) a krótko
SGD. Algorytm ten otrzymuje swoj&#261; nazw&#281; od tak zwanej stochastyczno&#347;ci, czyli
matematycznej nazwy na procesy losowe. W tym przypadku nazwa zwi&#261;zana jest z
losowo&#347;ci&#261; powstaj&#261;c&#261; na skutek u&#380;ywania pojedynczych przyk&#322;adów, które mog&#261;
by&#263; niereprezentatywne dla ca&#322;ego zbioru danych. Widzimy wi&#281;c, &#380;e SGD ma
te&#380; swoje wady. Jakie s&#261; g&#322;ówne ró&#380;nice pomi&#281;dzy u&#380;ywaniem ca&#322;ego zbioru
danych a u&#380;ywaniem pojedynczego przyk&#322;adu? Trenowanie na ca&#322;ym zbiorze danych
jest dok&#322;adniejsze, poniewa&#380; ró&#380;nice mi&#281;dzy pojedynczymi przyk&#322;adami si&#281;
niweluj&#261;, ale jest równie&#380; bardziej kosztowne obliczeniowo. Natomiast u&#380;ywanie
pojedynczego przyk&#322;adu przeciwnie: jest mniej kosztowne obliczeniowo, ale za to
du&#380;o bardziej niedok&#322;adne. Mo&#380;e wi&#281;c mogliby&#347;my znale&#378;&#263; rozwi&#261;zanie, tak
                                                                                    
                                                                                    
aby spotka&#263; si&#281; w po&#322;owie drogi. Trenujmy na kilku przyk&#322;adach wybranych z
naszego zbioru danych. To podej&#347;cie nazywa si&#281; <span 
class="aeb10-x-x-120">mini-batch </span>co z angielskiego
oznacza &#8222;ma&#322;y pakiet&#8221;. Algorytm nazywa si&#281; mini-batch SGD. Czasami dla skrótu
mówi si&#281; na niego SGD, opuszczaj&#261;c pierwszy cz&#322;on, co mo&#380;e by&#263; myl&#261;ce dla
osoby niezaznajomionej z tematem. Takie podej&#347;cie zniweluje fluktuacje w funkcji
warto&#347;ci, które mo&#380;emy obserwowa&#263; w czystym SGD i sprawi, &#380;e uczenie
b&#281;dzie &#322;atwiejsze. Ten algorytm jest jednym z najcz&#281;&#347;ciej stosowanych w AI. Nawet
pomimo tego, &#380;e by&#322; on jednym z pierwszych, które zosta&#322;y wymy&#347;lone, to nadal
jest cz&#281;sto u&#380;ywany i potrafi osi&#261;gn&#261;&#263; najlepsze wyniki w trenowaniu np. sieci
neuronowych.
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p><!--l. 2--><p class="indent" >
                                                                                    
                                                                                    
</p>
   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;3</span><br /><a 
 id="x1-140003"></a>Sieci neuronowe</h2>
<!--l. 5--><p class="noindent" >Sieci neuronowe s&#261; jednym z najgor&#281;tszych tematów w &#347;wiecie sztucznej inteligencji a
mo&#380;e tak&#380;e poza nim. Maj&#261; one proste i eleganckie w&#322;a&#347;ciwo&#347;ci, które zosta&#322;y
zainspirowane my&#347;leniem o podobnych systemach znajduj&#261;cych si&#281; w mózgu. Pomimo
tego, &#380;e ich genez&#261; s&#261; modele mózgu, to teraz wiemy, &#380;e ró&#380;ni&#261; si&#281; one od ich
biologicznych odpowiedników na pewne ogromne sposoby. Na przyk&#322;ad prawdziwe neurony
s&#261; aktywowane inaczej i maj&#261; prawdopodobnie inny mechanizm uczenia si&#281;. Poniewa&#380;
wiedza o mózgu jest ograniczona, nie mo&#380;emy wiedzie&#263;, czy tak jest na pewno. Czy te
ró&#380;nice s&#261; do pogodzenia, nie jest jeszcze pewnym. Wiemy, natomiast &#380;e sieci, które
dzia&#322;aj&#261; na naszych komputerach, mog&#261; osi&#261;ga&#263; dosy&#263; niesamowite wyniki. Jednak nie
by&#322;o tak zawsze. Jeszcze kilkadziesi&#261;t lat temu wiele osób mia&#322;o w&#261;tpliwo&#347;ci na
temat tego, czy sieci neuronowe s&#261; w stanie dokona&#263; niektórych rzeczy. To tak
jakby&#347;my przenie&#347;li si&#281; w czasie do wynalazku silnika. Dla wielu osób w tym
czasie nie by&#322;o zapewne jasne, do czego mo&#380;na go u&#380;y&#263;, a nawet je&#347;li zdawali
sobie spraw&#281; z niektórych zastosowa&#324;, to nie byli sobie w stanie wyobrazi&#263;
innych. Podobnie na pocz&#261;tku badania sztucznej inteligencji nie by&#322;o wiadomo, co da
si&#281; osi&#261;gn&#261;&#263;, a co jest, niemo&#380;liwe stosuj&#261;c te metody. Nie wiedziano nawet
które problemy s&#261; &#322;atwe a które ci&#281;&#380;kie do rozwi&#261;zania. Niektórzy my&#347;leli, &#380;e
rozwi&#261;zanie problemów, które s&#261; ci&#281;&#380;kie dla nas, takich jak ró&#380;niczkowanie, b&#281;dzie
ci&#281;&#380;kie równie&#380; dla maszyn, a problemów &#322;atwych dla nas, jak rozpoznawanie
obiektów, b&#281;dzie dla nich &#322;atwe. Okaza&#322;o si&#281; inaczej. Problem ró&#380;niczkowania zosta&#322;
rozwi&#261;zany do&#347;&#263; szybko przez Jamesa Slagle&#8217;a, który napisa&#322; pierwszy program
obliczaj&#261;cy ca&#322;ki. Co ciekawe Slage by&#322; niewidomy, nie przeszkodzi&#322;o mu to jednak w
napisaniu programu ca&#322;kuj&#261;cego w j&#281;zyku LISP. LISP by&#322; pocz&#261;tkowo popularnym
j&#281;zykiem programowania w kr&#281;gach ludzi zajmuj&#261;cych si&#281; sztuczn&#261; inteligencj&#261;. By&#322;,
mo&#380;na nawet powiedzie&#263;, elitarnym j&#281;zykiem programowania. Dzi&#281;ki swojej prostej
i eleganckiej sk&#322;adni, która przypomina&#322;a operowanie na listach, nowoczesnym
rozwi&#261;zaniom oraz przede wszystkim traktowaniu ka&#380;dego wyra&#380;enia jak symbolu
sta&#322; si&#281; on popularny w kr&#281;gach AI. LISP by&#322; te&#380; nietypowy, gdy&#380; niektóre
wyra&#380;enia, które mo&#380;na naturalnie zapisa&#263; w innych j&#281;zykach, trzeba by&#322;o
napisa&#263; w sposób rekursywny, co stanowi&#322;o dodatkow&#261; trudno&#347;&#263;. LISP nie by&#322;
j&#281;zykiem stworzonym dla sieci neuronowych. Jego wolne dzia&#322;anie w porównaniu do
innych j&#281;zyków tamtego czasu, takich jak C, by&#322;o przeszkod&#261; dla algorytmów
wymagaj&#261;cych szybko&#347;ci obliczeniowej. W tamtym czasie wielkich prze&#322;omów nie to
by&#322;o najwa&#380;niejsze. Konceptualne prze&#322;omy dokonywa&#322;y si&#281; jeden po drugim, a
naukowcy dokonywali wielkich obietnic, poniewa&#380; widzieli ogromny post&#281;p w kilku
formalnych dziedzinach. Problemy takie jak rozpoznawanie obiektów nadal pozostawa&#322;y
nierozwi&#261;zane. Kiedy okaza&#322;o si&#281; niemo&#380;liwym, &#380;eby rozwi&#261;za&#263; inteligencj&#281;
bez wcze&#347;niejszego poradzenia sobie z tymi &#8216;&#322;atwiejszymi&#8217; problemami przysz&#322;a
                                                                                    
                                                                                    
tzw. zima AI (ang. AI winter), kiedy to fundusze na badania zosta&#322;y ograniczone.
Wszyscy byli zawiedzeni tym, co zosta&#322;o osi&#261;gni&#281;te, poniewa&#380; spodziewano si&#281; jeszcze
szybszych post&#281;pów, jednak ukryte problemy dawa&#322;y zna&#263;. Dotkni&#281;ta zosta&#322;a
równie&#380; dziedzina bada&#324; nad sieciami neuronowymi, które w tamtym czasie nie
dawa&#322;y tak niezwyk&#322;ych rezultatów. W konsekwencji tylko kilku najwytrwalszych
naukowców kontynuowa&#322;o badania nad sieciami neuronowymi. Byli to naukowcy z
Kanady i jeden Francuz. W 2019 za badania prowadzone w czasie kiedy nikt nie
wierzy&#322; w sieci neuronowe Hinton, Bengio i LeCun zostali nagrodzeni nagrod&#261;
Turinga. Istnia&#322; te&#380; inny realny problem poza wygórowanymi oczekiwaniami.
Komputery lat 70 by&#322;y du&#380;o wolniejsze ni&#380; obecne. A je&#347;li jest jedna rzecz,
która jest prawdziwa w stosunku do sieci neuronowych to to, &#380;e s&#261; ogromnie
g&#322;odne zasobów. By&#322;o po prostu niemo&#380;liwym, &#380;eby osi&#261;gn&#261;&#263; niektóre z
niezwyk&#322;ych rezultatów, które potrafimy dokona&#263; obecnie na tamtych komputerach.
Dzisiaj sieci neuronowe s&#261; u&#380;ywane we wszelakich rozwi&#261;zaniach, zaczynaj&#261;c od
rozpoznawania liter, znaków, twarzy, przeprowadzania diagnozy medycznej, grania w
gry komputerowe, szachy i Go, po wykonywanie za nas nu&#380;&#261;cych czynno&#347;ci jak
filtrowanie spamu czy wybieranie kolejnego filmu do odtworzenia albo piosenki do
pos&#322;uchania.
<a 
 id="x1-14001r13"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">3.1   </span> <a 
 id="x1-150001"></a>Perceptron</h3>
<!--l. 9--><p class="noindent" >Pomys&#322; stoj&#261;cy za <span 
class="aeb10-x-x-120">perceptronem </span>jest prosty. We&#378;my kilka danych wej&#347;ciowych, po&#322;&#261;czmy
je w pewien sposób i zwró&#263;my warto&#347;&#263; numeryczn&#261;. Je&#347;li ta warto&#347;&#263; jest
wi&#281;ksza ni&#380; zero, to klasyfikujemy dane wej&#347;ciowe jako nale&#380;&#261;ce do klasy 0, w
przeciwnym wypadku klasyfikujemy je jako klas&#281; 1. Na ten pomys&#322; wpad&#322; Frank
Rosenblatt w 1958 roku. Perceptron pocz&#261;tkowo mia&#322; by&#263; nie programem a specjaln&#261;
elektroniczno-elektro-mechaniczn&#261; maszyn&#261; zafundowan&#261; przez ameryka&#324;skie wojsko.
Rosenblatt &#8216;sprzeda&#322;&#8217; wojskowym swój pomys&#322; jako maszyn&#281; do rozpoznawania znaków na
zdj&#281;ciach, cho&#263; oni wi&#261;zali z nim prawdopodobnie du&#380;o wi&#281;ksze nadzieje. Pomy&#347;lmy co
mogliby&#347;my chcie&#263; klasyfikowa&#263;. Mo&#380;emy np. chcie&#263; sprawdzi&#263;, czy na zdj&#281;ciu jest
kot, czy go tam nie ma albo sprawdzi&#263;, czy podana litera to &#8216;A&#8217;, czy nie. Jednak wojskowi
pok&#322;adali zapewne najwi&#281;ksze nadzieje w rozpoznawaniu sprz&#281;tu wojskowego na zdj&#281;ciach.
Jak mia&#322;oby to dzia&#322;a&#263; w perceptronie? Musimy mu najpierw przekaza&#263; nasze
dane jako wej&#347;ciowe, np. je&#347;li chcemy klasyfikowa&#263; zdj&#281;cia, powinni&#347;my mu
dostarczy&#263; list&#281; wszystkich pikseli. Teraz musimy pomy&#347;le&#263;, jak chcemy po&#322;&#261;czy&#263;
wszystkie informacje, które otrzymuje perceptron. Na pocz&#261;tku zmieniamy piksele w
zwi&#261;zane z nimi warto&#347;ci numeryczne, a nast&#281;pnie mno&#380;ymy je przez jak&#261;&#347;
pozytywn&#261; lub negatywn&#261; wag&#281;. Kolejno musimy tylko doda&#263; wszystkie warto&#347;ci,
które otrzymali&#347;my i sprawdzi&#263;, czy ich suma jest wi&#281;ksza, czy mniejsza od
                                                                                    
                                                                                    
0.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-15001r1"></a>
<!--l. 11--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
   <mtable 
class="equation"><mtr><mtd>
   <mtable  
columnalign="right left" class="split">
<mtr class="split-mtr"><mtd 
class="split-mtd">          <mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mn>1</mn><mo 
class="MathClass-punc">,</mo></mtext><mtext class="textrm" mathvariant="normal" ><mstyle&#x00A0;
class="text"><mtext&#x00A0;class="textrm"&#x00A0;mathvariant="normal"&#x00A0;>je&#347;li&#x00A0;&#x00A0;</mtext></mstyle><mi 
>w</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi> <mo 
class="MathClass-rel">&#x003E;</mo> <mn>0</mn></mtd>
</mtr><mtr class="split-mtr"><mtd 
class="split-mtd"> </mtext><mtext class="textrm" mathvariant="normal" ><mstyle&#x00A0;
class="text"><mtext&#x00A0;class="textrm"&#x00A0;mathvariant="normal"&#x00A0;>i&#x00A0;&#x00A0;</mtext></mstyle><mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mn>0</mn></mtext><mtext class="textrm" mathvariant="normal" ><mstyle&#x00A0;
class="text"><mtext&#x00A0;class="textrm"&#x00A0;mathvariant="normal"&#x00A0;>&#x00A0;w&#x00A0;przeciwnym&#x00A0;wypadku</mtext></mstyle></mtd>
   </mtr></mtable>                                                                                 </mtd><mtd>
   </mtd></mtr></mtable>
</math></td><td class="eq-no">(3.1)</td></tr></table>
<!--l. 19--><p class="noindent" >W równaniu (3.1) <!--l. 19--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>w</mi></mstyle></mstyle></math>
s&#261; wagami, przez które mno&#380;ymy dane wej&#347;ciowe
<!--l. 19--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>,
nast&#281;pnie, je&#347;li suma jest wi&#281;ksza ni&#380; 0, zwracamy jeden, inaczej zwracamy
zero.<br 
class="newline" />
</p><!--l. 21--><p class="indent" >   Dzia&#322;anie perceptronu mo&#380;emy zwizualizowa&#263; jako oddzielanie p&#322;aszczyzny prost&#261; lini&#261;.
Z jednej strony takiej linii b&#281;d&#261; przyk&#322;ady pozytywne, czyli te oznaczone jako 1, a z drugiej
negatywne, czyli oznaczone jako 0. Ta linia b&#281;dzie koniecznie przechodzi&#263; przez punkt (0,
0). Mo&#380;esz to sprawdzi&#263;, wybieraj&#261;c jakie&#347; wagi i wstawiaj&#261;c do równania
<!--l. 21--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
równe 0. Je&#347;li nie lubimy tej w&#322;a&#347;ciwo&#347;ci, a nie jest ona najbardziej po&#380;&#261;dana ze
wzgl&#281;du na niemo&#380;liwo&#347;&#263; rozdzielenia pewnych zbiorów danych, to mo&#380;emy
doda&#263; tzw. <span 
class="aeb10-x-x-120">wsp</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">&#322;czynnik koryguj&#261;cy </span>(ang. bias) do ka&#380;dej danej wej&#347;ciowej.
Wi&#281;c:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-15002r2"></a>
                                                                                    
                                                                                    
<!--l. 23--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
   <mtable 
class="equation"><mtr><mtd>
   <mtable  
columnalign="right left" class="split">
<mtr class="split-mtr"><mtd 
class="split-mtd">     <mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mn>1</mn><mo 
class="MathClass-punc">,</mo></mtext><mtext class="textrm" mathvariant="normal" ><mstyle&#x00A0;
class="text"><mtext&#x00A0;class="textrm"&#x00A0;mathvariant="normal"&#x00A0;>je&#347;li&#x00A0;&#x00A0;</mtext></mstyle><mi 
>w</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi> <mo 
class="MathClass-rel">&#x003E;</mo> <mn>0</mn></mtd>
</mtr><mtr class="split-mtr"><mtd 
class="split-mtd"> <mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mn>0</mn></mtext><mtext class="textrm" mathvariant="normal" ><mstyle&#x00A0;
class="text"><mtext&#x00A0;class="textrm"&#x00A0;mathvariant="normal"&#x00A0;>&#x00A0;&#x00A0;w&#x00A0;przeciwnym&#x00A0;wypadku</mtext></mstyle></mtd>
   </mtr></mtable>                                                                                 </mtd><mtd>
   </mtd></mtr></mtable>
</math></td><td class="eq-no">(3.2)</td></tr></table>
<!--l. 31--><p class="noindent" >Jedyna zmiana nast&#281;puje w pierwszej cz&#281;&#347;ci równania (3.2), gdzie dodajemy warto&#347;ci
<!--l. 31--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>b</mi></mstyle></mstyle></math> do
ka&#380;dej danej wej&#347;ciowej. I pami&#281;tamy tu, &#380;e dodawanie nast&#281;puje po mno&#380;eniu.<br 
class="newline" />
</p><!--l. 33--><p class="indent" >   Co pozosta&#322;o nam do zrobienia? Potrzebujemy jako&#347; okre&#347;li&#263; warto&#347;&#263; naszych wag,
ale jest bardzo du&#380;o mo&#380;liwo&#347;ci, na które mogliby&#347;my to zrobi&#263;. Wagi mog&#261; w teorii
przyjmowa&#263; warto&#347;&#263; równ&#261; dowolnej liczbie rzeczywistej. Jednak aby poprawnie
klasyfikowa&#322;y nasze dane, konieczne jest, aby by&#322;y odpowiednio dobrane. Tu z pomoc&#261;
przychodzi rozdzia&#322; 2.X. Mo&#380;emy po prostu u&#380;y&#263; algorytmu SGD na przyk&#322;adach
zdj&#281;&#263; z kotami. &#379;eby mog&#322;o to jednak zadzia&#322;a&#263;, potrzebna jest nam funkcja
warto&#347;ci, która b&#281;dzie okre&#347;la&#263;, jak dobrze zaklasyfikowali&#347;my dany przyk&#322;ad. Jak
dok&#322;adnie b&#281;dzie wygl&#261;da&#263; nasza funkcja warto&#347;ci w tym przypadku? Funkcj&#261;
warto&#347;ci b&#281;dzie dystans pomi&#281;dzy przyk&#322;adem a <span 
class="aeb10-x-x-120">granic&#261; decyzyjn&#261;</span>, tutaj nasz&#261; prost&#261;
<!--l. 33--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mn>0</mn></mstyle></mstyle></math>.
Dystans ten pomno&#380;ymy przez 1, je&#347;li zaklasyfikowali&#347;my przyk&#322;ad poprawnie i -1, je&#347;li
zrobili&#347;my to b&#322;&#281;dnie. Zauwa&#380;my, &#380;e warto&#347;&#263; funkcji warto&#347;ci zale&#380;y od odleg&#322;o&#347;ci
przyk&#322;adu od prostej. Sprawia to, &#380;e perceptron próbuje znale&#378;&#263; najlepsz&#261; tak&#261; prost&#261;,
a tak&#380;e pomaga w uczeniu, poprzez pokazywanie jak daleko nasz przyk&#322;ad znajduje si&#281; od
bycia &#378;le zaklasyfikowanym. Pozostaje nam doda&#263; ostatni&#261; cz&#281;&#347;&#263;. Mogliby&#347;my, co
prawda, zrobi&#263; to, co opisali&#347;my, ale by&#322;oby koniecznym u&#380;ywa&#263; wszystkich
przyk&#322;adów do obliczania jednego kroku. Dzieje si&#281; tak, poniewa&#380; nie mamy
sposobu, aby zmieni&#263; wynik klasyfikacji za pomoc&#261; pojedynczego przyk&#322;adu. Mo&#380;e
nam si&#281; b&#322;&#281;dnie wydawa&#263;, &#380;e SGD rozwi&#261;zuje ten problem. Mo&#380;emy przecie&#380;
trenowa&#263; po kolei na kolejnych przyk&#322;adach, jednak musimy powiedze&#263;, &#380;e
SGD nie wykorzystuje informacji, o tym, jak mocno dany piksel si&#281; &#8216;&#347;wieci&#8217; do
poprawy klasyfikacji. A zauwa&#380;my, &#380;e obecno&#347;&#263; danego piksela o okre&#347;lonym
kolorze mo&#380;e &#347;wiadczy&#263; o obecno&#347;ci np. kota. SGD z funkcj&#261; warto&#347;ci, któr&#261;
opisali&#347;my, spróbuje tylko znale&#378;&#263; odpowiednie wagi, które prowadz&#261; do najlepszej
klasyfikacji, nie we&#378;mie natomiast pod uwag&#281; jakie elementy wej&#347;ciowe przyczyni&#322;y
si&#281; do osi&#261;gni&#281;cia rezultatu. SGD zmienia wagi na korzystniejsze, patrz&#261;c si&#281; na
przyk&#322;ady tylko aby okre&#347;li&#263; funkcj&#281; warto&#347;ci, poza tym skupia si&#281; na zmienialnych
                                                                                    
                                                                                    
parametrach czyli wagach. Chcemy aby nasze rozwi&#261;zanie nie zmienia&#322;o, w sposób
&#347;lepy wag, tylko bra&#322;o pod uwag&#281; to, w jaki sposób dane wej&#347;ciowe mog&#261; by&#263;
skorelowane z klasyfikacj&#261;. Na pomoc przychodzi <span 
class="aeb10-x-x-120">regu&#322;a aktualizacji </span>perceptronu
(ang. update rule). Jest ona jedn&#261; z najciekawszych jego cz&#281;&#347;ci. Mówi nam ona,
&#380;e:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-15003r3"></a>
<!--l. 35--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                      <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi> <mo 
class="MathClass-bin">+</mo> <mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">+</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>y</mi> <mo 
class="MathClass-bin">-</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>w</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi>
</math></td><td class="eq-no">(3.3)</td></tr></table>
<!--l. 39--><p class="noindent" >Gdzie <!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> s&#261; wagami
w kroku <!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>t</mi></mstyle></mstyle></math>,
<!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi> <mo 
class="MathClass-bin">-</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>w</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> jest ró&#380;nic&#261; mi&#281;dzy
oczekiwanym rezultatem <!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>
a otrzymanym <!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>w</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mstyle></mstyle></math>
a <!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> jest
warto&#347;ci&#261; wej&#347;cia.<br 
class="newline" />
</p><!--l. 41--><p class="indent" >   Wszystkie elementy maj&#261; pewien sens, w &#347;wietle tego, o czym mówili&#347;my.
Zastosowali&#347;my regu&#322;&#281; rekurencyjn&#261; do aktualizacji wag. Do tego zmieniamy
je o ró&#380;nic&#281; mi&#281;dzy oczekiwanym wyj&#347;ciem a otrzymanym, u&#380;ywaj&#261;c
poj&#281;cia granicy decyzyjnej. Jedyne czego nie wiemy, to, sk&#261;d pojawi&#322;o si&#281;
<!--l. 41--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> na
ko&#324;cu równania. Mo&#380;emy pomy&#347;le&#263; o sytuacjach, w których chcieliby&#347;my
zwi&#281;kszy&#263; zmian&#281;, któr&#261; aplikujemy do naszych wag. Co si&#281; dzieje, gdy zwi&#281;kszamy j&#261; gdy
<!--l. 41--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> jest du&#380;e i
zmniejszamy gdy <!--l. 41--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
jest ma&#322;e? Zmiana b&#281;dzie wi&#281;ksza przy wi&#281;kszych warto&#347;ciach tej zmiennej, ale
ca&#322;kowita zmiana zale&#380;y te&#380; od ró&#380;nicy pomi&#281;dzy spodziewanym a otrzymanym
wynikiem, czyli od b&#322;&#281;du przewidywania. A wi&#281;c zmiana wag b&#281;dzie wzmacniana, gdy
jednocze&#347;nie b&#322;&#261;d i wej&#347;cie b&#281;d&#261; du&#380;e. Je&#347;li taka sytuacja ma miejsce, to znaczy, &#380;e
<!--l. 41--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
jest dobrym predyktorem tej ró&#380;nicy, a wi&#281;c waga odpowiadaj&#261;ca temu
<!--l. 41--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
                                                                                    
                                                                                    
powinna by&#263; zmieniona tak, aby by&#322;a bardziej receptywna na to wej&#347;cie. To
w&#322;a&#347;nie osi&#261;ga regu&#322;a aktualizacyjna perceptronu. Jest to jeden z najwa&#380;niejszych
pomys&#322;ów dotycz&#261;cych sieci neuronowych. U&#380;ywaj&#261;c tej regu&#322;y, szukamy danych
wej&#347;ciowych, które dobrze przewiduj&#261; b&#322;&#261;d, a wi&#281;c pomagaj&#261; w otrzymaniu poprawnego
wyniku.<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-15004r1"></a>
                                                                                    
                                                                                    
<!--l. 46--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 46--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-15005"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;3.1:</span><span  
class="content">Perceptron</span></figcaption><!--tex4ht:label?: x1-15004r3 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 51--><p class="indent" >   Czy wiedz&#261;c wszystko, co zosta&#322;o zawarte w tym rozdziale, mo&#380;emy i&#347;&#263; i
próbowa&#263; klasyfikowa&#263; koty? Prawdopodobnie nie. Mimo i&#380; perceptron by&#322;
zaprojektowany, by klasyfikowa&#263; obrazy, jest on do&#347;&#263; z&#322;y w tym zadaniu.
Jedyne co robi perceptron, to tworzy oddzielaj&#261;c&#261; przyk&#322;ady p&#322;aszczyzn&#281; w
<!--l. 51--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
wymiarowej przestrzeni. Taka p&#322;aszczyzna oddzielaj&#261;ca jest zbyt ma&#322;o skomplikowana, aby
przedstawi&#263; wi&#281;kszo&#347;&#263; ró&#380;nic mi&#281;dzy przyk&#322;adami np. kotów. Perceptron mo&#380;e by&#263;
bardziej predysponowany, do powiedzmy, klasyfikacji domów na te zawieraj&#261;ce basen i te go
nie posiadaj&#261;ce, u&#380;ywaj&#261;c do tego celu informacji na temat ceny, metra&#380;u i dystansu
do centrum miasta. Je&#347;li chodzi natomiast o bardziej z&#322;o&#380;one zastosowania,
perceptron jest przestarza&#322;y, maj&#261;c na uwadze obecne standardy. Mo&#380;e on mie&#263;
dosy&#263; du&#380;e problemy z pewnymi specjalnie wybranymi, ale bardzo prostymi
funkcjami takimi jak XOR (XOR jest funkcj&#261; która przyjmuje dwa argumenty,
oba z nich s&#261; 0 albo 1, i zwraca 1, je&#347;li wej&#347;cia s&#261; ró&#380;ne i 0 w przeciwnym
przypadku). W roku 1969 Marvin Minsky i Seymour Papert wydali s&#322;ynn&#261; ksi&#261;&#380;k&#281; o
nazwie &#8222;Perceptrons&#8221;, która matematycznie udowadnia&#322;a, &#380;e perceptron nie
jest w stanie dzia&#322;a&#263; jak bramka XOR, co spowodowa&#322;o w tamtym czasie spadek
zainteresowania rozwi&#261;zaniami takimi jak perceptron, poniewa&#380; wydawa&#322;o si&#281;, &#380;e
udowodniono, &#380;e sieci typu perceptron maj&#261; pewne nierozwi&#261;zywalne ograniczenia z nimi
zwi&#261;zane.
<a 
 id="x1-15006r15"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">3.2   </span> <a 
 id="x1-160002"></a>Neurony</h3>
<!--l. 57--><p class="noindent" >O neuronach wiemy, wydaje si&#281; nam, intuicyjnie du&#380;o, przecie&#380; towarzysz&#261; nam ka&#380;dego
dnia. Jednak niestety &#380;aden z nich nie raczy&#322; si&#281; nam przedstawi&#263; i obja&#347;ni&#263; sposobu
swojego dzia&#322;ania. Pomog&#322;oby to nam zapewne w podejmowaniu lepszych decyzji, je&#347;li
wiedzieliby&#347;my, z jakich cz&#281;&#347;ci sk&#322;ada si&#281; nasz mózg. Jednak przy braku takich kurtuazji
pozostaje si&#281; nam zda&#263; na nasze w&#322;asne badania i dociekania na ten temat. W
poszukiwaniu wyja&#347;nienia wewn&#281;trznego dzia&#322;ania mózgu ludzie stworzyli modele tego, co
jest w &#347;rodku. Jeden z najprostszy takich modeli by&#322; u&#380;ywany w perceptronie, który
opisali&#347;my poprzednio. Nie b&#281;dziemy tu opisywa&#263; takich modeli prawdziwych neuronów
ze wzgl&#281;du na ortogonalno&#347;&#263; takiego przedsi&#281;wzi&#281;cia oraz brak wiedzy autora
na ten temat. Co jednak zrobimy, to opiszemy modele u&#380;ywane w sztucznych
sieciach neuronowych. Nale&#380;y zaznaczy&#263;, &#380;e te modele nie s&#261; identyczne i, wed&#322;ug
naszej wiedzy, ró&#380;ni&#261; si&#281; od siebie w znacz&#261;cy sposób. Przejd&#378;my wi&#281;c do
opisu wytworu naszej wyobra&#378;ni. Ka&#380;dy sztuczny neuron posiada pewn&#261; liczb&#281;
<!--l. 57--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
wej&#347;&#263;, które zazwyczaj s&#261; liczbami rzeczywistymi. Celem takiego neuronu jest dokonanie
                                                                                    
                                                                                    
pewnej transformacji tych danych wej&#347;ciowych. Mo&#380;emy niejako my&#347;le&#263; o
dzia&#322;aniu pojedynczego neuronu jak o wyniku dzia&#322;ania perceptronu, który klasyfikuje
dane, które otrzymuje na pewne klasy. To by&#322; najpopularniejszy pogl&#261;d, na to,
jak powinien dzia&#322;a&#263; neuron jeszcze kilkadziesi&#261;t lat temu. Zazwyczaj klas, na
które neuron mia&#322; klasyfikowa&#263; wej&#347;cie, by&#322;o dwie. Jedna dla stanu aktywnego a
druga dla stanu nieaktywnego. W ten sposób mia&#322;a by&#263; oddana w&#322;a&#347;ciwo&#347;&#263;
prawdziwych neuronów, które albo s&#261;, albo nie s&#261; aktywne w zale&#380;no&#347;ci od
wej&#347;cia. W nast&#281;pnym podrozdziale zobaczymy jak po&#322;&#261;czenie neuronu z funkcj&#261;
aktywacji, mo&#380;e da&#263; podobny wynik. Jednak podstawow&#261; ró&#380;nic&#261; mi&#281;dzy
perceptronem a neuronami jest to, &#380;e te drugie, jak mo&#380;esz si&#281; domy&#347;la&#263;, &#322;&#261;czymy w
wi&#281;ksze sieci, sk&#322;adaj&#261;ce si&#281; z wielu neuronów. Te wi&#281;ksze sieci s&#261; podstaw&#261; pot&#281;gi
neuronów. Tak jak to zosta&#322;o udowodnione w komputerach, u mrówek czy u
ludzi, nie si&#322;a pojedynczej jednostki decyduje o sile systemu, lecz raczej zbiorowe,
skoordynowane dzia&#322;anie. Sieci neuronów wykorzystuj&#261; efekt sieci i skali, aby si&#281;
wzajemnie wzmacnia&#263;. Pomimo &#380;e dzia&#322;anie jednego neuronu jest proste i &#322;atwe do
opisania to dzia&#322;anie ich grup daje niespodziewane wyniki i jest ci&#281;&#380;kie do uj&#281;cia
matematycznymi wyra&#380;eniami w sposób przejrzysty dla cz&#322;owieka. O tym te&#380; powiemy w
nast&#281;puj&#261;cych podrozdzia&#322;ach. Wracaj&#261;c do dzia&#322;ania neuronu, zazwyczaj ka&#380;de wej&#347;cie
<!--l. 57--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> zostaje na pocz&#261;tku
pomno&#380;one przez wag&#281; <!--l. 57--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>w</mi></mstyle></mstyle></math>
, nast&#281;pnie dodajemy wspó&#322;czynnik koryguj&#261;cy
<!--l. 57--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>b</mi></mstyle></mstyle></math>,
zupe&#322;nie jak w perceptronie, i sumujemy wszystkie rezultaty.<br 
class="newline" />
</p>
   <table class="equation"><tr><td> <a 
 id="x1-16001r4"></a>
<!--l. 59--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                  <mi 
>u</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>w</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.4)</td></tr></table>
<!--l. 63--><p class="indent" >   Sumuj&#261;c wszystkie warto&#347;ci <!--l. 63--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>w</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mstyle></mstyle></math>
otrzymujemy pewien wynik <!--l. 63--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>u</mi></mstyle></mstyle></math>.
Mogliby&#347;my go uzna&#263; za wynik dzia&#322;ania neuronu, jednak to znaczy&#322;oby, &#380;e
wynikiem mog&#322;aby by&#263; dowolna liczba, co niekoniecznie jest wskazane. Pomy&#347;lmy,
&#380;e taka liczba mog&#322;aby by&#263; dowolnie ma&#322;a lub du&#380;a, co sprawia&#322;oby nie tylko
                                                                                    
                                                                                    
problemy z przetworzeniem jej przez komputer, ale tak&#380;e mog&#322;aby niszczy&#263;
wyniki dzia&#322;ania wielu innych neuronów, je&#347;li zosta&#322;aby u&#380;yta wraz z ich
wynikami do dalszych oblicze&#324;. Z tego powodu chcemy, aby nasza warto&#347;&#263;
<!--l. 63--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>u</mi></mstyle></mstyle></math>
zosta&#322;a przetworzona przez tak zwan&#261; <span 
class="aeb10-x-x-120">funkcj&#281; aktywacji</span>. Jest ona zazwyczaj nieliniowa,
poniewa&#380; nie chcemy, aby nasz neuron zachowywa&#322; si&#281; jak perceptron, to znaczy zawsze
dzieli&#322; przestrze&#324; prost&#261; lini&#261;. Je&#347;li u&#380;yjemy funkcji nieliniowej jako funkcji
aktywacji, to podzia&#322; przestrzeni b&#281;dzie móg&#322; by&#263; du&#380;o bardziej z&#322;o&#380;ony. Ta
nieliniowo&#347;&#263; wprowadzona przez funkcj&#281; aktywacji sprawi, &#380;e podzia&#322; b&#281;dzie nieliniowy, a
wi&#281;c kilka po&#322;&#261;czonych ze sob&#261; neuronów b&#281;dzie mog&#322;o stworzy&#263; du&#380;o bardziej
skomplikowany podzia&#322; przestrzeni, ni&#380; taki, który mogliby&#347;my otrzyma&#263; bez funkcji
aktywacji.<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-16002r2"></a>
                                                                                    
                                                                                    
<!--l. 68--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 68--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-16003"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;3.2:</span><span  
class="content">Neuron</span></figcaption><!--tex4ht:label?: x1-16002r3 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-16004r16"></a>
<h3 class="sectionHead"><span class="titlemark">3.3   </span> <a 
 id="x1-170003"></a>Funkcje aktywacji</h3>
<!--l. 76--><p class="noindent" >Funkcja aktywacji <!--l. 76--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x03D5;</mi></mstyle></mstyle></math>
bierze jako wej&#347;cie <!--l. 76--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>u</mi></mstyle></mstyle></math>
i zwraca wyj&#347;cie neuronu.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-17001r5"></a>
<!--l. 78--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                      <mi 
>y</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>u</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.5)</td></tr></table>
<!--l. 82--><p class="noindent" >Wszystkie równania na neuron przedstawiaj&#261; si&#281; nast&#281;puj&#261;co:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-17002r6"></a>
<!--l. 84--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                  <mi 
>u</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>w</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.6)</td></tr></table>
   <table class="equation"><tr><td> <a 
 id="x1-17003r7"></a>
<!--l. 87--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                      <mi 
>y</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>u</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.7)</td></tr></table>
                                                                                    
                                                                                    
<!--l. 91--><p class="noindent" >Pozostaje nam tylko doda&#263; jakiej funkcji aktywacji nale&#380;y u&#380;ywa&#263;. Funkcj&#261;, która by&#322;a
najbardziej popularna na pocz&#261;tku wiedzy o sieciach neuronowych by&#322;a <span 
class="aeb10-x-x-120">funkcja sigmoidalna</span>
zdefiniowana jako:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-17004r8"></a>
<!--l. 93--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <mi 
>S</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mn>1</mn><mo 
class="MathClass-bin">&#x2215;</mo><mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>1</mn> <mo 
class="MathClass-bin">-</mo> <msup><mrow 
><mi 
>e</mi></mrow><mrow 
><mo 
class="MathClass-bin">-</mo><mi 
>x</mi></mrow></msup 
></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.8)</td></tr></table>
<!--l. 97--><p class="indent" >   Ta funkcja ma kszta&#322;t litery &#8216;S&#8217;. Zmienia si&#281; ona bardzo ma&#322;o na ko&#324;cach, a gradient jest
najwi&#281;kszy blisko zera. Zwraca ona warto&#347;ci pomi&#281;dzy 0 a 1, z tym &#380;e wi&#281;kszo&#347;&#263;
warto&#347;ci le&#380;y blisko 0 lub 1 ze wzgl&#281;du na kszta&#322;t funkcji. By&#322;o to pocz&#261;tkowo interesuj&#261;c&#261;
w&#322;a&#347;ciwo&#347;ci&#261; ze wzgl&#281;du na podobie&#324;stwo do neuronów w mózgu, które albo s&#261; w
stanie aktywacji, albo nie daj&#261; &#380;adnego sygna&#322;u. Dodatkowym plusem jest nieliniowo&#347;&#263;
tej funkcji. Pochodna funkcji sigmoidalnej jest prosta i jest to niew&#261;tpliwie silna
strona ponad niektórymi konkurentami. Okazuje si&#281; jednak, &#380;e jest pewien du&#380;y
problem z t&#261; funkcj&#261;. Staje si&#281; ona w &#322;atwy sposób nasycona, co znaczy, &#380;e je&#347;li
<!--l. 97--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> zmienia si&#281;
znacz&#261;co to <!--l. 97--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>
zmienia si&#281; bardzo ma&#322;o. Nasycenie w funkcji sigmoidalnej ma miejsce przy jej
ko&#324;cach. Kiedy takie nasycone funkcje zostaj&#261; przez siebie pomno&#380;one z wynikiem
znajduj&#261;cym si&#281; blisko zera, sprawia to, &#380;e warto&#347;&#263; numeryczna staje si&#281; bardzo ma&#322;a.
Poniewa&#380; komputery nie radz&#261; sobie z arbitraln&#261; dok&#322;adno&#347;ci&#261;, prowadzi to do
niedok&#322;adno&#347;ci w obliczeniach gradientu podczas trenowania sieci neuronowej. Problemy
z tego powodu nazywane s&#261; <span 
class="aeb10-x-x-120">znikaj&#261;cym gradientem </span>(ang. vanishing gradient).
Mo&#380;e te&#380; wyst&#261;pi&#263; przeciwie&#324;stwo znikaj&#261;cego gradientu, kiedy du&#380;e wyniki
funkcji s&#261; mno&#380;one przez siebie, to mo&#380;e to prowadzi&#263; do eksplozji gradientu.
Taka sytuacja jednak nie b&#281;dzie mie&#263; miejsca przy sigmoidalnej funkcji aktywacji,
poniewa&#380; jej warto&#347;&#263; jest ograniczona do 1, natomiast przy innych funkcjach
nieograniczonych z góry, jest to bardzo realne zagro&#380;enie. Inn&#261; cz&#281;sto u&#380;ywan&#261; funkcj&#261;
jest ReLU (ang. rectifier linear unit), ma ona skomplikowan&#261; nazw&#281; i bardzo prost&#261;
definicj&#281;:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-17005r9"></a>
                                                                                    
                                                                                    
<!--l. 99--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <mi 
>R</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>a</mi><mi 
>x</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>0</mn><mo 
class="MathClass-punc">,</mo><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.9)</td></tr></table>
                                                                                    
                                                                                    
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-17006r3"></a>
                                                                                    
                                                                                    
<!--l. 106--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 106--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-17007"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;3.3:</span><span  
class="content">Funkcje aktywacji</span></figcaption><!--tex4ht:label?: x1-17006r3 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 111--><p class="indent" >   Jej warto&#347;&#263; wynosi 0 dla negatywnych warto&#347;ci
<!--l. 111--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> i jest równa
dok&#322;adnie <!--l. 111--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
dla warto&#347;ci pozytywnych. W wi&#281;kszo&#347;ci sytuacji powinno si&#281; u&#380;ywa&#263; ReLU zamiast
funkcji sigmoidalnej, poniewa&#380; daje ona lepsze empiryczne rezultaty. Ta funkcja
ma dodatkow&#261; w&#322;a&#347;ciwo&#347;&#263;, b&#281;d&#261;c bardzo szybk&#261; do policzenia, co oszcz&#281;dza
cykle procesora. Mo&#380;esz sobie my&#347;le&#263;: Poczekaj chwil&#281;, czy ta funkcja nie jest
przypadkiem liniowa? Odpowied&#378; brzmi: nie, nie jest liniowa ze wzgl&#281;du na to, &#380;e
jest ona liniowa tylko w pewnych jej cz&#281;&#347;ciach, które s&#261; po&#322;&#261;czone w punkcie
(0, 0). Okazuje si&#281;, &#380;e to wystarcza, aby zapewni&#263; bogate zachowanie dla ca&#322;ej
sieci. Istniej&#261; pewne wariacje na temat funkcji ReLU. Krótko opiszemy dwie z
nich.<br 
class="newline" />
</p><!--l. 113--><p class="noindent" >Nieszczelne ReLU (ang. leaky ReLU) jest jednostk&#261; ReLU, która jest &#8216;nieszczelna&#8217;, to znaczy,
&#380;e je&#347;li <!--l. 113--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
jest mniejsze od zera, to nie zwraca ona 0 tylko zamiast tego
<!--l. 113--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> * 0,01, lub inn&#261; ma&#322;&#261;
warto&#347;&#263; zale&#380;n&#261; od <!--l. 113--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>.<br 
class="newline" />
</p><!--l. 115--><p class="noindent" >Parametryczne ReLU (ang. parametric ReLU) jest taki sam jak nieszczelne ReLU z t&#261; ma&#322;&#261; ró&#380;nic&#261;, &#380;e
nie mno&#380;ymy <!--l. 115--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> przez
0,01 tylko przez <!--l. 115--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>a</mi></mstyle></mstyle></math>
które jest znalezione w procesie uczenia. To ko&#324;czy nasz krótki przegl&#261;d funkcji
aktywacji.<br 
class="newline" />
</p><!--l. 117--><p class="indent" >   Funkcja sigmoidalna i ReLU stanowi&#261; dwie najwa&#380;niejsze opcje, które mamy do
wyboru tworz&#261;c model sieci neuronowej. Poza tym istniej&#261; oczywi&#347;cie inne mo&#380;liwo&#347;ci,
takie jak, chocia&#380;by tanges hiperboliczny. Faktem jest natomiast, &#380;e zazwyczaj dziel&#261;
kluczowe w&#322;a&#347;ciwo&#347;ci, silnie oraz s&#322;abe strony z jedn&#261; z dwóch opisanych tu funkcji. Z
tego w&#322;a&#347;nie powodu ograniczyli&#347;my list&#281; funkcji aktywacji do dwóch najwa&#380;niejszych
przyk&#322;adów. Dodajmy, &#380;e perceptron posiada&#322; swoj&#261; w&#322;asn&#261; inn&#261; od tych tu opisanych
funkcj&#281; aktywacji. Mo&#380;esz teraz powróci&#263; do rozdzia&#322;u o perceptronie i zobaczy&#263; czy j&#261;
rozpoznasz.
<a 
 id="x1-17008r17"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">3.4   </span> <a 
 id="x1-180004"></a>Wszystko razem</h3>
<!--l. 122--><p class="noindent" >Teraz pokryli&#347;my wszystkie cz&#281;&#347;ci budulcowe potrzebne do stworzenia sieci neuronowej.
Mo&#380;esz si&#281; siebie teraz pyta&#263;: Zaczekaj, czy nie mówili&#347;my tylko o neuronach? Tak
                                                                                    
                                                                                    
rozmawiali&#347;my tylko o neuronach, ale pi&#281;kn&#261; rzecz&#261; dotycz&#261;c&#261; sieci neuronowych jest to,
&#380;e potrzebuj&#261; jako budulca tylko neuronów. Nie oznacza to, jednak &#380;e nie pozosta&#322;o nam
nic do zrobienia. Musimy si&#281; zastanowi&#263; nad jedn&#261; kluczow&#261; kwesti&#261;. Jak po&#322;&#261;czymy pewn&#261;
liczb&#281; neuronów w ca&#322;o&#347;&#263;? Jest naprawd&#281; wiele mo&#380;liwo&#347;ci, na które mogliby&#347;my
tego dokona&#263;, bo ka&#380;de wyj&#347;cie neuronu mo&#380;emy w teorii po&#322;&#261;czy&#263; z wej&#347;ciem
dowolnego innego neuronu. Mogliby&#347;my nawet po&#322;&#261;czy&#263; wyj&#347;cie naszego neuronu z jego
wej&#347;ciem, tworz&#261;c swego rodzaju p&#281;tl&#281; zwrotn&#261;. Mimo tej dowolno&#347;ci istniej&#261; pewne
rodzaje neuronów, które si&#281; zwyczajowo wyró&#380;nia. S&#261; to neurony, które maj&#261; troch&#281;
inne zastosowania. Nazywane s&#261; one <span 
class="aeb10-x-x-120">neuronami wej</span><span 
class="aeb10-x-x-120">&#347;</span><span 
class="aeb10-x-x-120">cia </span>i <span 
class="aeb10-x-x-120">wyj</span><span 
class="aeb10-x-x-120">&#347;</span><span 
class="aeb10-x-x-120">cia </span>(ang. input and output
neurons). Widzimy, wi&#281;c &#380;e te same cz&#281;&#347;ci sk&#322;adowe w sieci neuronowej mog&#261;
pe&#322;ni&#263; ró&#380;ne funkcje. Neurony wej&#347;cia ró&#380;ni&#261; si&#281; od innych tylko tym, &#380;e nie
bior&#261; informacji od innych neuronów, ale bezpo&#347;rednio z danych wej&#347;ciowych.
Neurony wyj&#347;cia za to, s&#261; cz&#281;sto ró&#380;nego, specjalnego typu, np. pozostawione
bez funkcji aktywacji lub ich wynik jest tak zmieniony, aby zwraca&#322;y dystrybucj&#281;
prawdopodobie&#324;stwa. Pozwala to na swego rodzaju sformatowanie danych wyj&#347;ciowych,
aby nie by&#322;y one ograniczone przez funkcj&#281; aktywacji. Pomy&#347;lmy teraz jak w
sensowny sposób po&#322;&#261;czy&#263; wiele neuronów w ca&#322;o&#347;&#263;. Je&#347;li &#322;&#261;czyliby&#347;my je
losowo, to cz&#281;&#347;&#263; po&#322;&#261;cze&#324; by&#322;aby odleg&#322;ych, to znaczy znacz&#261;co zmniejsza&#322;aby
odleg&#322;o&#347;&#263; na grafie pomi&#281;dzy danymi neuronami. Sprawi&#322;oby to, &#380;e w sieci
nie istnia&#322;abo poj&#281;cie lokalno&#347;ci, poniewa&#380; ka&#380;dy neuron by&#322;by po&#322;&#261;czony z
odleg&#322;ymi, jak i bliskimi neuronami. Zazwyczaj jednak neurony uk&#322;adamy w tak zwane
<span 
class="aeb10-x-x-120">warstwy </span>(ang. layers). To znaczy, &#380;e s&#261; zapakowane jeden obok drugiego w pewnej
kolejno&#347;ci.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-18001r10"></a>
<!--l. 124--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                              <mi 
>w</mi><mi 
>a</mi><mi 
>r</mi><mi 
>s</mi><mi 
>t</mi><mi 
>w</mi><mi 
>a</mi> <mo 
class="MathClass-rel">=</mo> <mrow ><mo 
class="MathClass-open">[</mo><mrow><msub><mrow 
><mi 
>n</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>n</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>n</mi></mrow><mrow 
><mn>3</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>&#x2026;</mi></mrow><mo 
class="MathClass-close">]</mo></mrow>
</math></td><td class="eq-no">(3.10)</td></tr></table>
<!--l. 128--><p class="indent" >   W jednej sieci neuronowej mo&#380;emy mie&#263; wiele takich warstw. W tym momencie
pojawia si&#281; oczywiste pytanie: Jak wiele ma by&#263; takich warstw i w jaki sposób maj&#261; by&#263;
po&#322;&#261;czone? Niestety na pierwsze pytanie musimy odpowiedzie&#263; tak jak poprzednio w takich
sytuacjach. To zale&#380;y od sytuacji. Nie ma jednej najlepszej liczby warstw ani liczby
neuronów w warstwie. To kolejna rzecz, któr&#261; mo&#380;emy zmienia&#263;, tworz&#261;c nasz model.
Na pytanie na temat po&#322;&#261;czenia nale&#380;a&#322;oby w&#322;a&#347;ciwie te&#380; odpowiedzie&#263;, &#380;e to zale&#380;y
                                                                                    
                                                                                    
od specyfiki architektury, np. istniej&#261; specjalne rozwi&#261;zania przeznaczone do rozpoznawania
obrazu. Nazywaj&#261; si&#281; one CNN (ang. convolutional neural network) i wykorzystuj&#261;
konwolucje. O konwolucji mo&#380;emy my&#347;le&#263; jak o pewnym okienku z okre&#347;lonymi wagami
dla ró&#380;nych pozycji w okienku. Takie okienko jest przesuwane przez obraz tak,
&#380;e w ró&#380;nych momentach zapisywane s&#261; wyniki z ró&#380;nych cz&#281;&#347;ci obrazu
przetworzonej przez konwolucj&#281;. Te wyniki tworz&#261; jakby nowy obraz, na których znowu
u&#380;ywane s&#261; konwolucje. Wagi w konwolucjach podlegaj&#261; normalnemu uczeniu
podobnie jak w normalnych sieciach neuronowych. Takie konwolucje maj&#261; w teorii
znajdywa&#263; pewne powtarzaj&#261;ce si&#281; elementy na zdj&#281;ciu, takie jak kraw&#281;dzie, rogi a w
wy&#380;szych warstwach mo&#380;e np. rozpoznaj&#261; cz&#281;&#347;ci cia&#322;a takie jak oko, nos itd. Innym
typem sieci neuronowej jest tak zwana <span 
class="aeb10-x-x-120">losowo po&#322;&#261;czona </span>sie&#263; (ang. randomly
wired network). Znaczy to, &#380;e neurony w pierwszej warstwie &#322;&#261;cz&#261; si&#281; z losowymi
neuronami w warstwie drugiej. Kolejne warstwy po&#322;&#261;czone s&#261; w ten sam sposób.
Mimo i&#380; mogliby&#347;my na tym zaprzesta&#263;, to nie wiedzieliby&#347;my czy neurony
s&#261; po&#322;&#261;czone w najlepszy sposób. Najlepsze po&#322;&#261;czenie neuronów jest bardzo
skomplikowanym problemem. Sk&#261;d w ko&#324;cu mamy wiedzie&#263; która informacja, z którego
neuronu mo&#380;e si&#281; przyda&#263; dalej? Bardzo prostym rozwi&#261;zaniem jest wcale nie
zastanawia&#263; si&#281; nad tym problemem i neurony w kolejnej warstwie po&#322;&#261;czy&#263; ze
wszystkimi neuronami w warstwie poprzedzaj&#261;cej. W ten sposób ka&#380;dy neuron w
warstwie otrzymuje wszystkie informacje obecne w warstwie poprzedniej. Jest to
nazywane <span 
class="aeb10-x-x-120">sieci&#261; w pe&#322;ni po&#322;&#261;czon&#261; </span>(ang. fully connected network). Jeszcze innym
cz&#281;sto wykorzystywanym typem sieci jest RNN (ang. recurrent neural network).
Wspomnieli&#347;my ju&#380;, &#380;e mo&#380;emy w teorii pod&#322;&#261;czy&#263; neurony do samych siebie. Tworzy
to najprostsz&#261; sie&#263; rekurencyjn&#261;. Sieci rekurencyjne s&#261; przydatne, gdy chcemy, &#380;eby sie&#263;
by&#322;a w stanie przechowywa&#263; jakie&#347; dane. Zwyk&#322;a sie&#263; zwana jest feedforward
network, co mo&#380;emy lu&#378;no przet&#322;umaczy&#263; na &#8222;sie&#263; przesy&#322;u dalej&#8221;, jak sama
nazwa wskazuje, przesy&#322;a tylko informacje do przodu, nie przechowuj&#261;c w pami&#281;ci
&#380;adnych informacji. Mogliby&#347;my zamkn&#261;&#263; i ponownie otworzy&#263; tak&#261; sie&#263;
pomi&#281;dzy klasyfikowaniem przyk&#322;adów i otrzyma&#263; tak&#261; sam&#261; odpowied&#378;. Inaczej
jest z RNN, zachowuje ona informacje pomi&#281;dzy przyk&#322;adami, tak &#380;e informacja
pokazana kiedy&#347; mo&#380;e mie&#263; wp&#322;yw na obecny wynik jej dzia&#322;ania. Sie&#263; RNN
wymaga innego algorytmu propagacji wstecznej (o algorytmie propagacji wstecznej
powiemy w nast&#281;pnym rozdziale), zwanego propagacj&#261; w czasie. Je&#347;li kiedykolwiek
s&#322;ysza&#322;e&#347; o sieci nueronowej, to mog&#322;o ci si&#281; wydawa&#263;, &#380;e musi to by&#263; co&#347; bardzo
skomplikowanego. Przecie&#380; proste rzeczy nie mog&#261; by&#263; tak gor&#261;cym tematem
debaty. Jednak jak sam widzisz budowa sieci neuronowej, jest bardzo prosta do
matematycznego zdefiniowania i nie kryje w sobie wielkich tajemnic. To, co jest naprawd&#281;
skomplikowanym, to dopasowanie sieci do problemu, co wymaga szerokiej wiedzy i
pewnego rodzaju my&#347;lenia przez analogi&#281;. Widzieli&#347;my, &#380;e do dobrania jest
wiele parametrów, które teoretycznie mog&#261; wp&#322;ywa&#263; na wynik dzia&#322;ania, cho&#263;
                                                                                    
                                                                                    
zazwyczaj nie b&#281;d&#261; stanowi&#322;y &#380;adnej ró&#380;nicy. Pozosta&#322;a nam teraz ostatnia, mo&#380;e
najbardziej skomplikowana, cz&#281;&#347;&#263; wiedzy, a mianowicie omówienie trenowania sieci
neuronowych.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-18002r4"></a>
                                                                                    
                                                                                    
<!--l. 133--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 133--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-18003"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;3.4:</span><span  
class="content">Sie&#263; neuronowa</span></figcaption><!--tex4ht:label?: x1-18002r3 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-18004r18"></a>
<h3 class="sectionHead"><span class="titlemark">3.5   </span> <a 
 id="x1-190005"></a>Propagacja wsteczna</h3>
<!--l. 140--><p class="noindent" >Przed dyskusj&#261; na temat propagacji wstecznej powinni&#347;my omówi&#263; krótko, czym jest
<span 
class="aeb10-x-x-120">propagacja </span>przez sie&#263; neuronow&#261; (ang. forward pass). Przy ka&#380;dej propagacji zaczynamy
od podania sieci informacji wej&#347;ciowych. Nast&#281;pnie informacje s&#261; przetwarzane przez
pierwsz&#261; warstw&#281; i informacje z niej s&#261; przesy&#322;ane do nast&#281;pnej warstwy do ponownego
przetworzenia. Ten proces wyst&#281;puje dla wszystkich warstw, a dane przesuwaj&#261; si&#281; od
warstwy wej&#347;cia do warstwy wyj&#347;cia. Gdy ostatnia, wyj&#347;ciowa warstwa zostaje
osi&#261;gni&#281;ta, to wynik jest zwracany, a faza propagacji zostaje zako&#324;czona. Teraz
stworzyli&#347;my pierwsz&#261; sie&#263; neuronow&#261;, ale jest jeden problem, który wyst&#281;powa&#322;
równie&#380; w perceptronie. &#379;eby nasza sie&#263; robi&#322;a co&#347; przydatnego, musimy znale&#378;&#263;
odpowiednie wagi, które daj&#261; poprawn&#261; odpowied&#378;. Przypomnijmy o jakich wagach
mowa. Ka&#380;dy neuron przetwarza informacje poprzez pomno&#380;enie wej&#347;cia przez
<!--l. 140--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>w</mi></mstyle></mstyle></math> wagi i
dodanie <!--l. 140--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>b</mi></mstyle></mstyle></math>
wspó&#322;czynnika koryguj&#261;cego a nast&#281;pne przetworzenie ich przez funkcj&#281; aktywacji. Ka&#380;da
waga oraz wspó&#322;czynniki koryguj&#261;ce dla ka&#380;dego neuronu mog&#261; by&#263; ustawione. O
ustawianiu tych wag mo&#380;emy my&#347;le&#263; nie jak o wybieraniu ich dla poszczególnych
neuronów a zamiast tego, jak o ustawieniu wag dla ca&#322;ego modelu. Mogliby&#347;my
po prostu stworzy&#263; list&#281; wag wszystkich neuronów i nast&#281;pnie spróbowa&#263;
ustawi&#263; je wszystkie naraz za pomoc&#261; algorytmu SGD. Przestrze&#324;, nad któr&#261;
by&#347;my optymalizowali, mia&#322;aby ilo&#347;&#263; wymiarów równ&#261; ilo&#347;ci sumy wag
wszystkich neuronów. Funkcj&#261; warto&#347;ci mog&#322;aby by&#263; odleg&#322;o&#347;&#263; pomi&#281;dzy klas&#261;,
któr&#261; wybra&#322;a sie&#263; a poprawn&#261; klas&#261;. Je&#347;li sie&#263; jest odpowiednio ma&#322;a to,
to podej&#347;cie mo&#380;e odnie&#347;&#263; sukces. Je&#347;li jednak nasz&#261; sie&#263; tworz&#261; tysi&#261;ce
neuronów, wydaje si&#281; do&#347;&#263; ma&#322;o prawdopodobnym, &#380;eby wyszukiwanie w
takiej wielowymiarowej przestrzeni mog&#322;o znale&#378;&#263; odpowiednie wagi wszystkich
neuronów. Pomy&#347;lmy o tym jak o strojeniu instrumentu. &#321;atwo by&#322;oby nastroi&#263;
instrument, oczywi&#347;cie z odpowiednimi umiej&#281;tno&#347;ciami, je&#347;li do zmiany jest
tylko jedno &#8216;pokr&#281;t&#322;o&#8217;, je&#347;li jednak tych pokr&#281;te&#322; jest kilkadziesi&#261;t i na dodatek
ustawiamy je wszystkie naraz, zamiast pojedynczo, to zadanie wydaje si&#281; prawie
niemo&#380;liwe do wykonania. Przypomnijmy sobie, jak rozwi&#261;zany by&#322; podobny problem w
perceptronie. Równanie (3.3) prezentuj&#261;ce regu&#322;&#281; aktualizacji w perceptronie wygl&#261;da
nast&#281;puj&#261;co:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19001r11"></a>
                                                                                    
                                                                                    
<!--l. 142--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                          <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi> <mo 
class="MathClass-bin">+</mo> <mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">+</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>y</mi> <mo 
class="MathClass-bin">-</mo> <mi 
>j</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi>
</math></td><td class="eq-no">(3.11)</td></tr></table>
<!--l. 146--><p class="noindent" >Gdzie <!--l. 146--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math> by&#322;y wagami,
<!--l. 146--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> by&#322;o wej&#347;ciem, a
<!--l. 146--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>j</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> zdefiniujemy jako
równe wyj&#347;ciu <!--l. 146--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>w</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>x</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mstyle></mstyle></math>
perceptronu.<br 
class="newline" />
</p><!--l. 148--><p class="indent" >   Mo&#380;emy sobie wyobrazi&#263; u&#380;ycie tej samej regu&#322;y do zmiany wag w sieci neuronowej. Znamy
przecie&#380; <!--l. 148--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>w</mi></mstyle></mstyle></math>,
<!--l. 148--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> oraz
<!--l. 148--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>j</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> bo to
po prostu wyj&#347;cie neuronu. Sk&#261;d jednak we&#378;miemy spodziewan&#261; warto&#347;&#263;
<!--l. 148--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math> dla
ka&#380;dego neuronu? Na pewno mo&#380;emy j&#261; dosta&#263;, dla neuronów, dla których zarówno
spodziewany, jak i otrzymany wynik jest znany, czyli dla neuronów wyj&#347;cia.
Problematyczne s&#261; jednak neurony znajduj&#261;ce si&#281; w &#347;rodkowych warstwach. Przesy&#322;aj&#261; one
przecie&#380; informacje tylko do kolejnej warstwy, a przecie&#380; ta kolejna warstwa nie jest w
stanie poda&#263; nam spodziewanego wyniku dla poprzedzaj&#261;cych neuronów, bo spodziewana
warto&#347;&#263; jest znana dopiero dla ostatniej warstwy. Widzimy teraz, dlaczego sieci neuronowe
z jedn&#261; warstw&#261; s&#261; prostsze do stworzenia. W&#322;a&#347;nie takie rozwi&#261;zania by&#322;y pocz&#261;tkowo
wykorzystywane mimo swoich problemów, takich jak problem XOR. By&#322;oby jednak
&#347;wietnie, gdyby istnia&#322;a metoda przesy&#322;ania warto&#347;ci oczekiwanej w g&#322;&#261;b sieci, do
wcze&#347;niejszych warstw neuronów. To pozwoli&#322;oby nam na trenowanie wielowarstwowej
sieci. I okazuje si&#281;, &#380;e taka metoda istnieje. Nazywa si&#281; <span 
class="aeb10-x-x-120">procedur&#261; propagacji wstecznej</span>
(ang. backpropagation). U&#380;ywa ona zasady &#322;a&#324;cuchowej, która jest formu&#322;&#261;
obliczania pochodnej funkcji z&#322;o&#380;onej. Zasada &#322;a&#324;cuchowa mówi po prostu,
&#380;e:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19002r12"></a>
                                                                                    
                                                                                    
<!--l. 150--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                               <mi 
>d</mi><mi 
>x</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>y</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>x</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>z</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>y</mi>
</math></td><td class="eq-no">(3.12)</td></tr></table>
<!--l. 154--><p class="noindent" >Co mo&#380;e by&#263; ubrane w s&#322;owa w nast&#281;puj&#261;cy sposób: pochodna (tu: zmiana)
<!--l. 154--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> wzgl&#281;dem
<!--l. 154--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math> jest równa
pochodnej <!--l. 154--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> wzgl&#281;dem
<!--l. 154--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>z</mi></mstyle></mstyle></math> pomno&#380;onej
przez pochodn&#261; <!--l. 154--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>z</mi></mstyle></mstyle></math>
wzgl&#281;dem <!--l. 154--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>.
Pozwala to na rozbicie jednej pochodnej na dwie inne.<br 
class="newline" />
</p><!--l. 157--><p class="noindent" >Nasza zasada aktualizacji dla metody gradientu (2.6) jest równa:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19003r13"></a>
<!--l. 159--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                           <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi> <mo 
class="MathClass-bin">+</mo> <mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">-</mo> <mi 
>n</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>w</mi>
</math></td><td class="eq-no">(3.13)</td></tr></table>
<!--l. 163--><p class="noindent" >Gdzie <!--l. 163--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math> s&#261; naszymi
wagami, <!--l. 163--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math> jest
sta&#322;&#261; uczenia, a <!--l. 163--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>w</mi></mstyle></mstyle></math>
jest pochodn&#261; b&#322;&#281;du po wielko&#347;ci wagi.<br 
class="newline" />
</p><!--l. 165--><p class="indent" >   Aby obliczy&#263;&#x00A0;nowe wagi dla naszej sieci koniecznie potrzebujemy zna&#263; <span 
class="aeb10-x-x-120">dE/dw</span>, lecz
problemem jest to, &#380;e zazwyczaj nie mo&#380;emy obliczy&#263;&#x00A0;tej pochodnej bezpo&#347;rednio dla
neuronów znajduj&#261;cych si&#281; na dowolnej g&#322;&#281;boko&#347;ci w sieci. Zamiast tego u&#380;yjemy regu&#322;&#281;
&#322;a&#324;cuchow&#261;. Mo&#380;emy dzi&#281;ki niej obliczy&#263;&#x00A0;pochodn&#261;&#x00A0;funkcji cz&#261;stkowej, je&#347;li tylko
znamy pochodn&#261;&#x00A0;funkcji z&#322;o&#380;onej oraz równania wszystkich funkcji. Skupmy si&#281; na
nast&#281;puj&#261;cym przyk&#322;adzie sieci neuronowej sk&#322;adaj&#261;cej si&#281; z trzech neuronów, dla którego
chcemy obliczy&#263;&#x00A0;<span 
class="aeb10-x-x-120">dE/dw </span>dla neuronu <span 
class="aeb10-x-x-120">f</span>:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19004r14"></a>
                                                                                    
                                                                                    
<!--l. 167--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                               <mi 
>y</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>h</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">+</mo> <mi 
>g</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.14)</td></tr></table>
<!--l. 171--><p class="noindent" >Za&#322;ó&#380;my te&#380;, &#380;e znamy b&#322;&#261;d okre&#347;lony równaniem:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19005r15"></a>
<!--l. 173--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                    <mi 
>e</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>E</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>h</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>z</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.15)</td></tr></table>
<!--l. 177--><p class="noindent" >Teraz aby obliczy&#263;&#x00A0;pochodn&#261; b&#322;&#281;du&#x00A0;dla <span 
class="aeb10-x-x-120">z </span>korzystamy z równania (3.12). Zapiszmy
pochodn&#261;:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19006r16"></a>
<!--l. 180--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
               <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>h</mi> <mo 
class="MathClass-bin">*</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>d</mi><mi 
>h</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>f</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>f</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <mi 
>d</mi><mi 
>h</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>g</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>g</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.16)</td></tr></table>
<!--l. 184--><p class="noindent" >Co wynika po prostu z regu&#322; ró&#380;niczkowania. U&#380;yli&#347;my regu&#322;y &#322;a&#324;cuchowej oraz zasady
obliczania pochodnej z sumy funkcji.<br 
class="newline" />
</p><!--l. 186--><p class="noindent" >Znaj&#261;c podane poni&#380;ej równania mo&#380;emy obliczy&#263; ich pochodne:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19007r17"></a>
                                                                                    
                                                                                    
<!--l. 188--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
   <mtable 
class="equation"><mtr><mtd>
   <mtable  
columnalign="right left" class="split">
<mtr class="split-mtr"><mtd 
class="split-mtd">    <mi 
>e</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>E</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>h</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mtd>
</mtr><mtr class="split-mtr"><mtd 
class="split-mtd"> <mi 
>y</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>h</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>f</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>g</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mtd>
</mtr><mtr class="split-mtr"><mtd 
class="split-mtd"> <mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-punc">,</mo><mi 
>g</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow></mtd>
   </mtr></mtable>                                                                                 </mtd><mtd>
   </mtd></mtr></mtable>
</math></td><td class="eq-no">(3.17)</td></tr></table>
<!--l. 198--><p class="indent" >   To dawa&#322;oby nam mo&#380;liwo&#347;&#263; podstawienia odpowiednich wyników do równania
(3.16), obliczenie <span 
class="aeb10-x-x-120">dE/dw </span>i wstawienie rozwi&#261;zania do równania na aktualizacj&#281; wag
neuronów (3.13).<br 
class="newline" />
</p><!--l. 200--><p class="indent" >   Jedynym problemem jest to &#380;e nie potrafimy obliczy&#263; tych pochodnych ogólnie,
poniewa&#380; zale&#380;&#261; one równie&#380; od konkretnego wej&#347;cia które otrzymaj&#261; te funkcje. Tak
wi&#281;c podstawiaj&#261;c pochodne funkcji (3.17) do równania (3.16) otrzymujemy równanie
zale&#380;ne od wej&#347;cia <span 
class="aeb10-x-x-120">x </span>na pochodn&#261; b&#322;&#281;du po wagach <span 
class="aeb10-x-x-120">dE/dw</span>:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19008r18"></a>
<!--l. 202--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
     <mi 
>d</mi><mi 
>E</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>h</mi> <mo 
class="MathClass-bin">*</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>d</mi><mi 
>h</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>f</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <mi 
>d</mi><mi 
>h</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>g</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>g</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.18)</td></tr></table>
<!--l. 207--><p class="noindent" >Nast&#281;pnie naj&#322;atwiejszym sposobem aby uzyska&#263; wyniki numeryczne dla okre&#347;lonych wag
<!--l. 207--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></math> oraz
wej&#347;cia <span 
class="aeb10-x-x-120">x </span>funkcji <span 
class="aeb10-x-x-120">f </span>jest obliczanie tych pochodnych razem z funkcjami, których wynik jest i
tak konieczny do dzia&#322;ania sieci. Dzi&#281;ki temu ko&#324;cz&#261;c propagacj&#281;, b&#281;dziemy znali wyniki
wszystkich pochodnych cz&#261;stkowych <span 
class="aeb10-x-x-120">df, dg </span>koniecznych do obliczenia <span 
class="aeb10-x-x-120">dE/dw</span>. Je&#347;li
obliczymy wcze&#347;niej równanie na <span 
class="aeb10-x-x-120">dE/dw </span>to b&#281;dzie wystarczy&#322;o podstawi&#263; odpowiednie
warto&#347;ci, &#380;eby uzyska&#263; poszukiwan&#261;&#x00A0;zmian&#281; dla naszych wag. To pozwoli nam
zaktualizowa&#263; wagi funkcji <span 
class="aeb10-x-x-120">f</span>.<br 
class="newline" />
                                                                                    
                                                                                    
</p><!--l. 209--><p class="noindent" >Przedstawimy teraz wyprowadzenie takiego równania dla w pe&#322;ni po&#322;&#261;czonej sieci przesy&#322;u
do przodu (fully-connected feedforward net).<br 
class="newline" />
</p><!--l. 211--><p class="noindent" >Przypomnijmy sobie teraz równanie okre&#347;laj&#261;ce neuron (3.6), (3.7):
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19009r19"></a>
<!--l. 213--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                <mi 
>o</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>w</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>b</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.19)</td></tr></table>
<!--l. 217--><p class="noindent" >Gdzie <!--l. 217--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x03D5;</mi></math> jest funkcj&#261;
aktywacyjn&#261;, a <!--l. 217--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>z</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>w</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math>
cz&#261;stkowym wynikiem dzia&#322;ania neuronu jak to wcze&#347;niej zdefiniowali&#347;my.<br 
class="newline" />
</p><!--l. 219--><p class="indent" >   &#379;eby obliczy&#263; pochodn&#261; b&#322;&#281;du wzgl&#281;dem wag, b&#281;dziemy musieli u&#380;y&#263; regu&#322;y
&#322;a&#324;cuchowej dwukrotnie:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19010r20"></a>
<!--l. 221--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                          <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>w</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>o</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>z</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>w</mi>
</math></td><td class="eq-no">(3.20)</td></tr></table>
<!--l. 225--><p class="noindent" >Gdzie <!--l. 225--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math>
jest pochodn&#261; b&#322;edu wzgl&#281;dem wyniku dzia&#322;ania neuronu,
<!--l. 225--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>o</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi></mstyle></mstyle></math> jest
pochodn&#261; wyniku dzia&#322;ania neuronu wzgl&#281;dem jego wyniku sprzed uzycia funkcji aktywacji, a
<!--l. 225--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>z</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>w</mi></mstyle></mstyle></math>
jest pochodn&#261; warto&#347;ci neuronu przed funkcj&#261; aktywacji wzgl&#281;dem wagi
<!--l. 225--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>w</mi></mstyle></mstyle></math>.<br 
class="newline" />
                                                                                    
                                                                                    
</p><!--l. 227--><p class="noindent" >Jedyne co zrobili&#347;my, to przepisali&#347;my pochodn&#261; b&#322;&#281;du, bo &#322;atwiej b&#281;dzie nam
znale&#378;&#263; pochodne z prawej strony równania. Teraz we&#378;my pod uwag&#281;
<!--l. 227--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>o</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi></mstyle></mstyle></math>. Jest,
to, jak napisali&#347;my pochodna wyniku dzia&#322;ania neuronu wzgl&#281;dem wyniku sprzed u&#380;ycia
funkcji aktywacji. Bior&#261;c wi&#281;c pod uwag&#281; równanie (3.7), mo&#380;emy zapisa&#263; pochodn&#261;
funkcji aktywacji:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19011r21"></a>
<!--l. 229--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                 <mi 
>d</mi><mi 
>o</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>z</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi>
</math></td><td class="eq-no">(3.21)</td></tr></table>
<!--l. 233--><p class="indent" >   Pochodna <!--l. 233--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>o</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi></mstyle></mstyle></math>
jest równa pochodnej funkcji aktywacji. Przypomnijmy sobie, jakie mieli&#347;my funkcje
aktywacji. Pochodne funkcji sigmoidalnej (3.8) i ReLU (3.9) to odpowiednio:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19012r22"></a>
<!--l. 235--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                             <mi 
>d</mi><mi 
>S</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>x</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>S</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>1</mn> <mo 
class="MathClass-bin">-</mo> <mi 
>S</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.22)</td></tr></table>
   <table class="equation"><tr><td> <a 
 id="x1-19013r23"></a>
                                                                                    
                                                                                    
<!--l. 239--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
   <mtable 
class="equation"><mtr><mtd>
   <mtable  
columnalign="right left" class="split">
<mtr class="split-mtr"><mtd 
class="split-mtd">         <mi 
>R</mi> <mo 
class="MathClass-rel">=</mo> <mn>1</mn><mo 
class="MathClass-punc">,</mo><mstyle 
class="text"><mtext  >je&#347;li&#x00A0;</mtext></mstyle><mi 
>x</mi> <mo 
class="MathClass-rel">&#x003E;</mo> <mn>0</mn><mo 
class="MathClass-punc">,</mo></mtd>
</mtr><mtr class="split-mtr"><mtd 
class="split-mtd">         <mi 
>R</mi> <mo 
class="MathClass-rel">=</mo> <mn>0</mn><mo 
class="MathClass-punc">,</mo><mstyle 
class="text"><mtext  >je&#347;li&#x00A0;</mtext></mstyle><mi 
>x</mi> <mo 
class="MathClass-rel">&#x003C;</mo> <mn>0</mn><mo 
class="MathClass-punc">,</mo></mtd>
</mtr><mtr class="split-mtr"><mtd 
class="split-mtd"> <mstyle 
class="text"><mtext  >i&#x00A0;</mtext></mstyle><mi 
>R</mi> <mo 
class="MathClass-rel">=</mo> <mn>1</mn><mstyle 
class="text"><mtext  >&#x00A0;albo&#x00A0;</mtext></mstyle><mn>0</mn><mstyle 
class="text"><mtext  >,&#x00A0;je&#347;li&#x00A0;</mtext></mstyle><mi 
>x</mi> <mo 
class="MathClass-rel">=</mo> <mn>0</mn></mtd>
   </mtr></mtable>                                                                                 </mtd><mtd>
   </mtd></mtr></mtable>
</math></td><td class="eq-no">(3.23)</td></tr></table>
<!--l. 249--><p class="noindent" >Tutaj, poniewa&#380; ReLU jest nieró&#380;niczkowalne w punkcie
<!--l. 249--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math> = 0,
musimy wybra&#263; warto&#347;&#263; pochodnej dla tego punktu sami.<br 
class="newline" />
</p><!--l. 251--><p class="noindent" >Znamy <!--l. 251--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>o</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi></mstyle></mstyle></math>, przejd&#378;my
wi&#281;c do pochodnej <!--l. 251--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>z</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>w</mi></mstyle></mstyle></math>
z równania (3.20). Jest ona równa pochodnej wn&#281;trza funkcji aktywacji (3.19):
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19014r24"></a>
<!--l. 253--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                           <mi 
>d</mi><mi 
>z</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>x</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>w</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
>
</math></td><td class="eq-no">(3.24)</td></tr></table>
<!--l. 257--><p class="noindent" >Gdzie <!--l. 257--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>z</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math>
jest pochodn&#261; wn&#281;trza funkcji aktywacji wzgl&#281;dem wag,
<!--l. 257--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math>
jest &#8216;i&#8217; wej&#347;ciem neuronu. Dla neuronu w &#347;rodowej warstwie
<!--l. 257--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math> jest
równe <!--l. 257--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mi 
>j</mi></mrow></msub 
></mstyle></mstyle></math>
wyj&#347;ciu &#8216;j&#8217; poprzedniej warstwy. Wi&#281;c w generalnym przypadku:
<!--l. 257--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math> =
<!--l. 257--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mi 
>j</mi></mrow></msub 
></mstyle></mstyle></math>, a tylko dla
pierwszej warstwy <!--l. 257--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math>
= <span 
class="aeb10-x-x-120">i-te wej</span><span 
class="aeb10-x-x-120">&#347;</span><span 
class="aeb10-x-x-120">cie</span>.<br 
class="newline" /><br 
class="newline" />
</p><!--l. 259--><p class="noindent" >Teraz podstawiaj&#261;c równania (3.20), (3.21), (3.24) do równania (3.13) otrzymujemy:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19015r25"></a>
<!--l. 261--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                    <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi> <mo 
class="MathClass-bin">+</mo> <mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">-</mo> <mi 
>n</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>z</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mi 
>j</mi></mrow></msub 
>
</math></td><td class="eq-no">(3.25)</td></tr></table>
<!--l. 265--><p class="noindent" >To b&#281;dzie nasze równanie aktualizacji wag. Znamy w nim wszystkie warto&#347;ci oprócz
<!--l. 265--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math>. Tylko w ostatniej
warstwie <!--l. 265--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math>
jest znane. Dla innych warstw musimy obliczy&#263; t&#281; warto&#347;&#263;. Poniewa&#380; nasza sie&#263; jest w
pe&#322;ni po&#322;&#261;czona, to b&#322;&#261;d dla poprzedniej warstwy zale&#380;y od wszystkich pochodnych w
kolejnej warstwie:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19016r26"></a>
<!--l. 267--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                             <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mi 
>j</mi></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mi 
>k</mi></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi>
</math></td><td class="eq-no">(3.26)</td></tr></table>
<!--l. 271--><p class="noindent" >Gdzie <!--l. 271--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mi 
>N</mi></mrow></msub 
></mstyle></mstyle></math> oznacza b&#322;&#261;d dla
<!--l. 271--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi></mstyle></mstyle></math> neuronu w kolejnej warstwie.
Przypomnijmy, &#380;e: <!--l. 271--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math>
jest pochodn&#261; b&#322;edu wzgl&#281;dem wyniku dzia&#322;ania neuronu. B&#322;ad ten b&#281;dzie jednak pochodzi&#322;
od wszystkich neuronów w kolejnej warstwie, poniewa&#380; nasz neuron jest po&#322;&#261;czony z
wszystkimi neuronami w kolejnej warstwie.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-19017r5"></a>
                                                                                    
                                                                                    
<!--l. 276--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 276--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-19018"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;3.5:</span><span  
class="content">Pochodne w propagacji wstecznej</span></figcaption><!--tex4ht:label?: x1-19017r3 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 281--><p class="noindent" >Teraz bior&#261;c pochodn&#261; zupe&#322;n&#261; równania (3.32), otrzymujemy: </p><table class="equation"><tr><td> <a 
 id="x1-19019r27"></a>
<!--l. 282--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                       <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.27)</td></tr></table>
   <table class="equation"><tr><td> <a 
 id="x1-19020r28"></a>
<!--l. 285--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                       <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mi 
>j</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.28)</td></tr></table>
<!--l. 289--><p class="noindent" >Jedynka na ko&#324;cu oznacza, &#380;e chodzi o nast&#281;pn&#261; warstw&#281;.
<!--l. 290--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math> =
<!--l. 290--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi><mi 
>j</mi></mrow></msub 
></mstyle></mstyle></math> poniewa&#380;
<!--l. 290--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math> =
<!--l. 290--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>w</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>o</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math> =
<!--l. 290--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi><mi 
>j</mi></mrow></msub 
></mstyle></mstyle></math>. A
<!--l. 290--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math> jest
pochodn&#261; kolejnej warstwy funkcji aktywacji<br 
class="newline" />
</p><!--l. 292--><p class="indent" >   <!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math>
jest pochodn&#261; b&#322;&#281;du wzgl&#281;dem wej&#347;cia nast&#281;pnej warstwy funkcji aktywacji, ale
je&#347;li nast&#281;pna warstwa jest warstw&#261; wyj&#347;cia, to jak powiedzieli&#347;my wcze&#347;niej
<!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math> jest
znane, poniewa&#380; oznacza pochodn&#261; b&#322;&#281;du wzgl&#281;dem wyj&#347;cia ostatniej wartwy. Teraz, je&#347;li
policzymy <!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math>
dla przedostatniej warstwy i u&#380;yjemy go w poprzedniej warstwie, tak jak u&#380;yli&#347;my
<!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math> dla
obliczenia <!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math>
to otrzymamy formu&#322;&#281; rekursywn&#261; na obliczanie pochodnej b&#322;&#281;du wzgl&#281;dem
wyj&#347;cia kolejnych poprzednich wyj&#347;&#263; neuronów. W algorytmie propagacji
                                                                                    
                                                                                    
wstecznej przesuwamy si&#281; od ko&#324;ca sieci do jej pocz&#261;tku, obliczaj&#261;c
<!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi></mstyle></mstyle></math>
dzi&#281;ki formule rekursywnej, u&#380;ywaj&#261;c faktu, &#380;e warto&#347;&#263;
<!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math>
jest znana dla neuronów wyj&#347;cia, poniewa&#380; w tym przypadku
<!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>o</mi></mstyle></mstyle></math> =
<!--l. 292--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19021r29"></a>
<!--l. 294--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>d</mi><mi 
>E</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>y</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>y</mi>
</math></td><td class="eq-no">(3.29)</td></tr></table>
<!--l. 298--><p class="noindent" >Dla ostatniej warstwy mo&#380;emy w &#322;atwy sposób policzy&#263; pochodn&#261; b&#322;&#281;du wzgl&#281;dem
<!--l. 298--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>
u&#380;ywaj&#261;c technik ró&#380;niczkowania. Jednak je&#347;li znamy
<!--l. 298--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math>
dla warstwy wyj&#347;cia to mo&#380;emy, u&#380;ywaj&#261;c równania (3.28) policzy&#263;
<!--l. 298--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math> dla
warstwy przed warstw&#261; wyj&#347;cia. Mo&#380;emy t&#281; czynno&#347;&#263; powtarza&#263; dla kolejno
poprzednich warstw, a&#380; dojdziemy do wej&#347;cia. Korzystaj&#261;c z nast&#281;puj&#261;cych
równa&#324;, mo&#380;emy policzy&#263;, w jaki sposób powinni&#347;my zmieni&#263; wagi w
sieci:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-19022r30"></a>
<!--l. 300--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                    <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi> <mo 
class="MathClass-bin">+</mo> <mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>t</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">-</mo> <mi 
>n</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>z</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>z</mi> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mi 
>j</mi></mrow></msub 
>
</math></td><td class="eq-no">(3.30)</td></tr></table>
   <table class="equation"><tr><td> <a 
 id="x1-19023r31"></a>
                                                                                    
                                                                                    
<!--l. 303--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                       <mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><mi 
>o</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>d</mi><mi 
>E</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>o</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mi 
>&#x03D5;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>d</mi><msub><mrow 
><mi 
>z</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>w</mi></mrow><mrow 
><mi 
>i</mi><mi 
>j</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(3.31)</td></tr></table>
<!--l. 307--><p class="noindent" >Warto powiedzie&#263;, &#380;e równanie (3.30) i (3.31) mog&#261; by&#263; wykonywane niezale&#380;nie. Np.
w bibliotece PyTorch równanie (3.31) dla ka&#380;dej warstwy jest wykonywane, kiedy
wykonywana jest propagacja wsteczna. Równanie (3.30) jest natomiast wykonywane,
dopiero kiedy sami podamy tak&#261; komend&#281;. Oznacza to, &#380;e gradient jest obliczany
niezale&#380;nie od ustawiania wag.
                                                                                    
                                                                                    
<a 
 id="x1-19024r19"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">3.6   </span> <a 
 id="x1-200006"></a>Zaawansowane tematy w zagadnienu</h3>
<!--l. 312--><p class="noindent" >W poprzednich podrozdzia&#322;ach przypatrywali&#347;my si&#281; bli&#380;ej podstawowemu
wprowadzeniu do sieci neuronowych. Nauczyli&#347;my si&#281;, jak mo&#380;emy je zbudowa&#263;,
u&#380;ywa&#263; propaguj&#261;c przez nie dane i trenowa&#263; u&#380;ywaj&#261;c algorytmu propagacji wstecznej.
Je&#347;li nie zrozumia&#322;e&#347; poprzedniego rozdzia&#322;u, proponujemy tutaj pewn&#261; alternatywn&#261;,
rzadziej u&#380;ywan&#261; metod&#281; trenowania sieci neuronowych. Mo&#380;emy my&#347;le&#263; o wagach w
naszym modelu jak o genomie organizmu. Ka&#380;da waga koduje w tym modelu okre&#347;lone
zachowania. Bardziej sprawny organizm daje wi&#281;ksz&#261; warto&#347;&#263; funkcji warto&#347;ci. W celu
znalezienia lepszych organizmów u&#380;yjemy metod programowania genetycznego,
krzy&#380;uj&#261;c najlepsze organizmy z nadziej&#261;, &#380;e efektem b&#281;d&#261; jeszcze sprawniejsze
jednostki. Nast&#281;pnie przetestujemy je na naszym problemie. Wybierzemy kilka
najbardziej sprawnych i znów skrzy&#380;ujemy jednostki daj&#261;ce najlepszy wynik. Jest to
podej&#347;cie symuluj&#261;ce ewolucj&#281; wykorzystane w celu poprawy naszych wag. Ten sposób
trenowania sieci, cho&#263; zazwyczaj bardziej wymagaj&#261;cy obliczeniowo, je&#347;li damy mu
wystarczaj&#261;co du&#380;o czasu da nam równowarto&#347;ciowe rezultaty do metody propagacji
wstecznej.<br 
class="newline" />
</p><!--l. 314--><p class="indent" >   Mówili&#347;my, &#380;e celem sieci neuronowej jest minimalizacja funkcji warto&#347;ci, ale
nie powiedzieli&#347;my jeszcze wprost jakie typy takiej funkcji istniej&#261;. W uczeniu
maszynowym wyró&#380;nia si&#281; dwa g&#322;ówne typy zadania. Jest to <span 
class="aeb10-x-x-120">klasyfikacja </span>i <span 
class="aeb10-x-x-120">predykcja</span>.
Klasyfikacja polega na przypisaniu przyk&#322;adu do odpowiedniej klasy, np. jak w
przyk&#322;adzie z kotami do klasy kotów lub braku kotów na zdj&#281;ciu. W ten sposób
mo&#380;emy klasyfikowa&#263; przeró&#380;ne rzeczy: chocia&#380;by wykrywa&#263; twarze lub
stwierdzi&#263; czy naro&#347;le rakowe jest niebezpieczne. Inn&#261; mo&#380;liwo&#347;ci&#261; klasyfikacji jest
klasyfikacja do wielu klas. W ten sposób mo&#380;emy klasyfikowa&#263; np. litery, gatunki
zwierz&#261;t czy ceny. Aby dokona&#263; klasyfikacji w sieci neuronowej, nale&#380;y zwróci&#263;
liczb&#281; od 0 do 1 w przypadku klasyfikacji dwuklasowej. W przypadku klasyfikacji
wieloklasowej nale&#380;y zwróci&#263; <span 
class="aeb10-x-x-120">n </span>elementow&#261; dystrybucj&#281; prawdopodobie&#324;stwa
[<!--l. 314--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>&#x2026;</mi><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></math>],
gdzie ka&#380;dy element oznacza prawdopodobie&#324;stwo, &#380;e dany przyk&#322;ad nale&#380;y do danej
klasy. Lista ta powinna si&#281; sumowa&#263; do 1. Wyró&#380;nili&#347;my te&#380; inny sposób dzia&#322;ania
sieci neuronowych i nazwali&#347;my go predykcj&#261;. Predykcja polega na przewidywaniu
jakiej&#347; warto&#347;ci. Mo&#380;emy przewidywa&#263; np. temperatur&#281;, wyniki wyborów czy
wielko&#347;&#263; PKB. To wszystko s&#261; warto&#347;ci numeryczne w pewnym przedziale,
wi&#281;c nasza sie&#263; b&#281;dzie zwraca&#263; liczb&#281; naturaln&#261;. W tym wypadku wyj&#347;ciem
mo&#380;e by&#263;, odpowiednio zeskalowane, normalne wyj&#347;cie pojedynczego lub kilku
                                                                                    
                                                                                    
neuronów.<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-20001r6"></a>
                                                                                    
                                                                                    
<!--l. 319--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 319--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-20002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;3.6:</span><span  
class="content">Normalizacja danych</span></figcaption><!--tex4ht:label?: x1-20001r3 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 324--><p class="indent" >   Przed wprowadzeniem danych do sieci neuronowej chcemy je cz&#281;sto przetworzy&#263; w
jaki&#347; sposób. Dzia&#322;a tutaj zasada mówi&#261;ca, &#380;e lepsza reprezentacja prowadzi do lepszych
rezultatów. Ta maksyma odnosi si&#281; zreszt&#261;, równie&#380; do ludzi. Woleliby&#347;my, powiedzmy
gra&#263; w szachy, u&#380;ywaj&#261;c do tego planszy ni&#380; mówi&#263; na g&#322;os nasze ruchy, mimo i&#380; oba
rozwi&#261;zania opisuj&#261; t&#281; sam&#261; gr&#281;. Podobny fenomen mo&#380;emy obserwowa&#263; w sieciach
neuronowych. One te&#380; lepiej radz&#261; sobie z pewnymi rodzajami informacji ni&#380; innymi mniej
przystosowanymi do bycia wej&#347;ciem. Dlatego my chc&#261;c osi&#261;gn&#261;&#263; jak najlepsze rezultaty,
przetwarzamy dane w pewien sposób, licz&#261;c na to, &#380;e poprawi to wynik dzia&#322;ania sieci.
Przetwarzanie danych przed u&#380;yciem ich w sieci neuronowej cz&#281;sto sk&#322;ada si&#281; z
<span 
class="aeb10-x-x-120">normalizacji</span>. Normalizacja to proces skalowania danych wej&#347;ciowych. Popatrzmy na prosty
przyk&#322;ad:<br 
class="newline" />
</p><!--l. 327--><p class="noindent" >Zmierzyli&#347;my temperatur&#281; w przeci&#261;gu siedmiu kolejnych dni i otrzymali&#347;my w wyniku zbiór
danych <!--l. 327--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>D</mi></mstyle></mstyle></math>.<br 
class="newline" />
</p>
   <table class="equation"><tr><td> <a 
 id="x1-20003r32"></a>
<!--l. 329--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
          <mi 
>D</mi> <mo 
class="MathClass-rel">=</mo> <mrow ><mo 
class="MathClass-open">[</mo><mrow><mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>3</mn><mn>1</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>7</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>9</mn><mn>9</mn><mn>9</mn><mn>9</mn><mn>6</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>9</mn><mn>9</mn><mn>9</mn><mn>7</mn><mn>6</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>5</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>5</mn><mn>4</mn><mn>0</mn></mrow><mo 
class="MathClass-close">]</mo></mrow>
</math></td><td class="eq-no">(3.32)</td></tr></table>
<!--l. 333--><p class="noindent" >Widzimy, &#380;e zmierzone temperatury s&#261; bardzo du&#380;e. Trenowanie na tym zbiorze b&#281;dzie
ci&#281;&#380;kie, poniewa&#380; relatywne ró&#380;nice mi&#281;dzy punktami danych s&#261; niewielkie, du&#380;o
lepiej by&#322;oby odj&#261;&#263; od ka&#380;dego takiego punktu 1000000, otrzymuj&#261;c nowy zbiór
<!--l. 333--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>D</mi></mrow><mrow 
><mi 
>s</mi></mrow></msub 
></mstyle></mstyle></math>.<br 
class="newline" />
</p>
   <table class="equation"><tr><td> <a 
 id="x1-20004r33"></a>
                                                                                    
                                                                                    
<!--l. 335--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                         <msub><mrow 
><mi 
>D</mi></mrow><mrow 
><mi 
>s</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mrow ><mo 
class="MathClass-open">[</mo><mrow><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>3</mn><mn>1</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>7</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo><mo 
class="MathClass-bin">-</mo><mn>4</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo><mo 
class="MathClass-bin">-</mo><mn>2</mn><mn>4</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>5</mn><mn>0</mn><mo 
class="MathClass-punc">,</mo> <mn>5</mn><mn>4</mn><mn>0</mn></mrow><mo 
class="MathClass-close">]</mo></mrow>
</math></td><td class="eq-no">(3.33)</td></tr></table>
<!--l. 339--><p class="noindent" >Teraz nawet dla nas dane sta&#322;y si&#281; bardziej przejrzyste. Ten zbiór le&#380;y w bardziej
naturalnym przedziale i zazwyczaj trenowanie na nim b&#281;dzie &#322;atwiejsze. System nie
b&#281;dzie si&#281; musia&#322; uczy&#263; ignorowa&#263; du&#380;ych wielko&#347;ci i zwraca&#263; uwag&#281; tylko na
liczby na ni&#380;szych miejscach. Zauwa&#380;my te&#380;, &#380;e niektóre dane zmieni&#322;y si&#281; z
pozytywnych warto&#347;ci na ujemne. Nie b&#281;dzie to mia&#322;o jednak efektu na wynik dzia&#322;ania
sieci, poniewa&#380; informacja o relatywnych ró&#380;nicach mi&#281;dzy przyk&#322;adami zosta&#322;a
zachowana.<br 
class="newline" />
</p><!--l. 341--><p class="indent" >   Poniewa&#380; pozyskiwanie du&#380;ych zbiorów danych jest cz&#281;sto kosztowne, ludzie
u&#380;ywaj&#261; mniejszych zbiorów w p&#281;tli, przetwarzaj&#261;c przyk&#322;ady po kilka razy w trakcie
treningu. Ta praktyka, mimo i&#380; mo&#380;e zwi&#281;kszy&#263; nasze mo&#380;liwo&#347;ci trenowania sieci,
prowadzi te&#380; cz&#281;sto do pewnych niepo&#380;&#261;danych konsekwencji. Znany efekt z tym zwi&#261;zany
jest nazywany <span 
class="aeb10-x-x-120">nadmiernym dopasowaniem </span>(ang. overfitting), co znaczy, &#380;e sie&#263; osi&#261;ga
dobre wyniki na zbiorze u&#380;ywanym do &#263;wiczenia, ale s&#322;abe w prawdziwym u&#380;ytkowaniu
albo na zbiorze testowym.<br 
class="newline" />
</p><!--l. 343--><p class="noindent" ><span 
class="aeb10-x-x-120">Zbi</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">r testowy </span>jest zbiorem, na którym nie trenujemy, po to, aby uzyska&#263; bezstronn&#261;
ocen&#281; naszego modelu.<br 
class="newline" />
</p><!--l. 345--><p class="indent" >   Zobaczmy, w jaki sposób mo&#380;e si&#281; objawia&#263; nadmierne dopasowanie. Powiedzmy, &#380;e
mamy pewien zbiór punktów, który mo&#380;e by&#263; opisany prost&#261; lini&#261; albo troch&#281; lepiej za
pomoc&#261; skomplikowanego wielomianu. Je&#347;li do nauczenia tego dopasowania zosta&#322;o
u&#380;ytych niewiele przyk&#322;adów, mieliby&#347;my tendencje, &#380;eby powiedzie&#263;, &#380;e wielomian
jest prawdopodobnie nadmiernym dopasowaniem, poniewa&#380; nie jest prawdopodobne, by
dobrze opisywa&#322; przyk&#322;ady, których nie u&#380;yli&#347;my do jego stworzenia. Je&#347;li jednak
przyk&#322;adów by&#322;o wi&#281;cej, a dane nadal wskazuj&#261;, &#380;e wielomian jest dobrym dopasowaniem
do danych, to uzyskali&#347;my potwierdzenie i teraz mo&#380;e bardziej sensownym wyborem
jest wielomian, ni&#380; linia prosta. Nadmierne dopasowanie mo&#380;e si&#281; objawia&#263; w
sieci neuronowej jako zapami&#281;tywanie przyk&#322;adów. Mimo i&#380; klasyczna sie&#263;
neuronowa nie ma pami&#281;ci, to jednak mo&#380;e przechowywa&#263; pewne informacje w
swoich wagach. Czasami zdarza si&#281;, &#380;e taka sie&#263;, zamiast np. uczy&#263; si&#281;, z jakich
cz&#281;&#347;ci sk&#322;adaj&#261; si&#281; koty, &#380;eby przewidywa&#263; czy na zdj&#281;ciu jest kot, zapami&#281;tuje
konkretne informacje zwi&#261;zane z podanym zdj&#281;ciem. Pó&#378;niej wystarczy, &#380;e
sie&#263; &#8216;przypomni&#8217; sobie, &#380;e widzia&#322;a dane zdj&#281;cie, aby zaklasyfikowa&#263; je jako
zdj&#281;cie zawieraj&#261;ce lub niezawieraj&#261;ce kota. Dzieje si&#281; tak zazwyczaj, gdy sie&#263;,
                                                                                    
                                                                                    
której u&#380;ywamy, jest du&#380;a a przyk&#322;adów, których u&#380;ywamy do trenowania,
jest niewiele. W celu zapobiegania zjawisku otrzymywania lepszych rezultatów,
ale tylko na papierze, zosta&#322;y wymy&#347;lone metody <span 
class="aeb10-x-x-120">regularyzacji</span>. Jednymi z nich
s&#261; tak zwane regularyzacja L1 i L2, które dodaj&#261; do funkcji warto&#347;ci pewn&#261;
kar&#281; zale&#380;n&#261; od wielko&#347;ci wag w naszej sieci. Funkcja warto&#347;ci zmienia si&#281;
nast&#281;puj&#261;co:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-20005r34"></a>
<!--l. 347--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                              <mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>V</mi> </mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>V</mi> </mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">+</mo> <mo 
class="MathClass-rel">|</mo><mi 
>w</mi><mo 
class="MathClass-rel">|</mo>
</math></td><td class="eq-no">(3.34)</td></tr></table>
   <table class="equation"><tr><td> <a 
 id="x1-20006r35"></a>
<!--l. 350--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                             <mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>V</mi> </mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>V</mi> </mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">+</mo> <mo 
class="MathClass-rel">|</mo><mi 
>w</mi><msup><mrow 
><mo 
class="MathClass-rel">|</mo></mrow><mrow 
><mn>2</mn></mrow></msup 
>
</math></td><td class="eq-no">(3.35)</td></tr></table>
<!--l. 354--><p class="noindent" >Gdzie równanie (3.34) opisuje regularyzacj&#281; L1, a (3.35) regularyzacj&#281; L2. Ró&#380;nic&#261; jak
wida&#263;, jest pot&#281;ga, do której podnosimy wagi, jednak w obu przypadkach warto&#347;&#263; wag
jest warto&#347;ci&#261; bezwzgl&#281;dn&#261;.<br 
class="newline" />
</p><!--l. 356--><p class="indent" >   Taka zmiana w funkcji warto&#347;ci spowoduje, &#380;e nasza sie&#263; nie b&#281;dzie trenowa&#263;, tylko
aby zwi&#281;ksza&#263; zadan&#261; warto&#347;&#263;, co jest dla nas negatywnym skutkiem, ale za to sprawi,
&#380;e wagi b&#281;d&#261; pod presj&#261;, aby pozostawa&#263; mniejsze. Jest to niew&#261;tpliwie pozytywny
skutek, bior&#261;c pod uwag&#281; eksploduj&#261;cy gradient. Tak&#380;e ilo&#347;&#263; po&#322;&#261;cze&#324; b&#281;dzie
kontrolowana, ze wzgl&#281;du na to, &#380;e niepotrzebne po&#322;&#261;czenia b&#281;d&#261; zmniejszane, bo poprawi
to funkcj&#281; warto&#347;ci. Ta mniejsza liczba po&#322;&#261;cze&#324;, tak jak w naszym przyk&#322;adzie z
dopasowywaniem linii, sprawi, &#380;e wytrenowany model b&#281;dzie prostszy, co zazwyczaj
skutkuje lepsz&#261; generalizacj&#261;.<br 
class="newline" />
                                                                                    
                                                                                    
</p><!--l. 358--><p class="indent" >   Idea, która stoi za obecnym du&#380;ym sukcesem sieci neuronowych, jest nast&#281;puj&#261;ca
rekomendacja. Je&#347;li chcemy zwi&#281;kszy&#263; osi&#261;gni&#281;cia sieci neuronowej na danym problemie,
to chcemy zwi&#281;kszy&#263; jej rozmiar, je&#347;li nie zauwa&#380;amy poprawy w funkcji warto&#347;ci
podczas treningu. Natomiast je&#347;li widzimy popraw&#281; podczas treningu, ale nie jest ona
widoczna na zbiorze testowym, to powinni&#347;my zwi&#281;kszy&#263; wielko&#347;&#263; zbioru, na
którym trenujemy. Ten wzrost liczby przyk&#322;adów w zbiorze treningowym jest
naturalnym sposobem regularyzacji. Widzimy, &#380;e samym zwi&#281;kszaniem wielko&#347;ci
sieci i ilo&#347;ci danych jeste&#347;my w stanie poprawi&#263; wynik osi&#261;gany na naszym
problemie. Jest to rzadko spotykana w&#322;a&#347;ciwo&#347;&#263; w &#347;wiecie informatyki, gdzie
zazwyczaj ka&#380;de zachowanie trzeba zakodowa&#263; w sposób bezpo&#347;redni, gdy&#380;
komputery cechuj&#261; si&#281; wielk&#261; karno&#347;ci&#261; i ogromnym brakiem wyobra&#378;ni. Taki jest
klasyczny obraz sytuacji. Jednak sieci neuronowe udowadniaj&#261; co&#347; przeciwnego.
Odpowiednio zaprogramowany komputer mo&#380;e by&#263; kreatywny, nie porusza&#263; si&#281;
utartymi schematami, a nawet uczy&#263; si&#281; na w&#322;asn&#261; r&#281;k&#281;. Jest to naprawd&#281; wielki
prze&#322;om, który pozwala nam mie&#263; nadziej&#281;, &#380;e b&#281;dziemy w stanie w przysz&#322;o&#347;ci
wykorzystywa&#263; do po&#380;ytecznych celów moc obliczeniow&#261;, która do tej pory ro&#347;nie w
sposób wyk&#322;adniczy. Wzrost wyk&#322;adniczy oznacza &#380;e wzrost danej wielko&#347;ci
przyspiesza bardzo szybko. Jest to jeden z niewielu zasobów, które zachowuj&#261; si&#281; w
ten sposób. Po&#322;&#261;czenie tej ogromnej mocy z technikami przetwarzania danych
mo&#380;e dawa&#263; nam nadziej&#281; na prze&#322;om, który mo&#380;e nast&#261;pi&#263; w najbli&#380;szej
przysz&#322;o&#347;ci.
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p>
   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;4</span><br /><a 
 id="x1-210004"></a>Symboliczne AI</h2>
<!--l. 5--><p class="noindent" >Na poprzednich stronach rozmawiali&#347;my sporo o statystycznym podej&#347;ciu do sztucznej
inteligencji. Istnieje jednak inne podej&#347;cie nazywane symbolicznym AI. Nie jest ono obecnie
tak popularne czy podkre&#347;lane w nauce o sztucznej inteligencji, ale historycznie by&#322;o
wa&#380;n&#261; jej dziedzin&#261;. S&#261;dzimy, &#380;e obecny ruch oddalaj&#261;cy nas od symbolicznych
pomys&#322;ów wynika cz&#281;&#347;ciowo z braku sukcesu w oparciu symboli o sub-symboliczne
znaczenie. Ludzie, kiedy mówi&#261; o danym poj&#281;ciu, przypominaj&#261; sobie wiele faktów jego
dotycz&#261;cych. Kiedy chocia&#380;by mówimy o kocie, to mo&#380;emy mie&#263; przed oczami jego
wygl&#261;d, sposób poruszania si&#281;, wiemy, jakie jest jego ulubione jedzenie itd. Nie jest
wi&#281;c tak, &#380;e poj&#281;cie kota jest niezale&#380;ne od innych. Raczej nale&#380;y ono do sieci
poj&#281;&#263;, z której ka&#380;de definiuje inne, z którymi jest po&#322;&#261;czone, ale jednocze&#347;nie
uzyskuje swoje znaczenie poprzez inne poj&#281;cia. Tej w&#322;a&#347;ciwo&#347;ci cz&#281;sto brakuje w
symbolicznych systemach. S&#261; one raczej nakierowane na manipulacj&#281; symbolami w sensie
matematycznym. Nacisk rzadko jest po&#322;o&#380;ony na rozbudowywanie arsena&#322;u mo&#380;liwo&#347;ci
systemu, poprzez dodawanie nowych poj&#281;&#263;. Jednocze&#347;nie powiedzieli&#347;my, &#380;e
symbole nie maj&#261; zazwyczaj po&#322;&#261;czenia z sub-symbolicznymi systemami takimi
jak sieci neuronowe. Sprawia to, &#380;e symbole, którymi manipuluj&#261; te systemy,
nie maj&#261; dla nich takiego znaczenia jak dla nas. Jest to zupe&#322;nie inne podej&#347;cie.
Jednak mimo tych ogranicze&#324; systemy manipulacji symbolami odnios&#322;y spory
sukces. Podajmy tu przyk&#322;ad programu LT (ang. Logic Theorist) napisanego w
1956 roku przez Newell&#8217;a, Simon&#8217;a i Shaw&#8217;a. LT wykorzystywa&#322; struktur&#281; drzewa,
na której dokonywa&#322; rozumowania, aplikuj&#261;c zmiany do wyra&#380;enia oparte na
zasadach logiki i matematyki. Je&#347;li poprzez te zmiany doszed&#322; on do rozwi&#261;zania, to
ko&#324;czy&#322; poszukiwania, a &#347;cie&#380;ka prowadz&#261;ca od prepozycji do wyniku by&#322;a
nazywana dowodem. &#379;eby ograniczy&#263; rozga&#322;&#281;zianie mo&#380;liwo&#347;ci, LT posiada&#322;
pewne heurystyki, które ogranicza&#322;y przeprowadzanie pewnych operacji, &#380;eby
rozmiar drzewa wyszukiwa&#324; pozostawa&#322; sensowny. Program ten udowodni&#322; 38 z 52
twierdze&#324; w pewnym rozdziale ksi&#261;&#380;ki &#8222;Principia Mathematica&#8221;. Uda&#322;o mu si&#281; tak&#380;e
znale&#378;&#263; bardziej elegancki dowód pewnego twierdzenia, jednak nie zosta&#322; on
przyj&#281;ty do czasopisma matematycznego ze wzgl&#281;du na swoj&#261; prostot&#281;. Osoba,
która ocenia&#322;a to zg&#322;oszenie, prawdopodobnie nie zauwa&#380;y&#322;a, &#380;e autorem by&#322;
komputer.<br 
class="newline" />
</p><!--l. 7--><p class="noindent" >Symboliczne systemy definiuj&#261; pewien zestaw formalnych zasad i u&#380;ywaj&#261; ich do
dochodzenia do pewnych konkluzji. W ten sposób mo&#380;na by rozwi&#261;za&#263; na przyk&#322;ad
problem ró&#380;niczkowania albo nast&#281;puj&#261;cy sylogizm:
      </p><div class="quote">
      <!--l. 10--><p class="noindent" >Wszyscy ludzie s&#261; &#347;miertelni.</p></div>
                                                                                    
                                                                                    
      <div class="quote">
      <!--l. 13--><p class="noindent" >Sokrates jest cz&#322;owiekiem.</p></div>
<!--l. 16--><p class="noindent" >Tu chcieliby&#347;my, by nasz system skonkludowa&#322; oczywiste:
      </p><div class="quote">
      <!--l. 19--><p class="noindent" >St&#261;d wynika, &#380;e Sokrates jest &#347;miertelny.</p></div>
<!--l. 22--><p class="noindent" >Naturalnym rozwini&#281;ciem rozumowania symbolicznego s&#261; techniki propagacji ogranicze&#324;
(ang. constraint propagation), które sprawiaj&#261;, &#380;e wszystkie zdefiniowane ograniczenia s&#261;
ze sob&#261; zgodne. Na przyk&#322;ad mo&#380;emy sprawdzi&#263;, czy nast&#281;puj&#261;ce ograniczenia s&#261; ze sob&#261;
zgodne:
      </p><div class="quote">
      <!--l. 25--><p class="noindent" >Wszystkie jab&#322;ka s&#261; czerwone.</p></div>
      <div class="quote">
      <!--l. 28--><p class="noindent" >Moje jab&#322;ko jest zielone.</p></div>
<!--l. 31--><p class="indent" >   Tu chcemy, aby nasz system skonkludowa&#322; niemo&#380;liwo&#347;&#263; prawdziwo&#347;ci tych dwóch
stwierdze&#324; w tym samym czasie. Na podstawie podobnych zasad dzia&#322;aj&#261; tak zwane
systemy eksperckie zawdzi&#281;czaj&#261;ce swoj&#261; nazw&#281; od w teorii, na&#347;ladowania eksperta.
Takie systemy by&#322;y pocz&#261;tkowo najcz&#281;&#347;ciej wykorzystywanymi w przemy&#347;le.
Stworzenie takiego systemu wymaga&#322;o najpierw zebrania specjalistycznej wiedzy od
ekspertów. Nast&#281;pnie zapisywa&#322;o si&#281; t&#281; wiedz&#281; przy pomocy ró&#380;nych zasad, cz&#281;sto
przy pomocy popularnych w informatyce zasad je&#347;li-to. By&#322;y to cz&#281;sto metody
nieró&#380;ni&#261;ce si&#281; wiele od klasycznych metod programowania. Systemy eksperckie by&#322;y i s&#261;
wykorzystywane w ró&#380;nych specjalistycznych dziedzinach np. prawie, które jest czasami
podatne na sformalizowanie w taki sposób ze wzgl&#281;du na wyst&#281;powanie w nim wielu
zasad.<br 
class="newline" />
</p><!--l. 33--><p class="indent" >   Jako cz&#281;&#347;&#263; metod symbolicznych uznaliby&#347;my tak&#380;e metody poszukiwania w
drzewie. Te techniki daj&#261; nam sposób patrzenia na ró&#380;ne wybory, których mogliby&#347;my
dokona&#263;. Wyobra&#378;my, &#380;e znajdujemy si&#281; w wielkim zamku z wielkoma pokojami.
Chcemy wyj&#347;&#263; na zewn&#261;trz, lecz nie znamy drogi, która tam prowadzi. Musimy wi&#281;c
spróbowa&#263; drzwi, które prowadz&#261; z naszego pokoju do innego, w którym mo&#380;e by&#263;
wyj&#347;cie. Je&#347;li z naszego pokoju wychodzi kilka ró&#380;nych drzwi, to musimy mie&#263;
jaki&#347; sposób dokonania wyboru pomi&#281;dzy nimi. W nast&#281;pnym pokoju napotkamy
                                                                                    
                                                                                    
prawdopodobnie podobny problem, gdzie b&#281;dziemy musieli wybra&#263; mi&#281;dzy wieloma
drzwiami. Metody poszukiwania w drzewie daj&#261; nam sposób na &#347;ledzenie odwiedzonych
pokoi. Zbieraj&#261;c te informacje, daj&#261; nam one mo&#380;liwo&#347;&#263; dokonywania najlepszej decyzji
w danych okoliczno&#347;ciach.
<a 
 id="x1-21001r20"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">4.1   </span> <a 
 id="x1-220001"></a>Rozwi&#261;zywanie poprzez wyszukiwanie</h3>
<!--l. 37--><p class="noindent" >Widzieli&#347;my ju&#380; jedno rozwi&#261;zanie problemu poprzez wyszukiwanie. Czy pami&#281;tasz, co
to by&#322;o? Kiedy szukali&#347;my sposobu, aby znale&#378;&#263; minimum funkcji warto&#347;ci,
zaproponowali&#347;my na pocz&#261;tku, aby sprawdza&#263; mo&#380;liwe rozwi&#261;zania w sposób losowy
przez jaki&#347; czas, a nast&#281;pnie wybra&#263; najlepsze odwiedzone rozwi&#261;zanie. To jest w&#322;a&#347;nie
rozwi&#261;zanie przez wyszukiwanie. Jednym z problemów, które mogliby&#347;my rozwi&#261;za&#263;
poprzez wyszukiwanie, jest problem <span 
class="aeb10-x-x-120">propagacji ogranicze</span><span 
class="aeb10-x-x-120">&#324;</span>. W takim problemie staramy si&#281;
sprawdzi&#263;, czy wszystkie na&#322;o&#380;one ograniczenia s&#261; ze sob&#261; zgodne, czy mówi&#261;c
inaczej, nie zaprzeczaj&#261; sobie. Na przyk&#322;ad w problemie kolorowania map, pytamy
si&#281;, czy i w jaki sposób jeste&#347;my w stanie pokolorowa&#263; dan&#261; map&#281; za pomoc&#261;
<!--l. 37--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
kolorów, w ten sposób, aby przylegaj&#261;ce kraje by&#322;y pokryte innymi kolorami tuszu.
Dodatkowe pytanie, jakie mo&#380;emy zada&#263; to: czy istnieje, a je&#347;li tak to, jaka jest
najmniejsza liczba kolorów, za pomoc&#261; której mo&#380;emy pokolorowa&#263; dowoln&#261; map&#281;? Na
to pytanie odpowiada twierdzenie o czterech kolorach. Mówi nam ono, &#380;e za
pomoc&#261; czterech kolorów jeste&#347;my w stanie pokolorowa&#263; dowoln&#261; map&#281;. Tak&#261;
hipotez&#281; postawiono ju&#380; w XIX w. ale na rozwi&#261;zanie tego problemu przysz&#322;o nam
poczeka&#263; a&#380; do roku 1976, w którym przy u&#380;yciu komputera sprawdzono 1936
przypadków mo&#380;liwych u&#322;o&#380;e&#324; mapy. Jednak pó&#378;niej powsta&#322;y pewne w&#261;tpliwo&#347;ci
co do poprawno&#347;ci rozwi&#261;zania, które jednak uda&#322;o si&#281; rozwia&#263; znów przy
pomocy komputerowego wspomagania. Jest to jeden z ciekawszych dowodów w
matematyce, poniewa&#380; ci&#281;&#380;ko jest go sprawdzi&#263; cz&#322;owiekowi i pokazuje nam, &#380;e
nowy rodzaj dowodów jest mo&#380;liwy. Wracaj&#261;c jednak do g&#322;ównego tematu,
przypomnijmy, &#380;e chcemy rozwi&#261;za&#263; ten problem dla konkretnego przypadku,
wi&#281;c nie wystarczy nam dowód, ale potrzebujemy te&#380; konkretnych kolorów dla
danych pa&#324;stw. Mogliby&#347;my w teorii rozwi&#261;za&#263; ten problem metod&#261; prób i
b&#322;&#281;dów, ale istnieje du&#380;o szybszy sposób. U&#380;ywa on idei spójno&#347;ci. Kolor
pa&#324;stwa jest spójny w w&#281;&#378;le (ang. node-consistent), je&#347;li jest spójny ze samym
sob&#261;. Spójno&#347;&#263; w w&#281;&#378;le jest w oczywisty sposób zachowana, je&#347;li tylko
u&#380;ywamy legalnego koloru. Kolor b&#281;dzie spójny w &#322;uku (ang. arc-consistent), je&#347;li
jest spójny ze samym sob&#261; oraz z kolorami przylegaj&#261;cych pa&#324;stw. Lepszym
rozwi&#261;zaniem problemu kolorowania mapy jest wybranie jakiego&#347; koloru dla jednego
pa&#324;stwa i sprawdzenie spójno&#347;ci w &#322;uku. Nast&#281;pnie, je&#347;li rozwi&#261;zanie jest
                                                                                    
                                                                                    
spójne, wybierzemy kolor dla innego pa&#324;stwa i sprawdzimy jego spójno&#347;&#263; w
&#322;uku. Post&#281;pujemy w ten sposób, tak d&#322;ugo a&#380; nie rozwi&#261;zali&#347;my problemu lub
problem sta&#322; si&#281; niespójny. W takim przypadku cofniemy si&#281; do poprzedniego
rozwi&#261;zania, które by&#322;o spójne w &#322;uku i spróbujemy innych kolorów. To cofanie
nazywane jest <span 
class="aeb10-x-x-120">nawrotem </span>(ang. backtracking). Nawroty s&#261; do&#347;&#263; cz&#281;stym pomys&#322;em
wykorzystywanym w drzewie poszukiwa&#324;, o którym powiemy dalej. Pozwalaj&#261; nam one
cofn&#261;&#263; si&#281; do poprzednio odwiedzonego stanu i wybra&#263; inn&#261; &#347;cie&#380;k&#281;, czy to z
powodu bycia niespójnym, czy te&#380;, aby sprawdzi&#263; inne mo&#380;liwo&#347;ci. Pomys&#322;
cofania pewnych informacji w gór&#281; drzewa b&#281;dzie wykorzystywany dalej w drzewach
poszukiwa&#324;.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-22001r1"></a>
                                                                                    
                                                                                    
<!--l. 42--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 42--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-22002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;4.1:</span><span  
class="content">Propagacja ogranicze&#324;</span></figcaption><!--tex4ht:label?: x1-22001r4 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-22003r22"></a>
<h3 class="sectionHead"><span class="titlemark">4.2   </span> <a 
 id="x1-230002"></a>Drzewa poszukiwa&#324;</h3>
<!--l. 49--><p class="noindent" ><span 
class="aeb10-x-x-120">Drzewo </span>jest struktur&#261; danych, która bierze swoj&#261; nazw&#281; z podobie&#324;stwa do
drzewa. Drzewa wyrastaj&#261; z korzenia, a ga&#322;&#281;zie rozga&#322;&#281;ziaj&#261; si&#281; na coraz to mniejsze.
W informatyce drzewa umieszczamy na g&#322;owie, tak &#380;e korze&#324; znajduje si&#281; u
góry a czubek drzewa wraz z wi&#281;kszo&#347;ci&#261; ga&#322;&#281;zi na samym dole. Ten sposób
rysunku sprzyja naturalnemu rozwijaniu drzew od góry do do&#322;u, tak samo, jak
podczas pisania. Drzewo jako struktura danych sk&#322;ada si&#281; z w&#281;z&#322;ów po&#322;&#261;czonych
kraw&#281;dziami. Ka&#380;dy w&#281;ze&#322; oznacza pewien stan, a kraw&#281;d&#378; istnienie pewnej relacji
pomi&#281;dzy tymi stanami. Stanami mo&#380;e by&#263; np. numer pokoju, w którym si&#281;
znajdujemy a kraw&#281;dziami drzwi, które &#322;&#261;cz&#261; te pokoje. Ka&#380;dy w&#281;ze&#322;, z którego
wyrasta ga&#322;&#261;&#378;, nazywany jest w&#281;z&#322;em nadrz&#281;dnym (ang. parent node), a ka&#380;dy
w&#281;ze&#322; posiadaj&#261;cy w&#281;ze&#322; nadrz&#281;dny nazywany jest w&#281;z&#322;em podrz&#281;dnym (ang. child
node).<br 
class="newline" />
</p><!--l. 51--><p class="indent" >   <span 
class="aeb10-x-x-120">Drzewo poszukiwa</span><span 
class="aeb10-x-x-120">&#324;</span> jest technik&#261;, której nazwa nawi&#261;zuje do wykonywania
poszukiwa&#324; na strukturze danych, jakiej jest drzewo. Opisali&#347;my ju&#380; jedn&#261; metafor&#281; je
opisuj&#261;c&#261;, kiedy to wybieraj&#261;c odnog&#281; drzewa, wybieramy kolejne drzwi. Jakiego rodzaju
problemy mog&#322;yby by&#263; dobrze opisane jako takie drzewo poszukiwa&#324;? Wygl&#261;da na to, &#380;e
ka&#380;dy problem, w ci&#261;gu rozwi&#261;zywania którego, wielokrotnie podejmujemy podobn&#261;
decyzj&#281;, by&#322;by podatny takiemu podej&#347;ciu. Na przyk&#322;ad: wyszukiwanie drogi w labiryncie,
planowanie diety czy granie w szachy. Wszystkie te problemy wydaj&#261; si&#281; dobrze zdefiniowane
dla algorytmów opieraj&#261;cych si&#281; na drzewa. Je&#347;li nie rozumiesz dlaczego, to zastanówmy
si&#281; nad tym problemem. Po pierwsze, aby nasze dane mog&#322;y by&#263; dobrze opisane
przez drzewo, to ka&#380;dy stan musi mie&#263; ze sob&#261; co&#347; wspólnego, ale równie&#380;
ka&#380;dy stan powinien by&#263; rozró&#380;nialny od innych. I tak w labiryncie mo&#380;emy
zapisywa&#263; unikalne po&#322;o&#380;enie, przy planowaniu diety ilo&#347;&#263; kalorii a w grze w
szachy pozycj&#281;. Nast&#281;pnie wszystkie po&#322;&#261;czenia mi&#281;dzy stanami powinny by&#263;
tego samego rodzaju. Wybieranie mi&#281;dzy naszyjnikiem a ilo&#347;ci&#261; kalorii nie ma
wi&#281;kszego sensu. Natomiast wybór mi&#281;dzy sa&#322;atk&#261; a burgerem jest bardziej rozs&#261;dny.
Tak wi&#281;c podobny rodzaj po&#322;&#261;cze&#324; powinien wyst&#281;powa&#263; mi&#281;dzy wszystkimi
stanami, aby móc dokona&#263; mi&#281;dzy nimi wyboru. W pewnym sensie mo&#380;emy
my&#347;le&#263; o rozga&#322;&#281;zianiu si&#281; drzewa, od jego korzenia, jak o ró&#380;nych mo&#380;liwych
historiach, które si&#281; nam prezentuj&#261;. Je&#347;li wybraliby&#347;my pewn&#261; odnog&#281; drzewa i
podejmowali decyzje, &#380;eby j&#261; osi&#261;gn&#261;&#263;, to ona sta&#322;aby si&#281; prawd&#261;, a wi&#281;c histori&#261;
wydarze&#324;. Je&#347;li jednak podj&#281;liby&#347;my decyzje prowadz&#261;ce do innego miejsca, to
ono by&#322;oby histori&#261;, która si&#281; wydarzy&#322;a. Istnieje tu pewne podobie&#324;stwo do
interpretacji wielu &#347;wiatów w mechanice kwantowej, która mówi, &#380;e na poziomie
                                                                                    
                                                                                    
kwantowym &#347;wiat rozszczepia si&#281; na ró&#380;ne historie, które staj&#261; si&#281; nowymi
wszech&#347;wiatami. Ró&#380;nica jest taka, &#380;e w mechanice kwantowej wybór jest
dokonywany przez losowe zachowanie cz&#261;steczki a w drzewach poszukiwa&#324; przez
maksymalizuj&#261;cego cel aktora. Mo&#380;emy o drzewie poszukiwa&#324; my&#347;le&#263; jak
o wybieraniu takiego kwantowego wszech&#347;wiata. Sam wybór mo&#380;emy nawet
zobrazowa&#263; jak przechodzenie przez drzwi mi&#281;dzy kolejnymi wszech&#347;wiatami. Ta
metafora pomo&#380;e nam dalej w interpretacji bardziej abstrakcyjnych pomys&#322;ów
zwi&#261;zanych z drzewami poszukiwa&#324;. Wspomnieli&#347;my tak&#380;e o jednej z metod
wykorzystywanych w drzewach poszukiwa&#324;, jak&#261; jest nawrot. Pomy&#347;lmy teraz, co
oznacza on w metaforze wielu &#347;wiatów. Je&#347;li odwiedzimy pewien stan i si&#281;
z niego cofniemy do innego poprzedzaj&#261;cego stanu, to znaczy, &#380;e naprawd&#281; go
nie odwiedzili&#347;my. Je&#347;li rzeczywi&#347;cie by&#347;my w nim byli to znaczy, &#380;e nie
mogliby&#347;my si&#281; cofn&#261;&#263; do poprzedzaj&#261;cego stanu, poniewa&#380; czas p&#322;ynie tylko w jedn&#261;
stron&#281;. Jednak w nawrocie cofamy si&#281; do poprzedzaj&#261;cego stanu. Oznacza to, &#380;e nie
byli&#347;my w tym stanie, a wi&#281;c by&#322;o to tylko nasze wyobra&#380;enie bycia w danym stanie.
Inaczej mówi&#261;c, przeprowadzili&#347;my symulacj&#281;. Symulacje s&#261; jednym z ulubionych
narz&#281;dzi w skrzynce kogo&#347; zajmuj&#261;cego si&#281; sztuczn&#261; inteligencj&#261;. Co oznacza s&#322;owo
symulacja? Symulacja jest pewnym uproszczeniem rzeczywisto&#347;ci, które jednak
zachowuje pewne wa&#380;ne jego elementy w celu przewidywania przysz&#322;o&#347;ci. Próbujemy
symulowa&#263; zachowania, &#380;eby podejmowa&#263; najlepsze decyzje. Ludzie tworz&#261;
przeró&#380;ne symulacje, zaczynaj&#261;c od ekonomicznych i finansowych, symulacji
zachowania ludzi i t&#322;umów, symulacje dzia&#322;ania pojazdów, symulacje robotów.
Ludzie programuj&#261;cy rozwi&#261;zania sztucznej inteligencji lubi&#261; symulacje, poniewa&#380;
pozwalaj&#261; im one na sprawdzanie swoich systemów w &#347;rodowisku testowym.
Symulowana rzeczywisto&#347;&#263; mo&#380;e nam te&#380; dostarczy&#263; danych do trenowania naszych
systemów takich jak sieci neuronowe. Du&#380;o ci&#281;&#380;ej jest wpu&#347;ci&#263; system sztucznej
inteligencji do prawdziwego &#347;wiata ni&#380; do symulacji, co wynika z zagro&#380;e&#324; z tym
zwi&#261;zanych, mo&#380;liwo&#347;ci testowania systemu, jak ju&#380; wcze&#347;niej wspomnieli&#347;my, i
sposobów komunikacji takiego aktora z rzeczywisto&#347;ci&#261;. Czasami, &#380;eby dzia&#322;a&#263; w
rzeczywisto&#347;ci, konieczny by&#322;by robot, w przeciwie&#324;stwie do symulacji. Dlatego w&#322;a&#347;nie
naukowcy wol&#261; zazwyczaj u&#380;ywa&#263; do bada&#324; &#347;rodowisk testowych, jakimi s&#261;
symulacje. Najprostsze takie modele rzeczywisto&#347;ci powsta&#322;y dawno temu na
bliskim wschodzie i gdzie&#347; w Azji. Mowa tu oczywi&#347;cie o grach planszowych takich
jak szachy, Go, shogi. Oddaj&#261; one pewien aspekt rzeczywisto&#347;ci w uproszczonej
formie. Chocia&#380;by szachy by&#322;y symulacj&#261; kierowania polem walki. Takie proste gry
s&#261; nam dzisiaj bardzo przydatne do rozwijania rozwi&#261;za&#324; sztucznej inteligencji.
W&#322;a&#347;nie na nich z sukcesem zastosowano techniki drzew poszukiwa&#324;, i to one stoj&#261;
za niektórymi najnowszymi post&#281;pami w dziedzinie, s&#322;u&#380;&#261;c jako &#347;rodowisko
testowe.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-23001r2"></a>
                                                                                    
                                                                                    
<!--l. 56--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 56--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-23002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;4.2:</span><span  
class="content">Drzewo poszukiwa&#324;</span></figcaption><!--tex4ht:label?: x1-23001r4 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-23003r23"></a>
<h3 class="sectionHead"><span class="titlemark">4.3   </span> <a 
 id="x1-240003"></a>Poszukiwanie na g&#322;&#281;boko&#347;&#263; i rozpi&#281;to&#347;&#263;</h3>
<!--l. 63--><p class="noindent" >Powinni&#347;my teraz skupi&#263; si&#281; na problemie kolejno&#347;ci, w której b&#281;dziemy sprawdza&#263;
mo&#380;liwe przysz&#322;o&#347;ci. Mo&#380;emy o tym my&#347;le&#263; jak o planie jak otwiera&#263; kolejne drzwi.
Zastanówmy si&#281; jakie podstawowe w&#322;a&#347;ciwo&#347;ci ma drzewo poszukiwa&#324;. Patrz&#261;c si&#281;,
nawet wizualnie, mo&#380;emy wyró&#380;ni&#263; dwie g&#322;ówne cechy w&#281;z&#322;ów w drzewie. Jak
my&#347;lisz jakie s&#261; to cechy? Jednymi z wa&#380;niejszych cech jest to, jak g&#322;&#281;boko w&#281;ze&#322; znajduje
si&#281; wzgl&#281;dem korzenia i ilo&#347;&#263; rozga&#322;&#281;zie&#324;, na które si&#281; rozga&#322;&#281;zia. Na tych dwóch
cechach skupiaj&#261; si&#281; algorytmy poszukiwania na g&#322;&#281;boko&#347;&#263; i na rozpi&#281;to&#347;&#263;. Jednym
sposobem na eksplorowanie takiego drzewa poszukiwa&#324; jest patrze&#263; si&#281; tak g&#322;&#281;boko, jak to
jest mo&#380;liwe, nie zwracaj&#261;c uwagi na inne drogi, które mogliby&#347;my obra&#263;. To
podej&#347;cie ma nazw&#281; <span 
class="aeb10-x-x-120">poszukiwania w g&#322;&#261;b </span>(ang. depth first). Algorytm poszukiwania w g&#322;&#261;b
zawsze na pocz&#261;tku b&#281;dzie si&#281; stara&#322; patrze&#263;, jak najg&#322;&#281;biej jest to mo&#380;liwe, wybieraj&#261;c
do sprawdzenia w nast&#281;pnej kolejno&#347;ci zawsze w&#281;ze&#322; podrz&#281;dny, je&#347;li jest to
mo&#380;liwe. Kiedy osi&#261;gamy w&#281;ze&#322; ko&#324;cowy, musimy si&#281; nawróci&#263; do ostatniego
miejsca, w którym mieli&#347;my wybór i stamt&#261;d rozpocz&#261;&#263; nasze poszukiwania, w
podobny sposób, nie odwiedzaj&#261;c ju&#380; jednak raz odwiedzonych w&#281;z&#322;ów, je&#347;li
nie jest to konieczne. Je&#347;li wrócimy do naszej metafory o wybieraniu drzwi w
zamku, odpowiada&#322;oby to wybieranie pierwszych napotkanych drzwi w pokoju i
przechodzenie dalej do momentu a&#380; znajdziemy wyj&#347;cie albo napotkamy na pokój
bez drzwi. Kiedy dojdziemy do takiego pokoju, to zawracamy do poprzedniego
pokoju, w którym byli&#347;my i kontynuujemy poszukiwania w ten sam sposób.
Jakie mocne strony ma ten algorytm? Jedn&#261; siln&#261; stron&#261; tego podej&#347;cia jest to,
&#380;e nie musimy by&#263; bardzo dobrzy w ocenianiu sytuacji, w której jeste&#347;my,
poniewa&#380; dostajemy si&#281; do logicznego ko&#324;ca mo&#380;liwo&#347;ci i to tam mo&#380;emy
dokona&#263; oceny. Jedn&#261; s&#322;ab&#261; stron&#261; poszukiwania w g&#322;&#261;b jest to, &#380;e nie sprawdza ono
wielu mo&#380;liwo&#347;ci, tylko &#347;lepo wybiera jedn&#261; drog&#281;, któr&#261; pod&#261;&#380;a. Zupe&#322;nie
inn&#261; mo&#380;liwo&#347;ci&#261; jest <span 
class="aeb10-x-x-120">poszukiwanie wszerz</span>. Analogicznie do poszukiwania w
g&#322;&#261;b, poszukiwanie wszerz b&#281;dzie najpierw sprawdza&#263; wszystkie mo&#380;liwo&#347;ci na
jednym poziomie, zanim b&#281;dzie porusza&#263; si&#281; w g&#322;&#261;b. Zu&#380;ywa ono wszystkie w&#281;z&#322;y
podrz&#281;dne przed przej&#347;ciem do w&#281;z&#322;ów podrz&#281;dnych wzgl&#281;dem podrz&#281;dnych. W
naszej metaforze zamku musimy najpierw sprawdzi&#263; wszystkie drzwi prowadz&#261;ce z
naszego pokoju, pó&#378;niej sprawdzamy wszystkie drzwi w pokojach, do których
prowadz&#261; drzwi z naszego pokoju itd. &#379;eby to wszystko ogarn&#261;&#263;, musieliby&#347;my
stworzy&#263; map&#281; i zapisywa&#263; na niej wszystkie po&#322;&#261;czenia. Podobnie dzia&#322;aj&#261; oba z
tych algorytmów. Zapisuj&#261; odwiedzone stany w strukturze drzewa. Silne i s&#322;abe
strony algorytmu poszukiwania wszerz b&#281;d&#261; zamienione z poszukiwaniem w g&#322;&#261;b.
To podej&#347;cie bierze pod uwag&#281; wszystkie mo&#380;liwe wybory przed przej&#347;ciem
                                                                                    
                                                                                    
w g&#322;&#261;b, a wi&#281;c sprawdza wszystkie mo&#380;liwo&#347;ci, które napotyka. Wi&#261;&#380;e si&#281;
to jednak, z tym &#380;e mo&#380;e nie doj&#347;&#263; tak g&#322;&#281;boko, jak poszukiwanie w g&#322;&#261;b,
je&#347;li nie otrzyma wystarczaj&#261;cego czasu, wi&#281;c system oceniaj&#261;cy sytuacj&#281; musi
by&#263; dobry, poniewa&#380; tylko kilka ruchów w g&#322;&#261;b, gdzie b&#281;dzie trzeba dokona&#263;
wyboru, mo&#380;e by&#263; niejasnym czy sytuacja jest korzystna. Obie te metody mimo
swoich ró&#380;nic s&#261; w pewien sposób do siebie podobne. Stanowi&#261;, jak mo&#380;na by
powiedzie&#263;, swoje lustrzane odbicie. S&#261; jednymi z najprostszych metod przeszukiwania
drzewa. Obrazuj&#261; jednocze&#347;nie kluczowy problem, który napotykamy podczas
wyboru nast&#281;pnego w&#281;z&#322;a, który chcemy odwiedzi&#263;. Czy nale&#380;y sprawdzi&#263;
wiele alternatyw, czy lepiej porusza&#263; si&#281; g&#322;&#281;biej? Ten problem b&#281;dzie dla nas dalej
istotny i algorytmy dalej zaprezentowane maj&#261; unikalne metody radzenia sobie z
nimi. Obie z tych metod utrzymuj&#261; równie&#380; w pami&#281;ci najlepszy do tej pory
odwiedzony w&#281;ze&#322;, aby zwróci&#263; go jako odpowied&#378;. Kiedy odwiedzamy nowy w&#281;ze&#322;,
zawsze sprawdzamy, czy nie jest lepszy od do tej pory najlepszego i je&#347;li tak to
zamieniamy najlepszy w&#281;ze&#322; na obecnie odwiedzany. Ta w&#322;a&#347;ciwo&#347;&#263; wymaga
funkcji warto&#347;ci, która b&#281;dzie w stanie oceni&#263; ka&#380;dy odwiedzony stan. W
algorytmach tu zaprezentowanych funkcja warto&#347;ci jest u&#380;ywana dopiero na
ko&#324;cu po fazie rozwijania w&#281;z&#322;ów. W&#281;z&#322;y s&#261; najpierw rozwijane, a nast&#281;pnie ocena
przez funkcj&#281; warto&#347;ci jest stosowana na w&#281;z&#322;ach li&#347;ciach, czyli takich, które
nie maj&#261; &#380;adnych podrz&#281;dnych w&#281;z&#322;ów. Spo&#347;ród w&#281;z&#322;ów li&#347;ci wybierana
jest najlepsza ga&#322;&#261;&#378;, a nast&#281;pnie cofamy si&#281; do pocz&#261;tku tej ga&#322;&#281;zi i dokonujemy
pierwszego wyboru, który prowadzi do tej najkorzystniejszej historii. W nast&#281;pnym
ruchu zazwyczaj wszystko jest resetowane i poszukiwanie rozpoczyna si&#281; na nowo.
Wa&#380;ne jest tu tak&#380;e to, &#380;e sposób symulacji nast&#281;pnych stanów musi by&#263;
dobry przy du&#380;ej ilo&#347;ci rozga&#322;&#281;zie&#324;, tak &#380;eby ocena sytuacji w w&#281;&#378;le li&#347;ciu
nie odbiega&#322;a zbyt du&#380;o od poprawnej oceny naszej sytuacji z powodu ró&#380;nic
mi&#281;dzy zasymulowanym a prawdziwym rozwini&#281;ciem. Dlatego tego typu algorytmy
nadaj&#261; si&#281; najlepiej do sytuacji, w których symulacja jest idealna takich jak np.
szachy. W szachach mo&#380;emy dok&#322;adnie powiedzie&#263; jakie mo&#380;liwo&#347;ci istniej&#261; w
danej sytuacji i do czego prowadz&#261;, dlatego b&#281;dziemy dalej wykorzystywa&#263; ten
przyk&#322;ad.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-24001r3"></a>
                                                                                    
                                                                                    
<!--l. 68--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 68--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-24002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;4.3:</span><span  
class="content">Poszukiwanie na rozpi&#281;to&#347;&#263;&#x00A0;i g&#322;&#281;boko&#347;&#263;</span></figcaption><!--tex4ht:label?: x1-24001r4 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-24003r24"></a>
<h3 class="sectionHead"><span class="titlemark">4.4   </span> <a 
 id="x1-250004"></a>Minimax</h3>
<!--l. 77--><p class="noindent" >Mówili&#347;my o tym, &#380;e mo&#380;emy próbowa&#263; rozwi&#261;za&#263; gry dla dwóch graczy, takie jak
warcaby czy szachy u&#380;ywaj&#261;c technik wyszukiwania. Czy to znaczy, &#380;e mo&#380;emy po
prostu wzi&#261;&#263; algorytm poszukiwania w g&#322;&#261;b lub wszerz i wykorzysta&#263; go do
znalezienia najlepszego ruchu? U&#380;ywaj&#261;c tamtych algorytmów, musieli&#347;my poda&#263;
funkcj&#281; warto&#347;ci i wybierali&#347;my ruch ze wzgl&#281;du na jej maksymalizacj&#281;, ale na
przyk&#322;ad w szachach, ta sama pozycja mo&#380;e mie&#263; zupe&#322;ne inn&#261; warto&#347;&#263;, w
zale&#380;no&#347;ci od tego, czyj ruch jest nast&#281;pny. Tak dzieje si&#281;, poniewa&#380; jeden z
graczy chce maksymalizowa&#263; a drugi minimalizowa&#263; t&#281; sam&#261; funkcj&#281; warto&#347;ci.
Za&#322;ó&#380;my, &#380;e wygrana bia&#322;ego to +1 a wygrana czarnego to -1, remis oznaczmy
jako 0. W takiej sytuacji bia&#322;y chce, &#380;eby funkcja warto&#347;ci by&#322;a jak najbli&#380;ej
1, bo to daje mu najwi&#281;ksze szanse na wygran&#261;, natomiast czarny przeciwnie,
chce &#380;eby funkcja warto&#347;ci by&#322;a jak najni&#380;sza i znajdowa&#322;a si&#281; jak najbli&#380;ej
-1.<br 
class="newline" />
</p>
   <table class="equation"><tr><td> <a 
 id="x1-25001r1"></a>
<!--l. 79--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                             <msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mi 
>h</mi><mi 
>a</mi><mi 
>t</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>a</mi><mi 
>x</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mi 
>a</mi></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mi 
>b</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">]</mo></mrow></mrow><mo 
class="MathClass-close">]</mo></mrow>
</math></td><td class="eq-no">(4.1)</td></tr></table>
<!--l. 83--><p class="noindent" >Gdzie <!--l. 83--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mi 
>h</mi><mi 
>a</mi><mi 
>t</mi></mrow></msub 
></mstyle></mstyle></math>
oznacza funkcj&#281; warto&#347;ci dla jednego z graczy po ruchu przeciwnika i w&#322;asnym,
<!--l. 83--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math>
oznacza funkcj&#281; warto&#347;ci z jednej perspektywy w zale&#380;no&#347;ci od ruchów
<!--l. 83--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mi 
>a</mi></mrow></msub 
></mstyle></mstyle></math> w&#322;asnym i
<!--l. 83--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mi 
>b</mi></mrow></msub 
></mstyle></mstyle></math>
oponenta.<br 
class="newline" />
</p><!--l. 85--><p class="indent" >   Widzimy, &#380;e zachodzi tu rekursywna zale&#380;no&#347;&#263;, gdzie jeden z graczy chce
minimalizowa&#263; funkcj&#281; a drugi j&#261; maksymalizowa&#263;, i tak przy ka&#380;dym ruchu. Nie
mo&#380;emy wi&#281;c patrze&#263; tylko na nasze w&#322;asne ruchy, bo przeciwnik b&#281;dzie si&#281; stara&#322;
                                                                                    
                                                                                    
znale&#378;&#263; luki w naszym rozumowaniu. Musimy patrze&#263; si&#281; na przemian na ruchy dla nas i
dla naszego rywala. Chocia&#380; chcemy wybra&#263; najlepszy ruch, to musimy go wybra&#263; z
perspektywy najgorszej mo&#380;liwej sytuacji, któr&#261; wybierze dla nas nasz przeciwnik.
Jednak&#380;e on ma ten sam problem, musi wybra&#263; najgorszy ruch dla nas, wybieraj&#261;c
w&#347;ród najlepszych ruchów, które zrobimy i tak dalej.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-25002r4"></a>
                                                                                    
                                                                                    
<!--l. 90--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 90--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-25003"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;4.4:</span><span  
class="content">Minimax</span></figcaption><!--tex4ht:label?: x1-25002r4 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
   <table class="equation"><tr><td> <a 
 id="x1-25004r2"></a>
<!--l. 95--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                           <msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mi 
>h</mi><mi 
>a</mi><mi 
>t</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>a</mi><mi 
>x</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>m</mi><mi 
>a</mi><mi 
>x</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>&#x2026;</mi></mrow><mo 
class="MathClass-close">]</mo></mrow></mrow><mo 
class="MathClass-close">]</mo></mrow></mrow><mo 
class="MathClass-close">]</mo></mrow></mrow><mo 
class="MathClass-close">]</mo></mrow>
</math></td><td class="eq-no">(4.2)</td></tr></table>
<!--l. 99--><p class="indent" >   Mo&#380;emy zobaczy&#263;, &#380;e wyst&#281;puje tu rekursywno&#347;&#263;, w której etap maksymalizacji
nast&#281;puje po etapie minimalizacji, a po etapie minimalizacji nast&#281;puje etap maksymalizacji
itd. Ta seria wydarze&#324; prowadzi nas bezpo&#347;rednio do pomys&#322;u na algorytm, który
wykorzystuje t&#281; zale&#380;no&#347;&#263;. Ten algorytm patrz&#261;cy si&#281; kolejno i próbuj&#261;cy
maksymalizowa&#263; funkcj&#281; warto&#347;ci dla jednego poziomu w&#281;z&#322;ów i minimalizowa&#263; dla
kolejnego nazywa si&#281; <span 
class="aeb10-x-x-120">minimax</span>. Powtórzmy jeszcze raz, jak wygl&#261;da jego dzia&#322;anie na
przyk&#322;adzie szachów. Kiedy nast&#281;puje nasza tura, najpierw okre&#347;lamy wszystkie ruchy,
które mo&#380;emy wykona&#263; i zapisujemy je w drzewie, nast&#281;pnie przechodzimy do
powsta&#322;ych sytuacji i robimy to samo tym razem dla ruchów przeciwnika. Kiedy dojdziemy
do pozycji ko&#324;cowej, np. &#8217;mata&#8217; to okre&#347;lamy, kto wygra&#322; i zaprzestajemy poszukiwania.
Jednak prawie nigdy nie korzysta si&#281; w rzeczywisto&#347;ci z wyszukiwania do ko&#324;ca ze
wzgl&#281;du na astronomicznie rosn&#261;c&#261; liczb&#281; rozga&#322;&#281;zie&#324;. Na ogó&#322; w pewnym momencie
musimy przerwa&#263; poszukiwanie i okre&#347;li&#263; warto&#347;&#263; niedoko&#324;czonej sytuacji w
w&#281;&#378;le za pomoc&#261; chocia&#380;by sieci neuronowej. Kiedy okre&#347;limy która ga&#322;&#261;&#378; jest
najkorzystniejsza, to wybieramy j&#261; i cofamy si&#281; do pierwszego ruchu w tej sekwencji.
Wykonujemy znaleziony ruch. Czasami w algorytmie minimax nast&#261;pi sytuacja, w której
inna ga&#322;&#261;&#378; jest wybrana ponad ga&#322;&#261;&#378;, któr&#261; eksplorujemy i zobaczenie jakiejkolwiek
nowej warto&#347;ci, jakkolwiek dobrej dla nas, nie zmieni ruch, który wykona nasz przeciwnik.
W&#322;a&#347;ciwie im lepsz&#261; mo&#380;liwo&#347;&#263; znajdziemy, tym bardziej przeciwnik nie b&#281;dzie chcia&#322;
tam i&#347;&#263; w ruchu poprzedzaj&#261;cym, tak wi&#281;c znalezienie lepszej dla nas sytuacji, gdy
jeste&#347;my przekonani, &#380;e przeciwnik i tak nie wybierze tego rozga&#322;&#281;zienia, ze
wzgl&#281;du na to, &#380;e nie jest dla niego dobre jeszce przed sprawdzeniem nowego
rozga&#322;&#281;zienia, nie ma sensu. W takiej sytuacji mo&#380;liwym jest, aby dokona&#263; p&#322;ytkiego
lub g&#322;&#281;bokiego odci&#281;cia ga&#322;&#281;zi, to znaczy, &#380;e nie b&#281;dziemy takiej ga&#322;&#281;zi wi&#281;cej
przeszukiwa&#263;. Ta technika nazywana jest odci&#281;ciem <span 
class="aeb10-x-x-120">alfa-beta </span>(ang. alpha-beta
pruning) i jest cz&#281;sto u&#380;ywanym dodatkiem do techniki minimax. Powinna ona
by&#263; w&#322;a&#347;ciwie u&#380;ywana zawsze, gdy mamy tak&#261; mo&#380;liwo&#347;&#263;, poniewa&#380;
ucina ona tylko ga&#322;&#281;zie, które nie mog&#261; mie&#263; wp&#322;ywu na wynik wyszukiwania.
Tak wi&#281;c wyszukiwanie alfa-beta jest równowa&#380;ne w wyniku do wyszukiwania
minimax.<br 
class="newline" />
</p><!--l. 101--><p class="indent" >   Deep Blue, które pokona&#322;o Kasparova w s&#322;ynnej serii meczów, u&#380;ywa&#322;o algorytmu
alfa-beta, który dzia&#322;a&#322; w paraleli&#378;mie na wielu specjalnie do tego przygotowanych
procesorach, u&#380;ywa&#322; skonstruowanej na te potrzeby funkcji ewaluacji, której parametry
by&#322;y nauczone przez system. Co ciekawe Deep Blue korzysta&#322;o z wersji algorytmu zwanej
<span 
class="aeb10-x-x-120">iteracyjne pog&#322;&#281;bianie </span>(ang. iterative deepening) co oznacza, &#380;e wyszukiwanie jest
ograniczone do pewnego poziomu g&#322;&#281;boko&#347;ci i po jego osi&#261;gni&#281;ciu najlepszy do tej pory
wynik zostaje zwrócony, natomiast je&#347;li pozosta&#322;o jeszcze czasu na obliczenia, to
wybierany jest pewien g&#322;&#281;bszy poziom graniczny, do którego prowadzi si&#281; poszukiwanie. Ten
proces powtarzany jest wielokrotnie w ci&#261;gu wyszukiwania jednego ruchu i najlepszy ruch
jest zmieniany na ten osi&#261;gni&#281;ty najg&#322;&#281;bszym do tej pory wyszukiwaniem w miar&#281;
zwi&#281;kszania g&#322;&#281;boko&#347;ci. Trzeba zauwa&#380;y&#263;, &#380;e rezultaty poprzedniego wyszukiwania
zostaj&#261; utracone w kolejnym wyszukiwaniu, które prowadzi si&#281; od nowa. Mo&#380;e ci
si&#281; to wydawa&#263; du&#380;ym marnotrawstwem, ale nale&#380;y pami&#281;ta&#263;, &#380;e g&#322;&#281;bsze
poziomy zawieraj&#261; eksponencjalne wi&#281;cej w&#281;z&#322;ów ni&#380; te bli&#380;ej korzenia, wi&#281;c straty
osi&#261;gane przy ka&#380;dym wyszukiwaniu malej&#261; eksponencjalne w porównaniu do
wyszukiwania z maksymalnym poziomem g&#322;&#281;boko&#347;ci. Co daje nam ten algorytm?
Zauwa&#380;yli&#347;my, &#380;e w czasie jednego wyszukiwania kilka ruchów b&#281;dzie zwróconych.
Teraz, je&#347;li okazuje si&#281;, &#380;e nie wiemy dok&#322;adnie, ile ma trwa&#263; wyszukiwanie, to
dzi&#281;ki tej metodzie b&#281;dziemy mie&#263; gotowy dobry rezultat w trakcie ca&#322;ego trwania
wyszukiwania.
<a 
 id="x1-25005r25"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">4.5   </span> <a 
 id="x1-260005"></a>A*</h3>
<!--l. 107--><p class="noindent" >A* (czytaj z ang. A star) jest algorytmem <span 
class="aeb10-x-x-120">najpierw najlepsze </span>(ang. best first) co znaczy, &#380;e
wyszukuje na pocz&#261;tku te w&#281;z&#322;y, które podejrzewa, &#380;e b&#281;d&#261; najlepsze. &#379;eby to zrobi&#263;,
potrzebuje pewnego sposobu estymacji funkcji warto&#347;ci. Ga&#322;&#281;zi&#261; sprawdzan&#261; przez A*
b&#281;dzie ta, która minimalizuje koszt dotarcia do w&#281;z&#322;a i spodziewany koszt od tego
w&#281;z&#322;a.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-26001r3"></a>
                                                                                    
                                                                                    
<!--l. 109--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                           <mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>n</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">]</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>m</mi><mi 
>i</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">[</mo><mrow><mi 
>g</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>n</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">+</mo> <mi 
>h</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>n</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">]</mo></mrow>
</math></td><td class="eq-no">(4.3)</td></tr></table>
<!--l. 113--><p class="indent" >   Gdzie <!--l. 113--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> jest funkcj&#261;
warto&#347;ci, <!--l. 113--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>g</mi></mstyle></mstyle></math> jest kosztem
dotarcia do w&#281;z&#322;a, a <!--l. 113--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>h</mi></mstyle></mstyle></math>
jest spodziewanym kosztem od tego w&#281;z&#322;a do celu.<br 
class="newline" />
</p><!--l. 115--><p class="indent" >   Najprostszym przyk&#322;adem sytuacji, w której A* by&#322;by u&#380;yteczny, jest problem
poszukiwania najlepszej &#347;cie&#380;ki. Powiedzmy na przyk&#322;ad, &#380;e chcemy znale&#378;&#263;
drog&#281; prowadz&#261;c&#261; z miasta A do miasta B, która prowadzi przez pewien zbiór
miast C. Mo&#380;e poruszamy si&#281; z miasta A do B cz&#281;sto, wi&#281;c chcemy znale&#378;&#263;
najlepsz&#261; &#347;cie&#380;k&#281;, która prowadzi z A do B. Nie znamy jednak dok&#322;adnych
odleg&#322;o&#347;ci mi&#281;dzy miastami. W tym przypadku mo&#380;emy u&#380;y&#263; algorytmu A*, gdzie
<!--l. 115--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>g</mi></mstyle></mstyle></math>
by&#322;oby realnym czasem drogi, któr&#261; pokonali&#347;my przeliczonym na dystans, a
<!--l. 115--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>h</mi></mstyle></mstyle></math>
odleg&#322;o&#347;ci&#261; pomi&#281;dzy miastami na mapie, spo&#347;ród których próbujemy wybra&#263;
najkorzystniejsze. Widzimy wi&#281;c, &#380;e cz&#281;&#347;&#263; funkcji warto&#347;ci zale&#380;y od rzeczywi&#347;cie
przebytego dystansu, a druga cz&#281;&#347;&#263; od spodziewanego dystansu do przebycia. Naprawd&#281;
niekoniecznie musi to by&#263; dystans przebyty, a mog&#261; by&#263; to wielko&#347;ci na mapie. Kiedy np.
program próbuje znale&#378;&#263; najlepsz&#261; tras&#281; dla naszego samochodu, wykorzystuje
rozwi&#261;zania podobne do algorytmu A*. Sprawdza, ile wynosi odleg&#322;o&#347;&#263; w linii prostej do
celu w kilku punktach, do których mo&#380;emy pojecha&#263; i dodaje do niej odleg&#322;o&#347;&#263;
rzeczywistej drogi prowadz&#261;cej do tych punktów, która jest do pokonania. Nast&#281;pnie
przesuwa si&#281; do tych punktów i wykonuje podobn&#261; procedur&#281; a&#380; do znalezienia najlepszej
trasy. Algorytm A* ma t&#281; korzystn&#261; w&#322;a&#347;ciwo&#347;&#263;, &#380;e odleg&#322;o&#347;&#263; spodziewana
<!--l. 115--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>h</mi></mstyle></mstyle></math> jest
zawsze mniejsza ni&#380; rzeczywista odleg&#322;o&#347;&#263;, któr&#261; pokonamy. Pozwala to na okre&#347;lenie
w&#322;a&#347;ciwo&#347;ci, która mówi, &#380;e koszt dotarcia do s&#261;siedniego nast&#281;puj&#261;cego w&#281;z&#322;a i
podró&#380; od niego do celu jest zawsze nie wi&#281;ksza ni&#380; bezpo&#347;redni koszt podró&#380;y do
celu z naszego w&#281;z&#322;a. Mo&#380;e si&#281; to wydawa&#263; oczywiste, ale nie musi by&#263; zawsze
zapewnione dla generalnego przypadku wyszukiwania na grafie. Algorytm A* zosta&#322; po raz
pierwszy u&#380;yty w robocie Shakey, który by&#322; robotem poruszaj&#261;cym si&#281; samodzielnie na
ko&#322;ach pomi&#281;dzy pewnymi miejscami. Potrzebowa&#322; wi&#281;c sposobu planowania swojej trasy.
Shakey mia&#322; dostawa&#263; zadanie i by&#263; w stanie rozbi&#263; je na mniejsze cz&#281;&#347;ci, które
b&#281;d&#261; konieczne do realizacji celu. Shakey do realizowania tego celu posiada&#322; kilka
umiej&#281;tno&#347;ci. Potrafi&#322; podró&#380;owa&#263; z jednej lokacji do drugiej (dzi&#281;ki algorytmowi A*),
                                                                                    
                                                                                    
otwiera&#263; drzwi, w&#322;&#261;cza&#263; &#347;wiat&#322;a, popycha&#263; obiekty. Robot posiada&#322; system wizji,
dzi&#281;ki któremu orientowa&#322; si&#281; w otoczeniu. Te umiej&#281;tno&#347;ci pozwala&#322;y mu na
wykonywanie prostych zada&#324;. Shakey by&#322; jednym z pierwszych projektów integruj&#261;cych
robotyk&#281; i AI, u&#380;ywaj&#261;c wiedzy z obu dziedzin do stworzenia autonomicznego
robota.
<a 
 id="x1-26002r26"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">4.6   </span> <a 
 id="x1-270006"></a>MCTS</h3>
<!--l. 119--><p class="noindent" ><span 
class="aeb10-x-x-120">Drzewo poszukiwa</span><span 
class="aeb10-x-x-120">&#324;</span> <span 
class="aeb10-x-x-120">Monte Carlo </span>(ang. Monte Carlo tree search) w skórcie
MCTS, jest metod&#261;, któr&#261; polega w mocny sposób na losowo&#347;ci, st&#261;d Monte
Carlo w nazwie. MCTS nie potrzebuje funkcji warto&#347;ci, poniewa&#380; dokonuje
tzw. <span 
class="aeb10-x-x-120">rozwini&#281;</span><span 
class="aeb10-x-x-120">&#263;</span> (ang. rollout) co oznacza, &#380;e zostaje przeprowadzona symulacja
od li&#347;cia do w&#281;z&#322;a ko&#324;cowego, czyli takiego, który nie ma &#380;adnych w&#281;z&#322;ów
podrz&#281;dnych. Symulacja odbywa si&#281; poprzez wybranie losowej akcji i u&#380;ycie jej i
modelu &#347;wiata do wygenerowania nast&#281;pnej sytuacji. Powtarzamy t&#281; czynno&#347;&#263;,
a&#380; nie dojdziemy do w&#281;z&#322;a ko&#324;cowego. W tym przypadku musimy co prawda
u&#380;y&#263; funkcji warto&#347;ci do okre&#347;lenia sytuacji ko&#324;cowej i nawrócenia warto&#347;ci
do li&#347;cia, jednak w grach, w których ten algorytm jest cz&#281;sto stosowany jest
inaczej. Na ko&#324;cu rozgrywki funkcja warto&#347;ci jest powszechnie znana, poniewa&#380;
jest to rezultat gry, a on musi by&#263; jasno okre&#347;lony w zasadach. Nie musimy
wiedzie&#263; nic wi&#281;cej poza zasadami takiej gry. Tak wi&#281;c np. w przypadku szachów
dokonujemy najpierw losowego posuni&#281;cia dla nas, powiedzmy, poruszamy skoczkiem,
nast&#281;pnie wykonujemy posuni&#281;cie dla przeciwnika, powiedzmy, ruszamy pionkiem.
Kontynuujemy tak na przemian, a&#380; nie dojdziemy przypadkowo do sytuacji, w
której gra jest matem, patem lub remisem. Wtedy okre&#347;lamy warto&#347;&#263; dla
danego w&#281;z&#322;a ko&#324;cowego. Dla szachów mo&#380;e to by&#263; +1, 0 lub -1. Ka&#380;dy w&#281;ze&#322;
utrzymuje informacje o dwóch zmiennych, sumie warto&#347;ci w&#281;z&#322;ów podrz&#281;dnych
<!--l. 119--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> oraz liczbie wizyt w&#281;z&#322;a
<!--l. 119--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>. Kiedy rozwini&#281;cie jest
przeprowadzane to warto&#347;ci <!--l. 119--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math>
i <!--l. 119--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
s&#261; nawracane do w&#281;z&#322;ów nadrz&#281;dnych, a stamt&#261;d do w&#281;z&#322;ów nadrz&#281;dnych
do tych nadrz&#281;dnych itd. Na ka&#380;dym nadrz&#281;dnym poziomie warto&#347;ci
<!--l. 119--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> i
<!--l. 119--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math> s&#261;
zmieniane poprzez dodanie nast&#281;puj&#261;cych warto&#347;ci:
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-27001r5"></a>
                                                                                    
                                                                                    
<!--l. 124--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 124--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-27002"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;4.5:</span><span  
class="content">MCTS</span></figcaption><!--tex4ht:label?: x1-27001r4 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
   <table class="equation"><tr><td> <a 
 id="x1-27003r4"></a>
<!--l. 129--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                <msub><mrow 
><mi 
>&#x03B4;</mi></mrow><mrow 
><mi 
>v</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mstyle 
class="text"><mtext  >value&#x00A0;of&#x00A0;rollout</mtext></mstyle>
</math></td><td class="eq-no">(4.4)</td></tr></table>
   <table class="equation"><tr><td> <a 
 id="x1-27004r5"></a>
<!--l. 132--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                       <msub><mrow 
><mi 
>&#x03B4;</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mn>1</mn>
</math></td><td class="eq-no">(4.5)</td></tr></table>
<!--l. 136--><p class="noindent" >Gdzie <!--l. 136--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> zmienia si&#281; o
warto&#347;&#263; rozwini&#281;cia, a <!--l. 136--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
jest zwi&#281;kszane o 1, co znaczy, &#380;e jedna dodatkowa symulacja zosta&#322;a przeprowadzona.<br 
class="newline" />
</p><!--l. 138--><p class="indent" >   Kiedy rozwini&#281;cie zostaje przeprowadzone to ca&#322;a &#347;cie&#380;ka, która nas do tego miejsca
doprowadzi&#322;a, zostaje wykasowana z pami&#281;ci, a pozostaj&#261; jedynie informacje o
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>&#x03B4;</mi></mrow><mrow 
><mi 
>v</mi></mrow></msub 
></mstyle></mstyle></math> i
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>&#x03B4;</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math>. Te
informacje s&#261; u&#380;ywane do odpowiedniej zmiany warto&#347;ci w&#281;z&#322;ów nadrz&#281;dnych. Na razie
nie powiedzieli&#347;my, sk&#261;d te w&#281;z&#322;y si&#281; bior&#261; i pozostawimy t&#281; informacj&#281; na koniec. Teraz
musisz jedynie wiedzie&#263;, &#380;e tak jak w innych algorytmach poszukiwania te w&#281;z&#322;y istniej&#261; i
s&#261; czym&#347; innym ni&#380; rozwini&#281;cie. Rozwini&#281;cie jest jedynie swego rodzaju próbkowaniem
rzeczywisto&#347;ci. Wszystko, co jest konieczne do takiego próbkowania, zostaje
usuni&#281;te z pami&#281;ci, a zostaj&#261; pozostawione tylko w&#281;z&#322;y, z których przeprowadzamy to
próbkowanie. &#379;eby wybra&#263; kolejny w&#281;ze&#322;, z którego chcemy przeprowadzi&#263; rozwini&#281;cie,
potrzebujemy jakiego&#347; równania, które okre&#347;li nam warto&#347;&#263; rozwini&#281;cia z danego
w&#281;z&#322;a. Co mo&#380;emy zawrze&#263; w takim równaniu? Po pierwsze chcieliby&#347;my, aby
cz&#281;&#347;ciej wizytowane by&#322;y w&#281;z&#322;y, które s&#261; lepsze, czyli maj&#261; wi&#281;ksz&#261; warto&#347;&#263;
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math>, poniewa&#380;
chcemy sprawdzi&#263; czy s&#261; rzeczywi&#347;cie tak dobre jak to ustalili&#347;my. Musimy jednak pami&#281;ta&#263;, &#380;e
                                                                                    
                                                                                    
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> b&#281;dzie zale&#380;e&#263;
od warto&#347;ci <!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
czyli ilo&#347;ci takich rozwini&#281;&#263;. Tak wi&#281;c dobrze by&#322;oby, gdyby to równanie zale&#380;a&#322;o od
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>n</mi></mstyle></mstyle></math>. Taka jest
te&#380; pierwsza cz&#281;&#347;&#263; równania. Je&#347;li jednak zawarliby&#347;my tylko te informacje, to &#8216;dobre&#8217;
w&#281;z&#322;y by&#322;yby jedynymi odwiedzanymi. Mo&#380;e si&#281; jednak zdarzy&#263; tak, &#380;e jedna symulacja,
jedno rozwini&#281;cie jest z&#322;e, ale wszystkie inne wypad&#322;yby dobrze. Z funkcj&#261; wybieraj&#261;c&#261; w&#281;z&#322;y
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>n</mi></mstyle></mstyle></math> do
rozwini&#281;cia nie jest mo&#380;liwe, &#380;eby sprawdzi&#263; w&#281;ze&#322;, któremu si&#281; nie poszcz&#281;&#347;ci&#322;o. Tak
wi&#281;c dodana jest druga cz&#281;&#347;&#263; tego równania, która zale&#380;y od ilo&#347;ci odwiedzin
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
w stosunku do wszystkich przeprowadzonych rozwini&#281;&#263;
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi></mstyle></mstyle></math>. Druga cz&#281;&#347;&#263;
równania ma form&#281;: <!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msqrt><mrow><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>l</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>N</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>n</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow></msqrt></math>.
Ta druga cz&#281;&#347;&#263;&#x00A0;równania odpowiada za pewno&#347;&#263; na temat wielko&#347;ci
<!--l. 138--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math>, im
wi&#281;cej próbkowa&#324;, tym bardziej jest ona pewna. Ca&#322;e równanie za&#347; przedstawia si&#281;
nast&#281;puj&#261;co:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-27005r6"></a>
<!--l. 140--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                          <mi 
>U</mi><mi 
>C</mi><mi 
>B</mi><mn>1</mn> <mo 
class="MathClass-rel">=</mo> <mi 
>v</mi><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>n</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>c</mi> <mo 
class="MathClass-bin">*</mo><msqrt><mrow><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>l</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>N</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>n</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow></msqrt>
</math></td><td class="eq-no">(4.6)</td></tr></table>
<!--l. 144--><p class="noindent" >&#379;eby wybra&#263; kolejny w&#281;ze&#322;, w którym chcemy przeprowadzi&#263; rozwini&#281;cie, musimy
znale&#378;&#263; w&#281;ze&#322; z najwi&#281;ksz&#261; warto&#347;ci&#261; UCT, która mo&#380;e by&#263; równa np. UCB1. Tu
<!--l. 144--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> i
<!--l. 144--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math> s&#261; warto&#347;ci&#261; w&#281;z&#322;a i
ilo&#347;ci&#261; rozwini&#281;&#263; z w&#281;z&#322;a, <!--l. 144--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>c</mi></mstyle></mstyle></math>
jest sta&#322;&#261; wymiany pomi&#281;dzy pierwszym a drugim wyra&#380;eniem, a
<!--l. 144--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi></mstyle></mstyle></math> jest
liczb&#261; wszystkich przeprowadzonych symulacji w ca&#322;ym drzewie. UCB1 sprawia, &#380;e
odwiedzane s&#261; te w&#281;z&#322;y posiadaj&#261;ce najwy&#380;sz&#261; warto&#347;&#263; oraz te, które by&#322;y rzadko
odwiedzane.<br 
class="newline" />
                                                                                    
                                                                                    
</p><!--l. 146--><p class="indent" >   Pozosta&#322;a nam ostatnia rzecz: je&#347;li napotykamy na w&#281;ze&#322;, którego
<!--l. 146--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math> jest
wi&#281;ksze od zera, to znaczy jakie&#347; rozwini&#281;cie by&#322;o poprzednio wykonane z tego w&#281;z&#322;a, wtedy
rozwijamy w&#281;ze&#322; o wszystkie akcje, które mo&#380;emy wykona&#263;. Np. w przyk&#322;adzie
szachowym tworzymy w&#281;z&#322;y podrz&#281;dne zawieraj&#261;ce wszystkie posuni&#281;cia konikiem, pionkiem,
wie&#380;&#261; itd. Jest to proces dok&#322;adnie taki sam jak w poprzednich algorytmach, tylko &#380;e dla
jednego poziomu. Nast&#281;pnie wybieramy w&#281;ze&#322; z najwi&#281;kszym UCT, w tym wypadku UCT s&#261;
jednak równe, bo n = 0 wi&#281;c UCB1 = inf., tak wi&#281;c pozostaje nam wybra&#263; w&#281;ze&#322;
spo&#347;ród w&#281;z&#322;ów podrz&#281;dnych zgodnie z kolejno&#347;ci&#261; alfabetyczn&#261;. Z tego w&#281;z&#322;a
przeprowadzamy kolejne rozwini&#281;cie. Ostatecznie po przeprowadzeniu wielu rozwini&#281;&#263;,
&#380;eby wybra&#263; ruch, wybieramy spo&#347;ród w&#281;z&#322;ów podrz&#281;dnych do korzenia, czyli naszego
pocz&#261;tkowego w&#281;z&#322;a. Wybieramy ten w&#281;ze&#322; z najwi&#281;ksz&#261; warto&#347;ci&#261; rozwini&#281;&#263;
<!--l. 146--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>, ale
tylko dla w&#281;z&#322;ów bezpo&#347;rednio podrz&#281;dnych. Poszukiwanie Monte Carlo wraz ze
wzrastaj&#261;c&#261; liczb&#261; rozwini&#281;&#263; zbiega si&#281; do optymalnego rozwi&#261;zania.
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p><!--l. 1--><p class="indent" >   <a 
href="#x1-280005">5<!--tex4ht:ref: chap:reinforcement --></a>
                                                                                    
                                                                                    
</p><!--l. 2--><p class="indent" >
                                                                                    
                                                                                    
</p>
   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;5</span><br /><a 
 id="x1-280005"></a>Uczenie ze wzmocnieniem</h2>
<!--l. 5--><p class="noindent" >W przesz&#322;o&#347;ci by&#322;o wiele prób zbudowania przeró&#380;nych kognitywnych architektur. Mia&#322;y
one tworzy&#263; unifikuj&#261;cy obraz dzia&#322;ania mózgu lub oddawa&#263; w jaki&#347; sposób jego
dzia&#322;anie. Te modele by&#322;y cz&#281;sto lu&#378;no inspirowane pewnymi spostrze&#380;eniami na temat
funkcjonowania mózgu i by&#322;y nastawione na przybli&#380;enie generalnych metod jego
dzia&#322;ania. Zazwyczaj takie modele wymaga&#322;y tak&#380;e ogromnych zbiorów stwierdze&#324; na
temat &#347;wiata w duchu symbolicznego AI. My co prawda w rozdziale o symbolicznym AI
skupili&#347;my si&#281; na mo&#380;e pobocznym temacie, jakim s&#261; drzewa poszukiwa&#324;, ale w tym
dziale cz&#281;sto korzysta si&#281; ze stwierdze&#324; zapisanych w formie logiki, tak jak to
powiedzieli&#347;my na pocz&#261;tku tamtego rozdzia&#322;u. Takie symboliczne podej&#347;cie ma swoje
plusy, wykorzystuje, chocia&#380;by aparat matematyczny do okre&#347;lania warto&#347;ci stwierdze&#324;
jest jednak zbyt sztywne dla wi&#281;kszo&#347;ci rozwi&#261;za&#324;. Sam spróbuj zapisa&#263; informacje na
jaki&#347; temat za pomoc&#261; samych stwierdze&#324;, &#380;eby przekona&#263; si&#281;, &#380;e nie jest to &#322;atwe
zadanie. Tak wi&#281;c systemy te wymaga&#322;y ogromnych zbiorów twierdze&#324;. Dzia&#322;o si&#281; tak,
poniewa&#380; te systemy nie posiada&#322;y w&#322;asnego mechanizmu interpretacji tego, co
dzieje si&#281; w &#347;wiecie i wyci&#261;gania z tego wniosków. Mo&#380;na powiedzie&#263;, &#380;e pod
pewnymi wzgl&#281;dami te systemy by&#322;y nawet w tyle za robotem Shakey, który potrafi&#322;
interpretowa&#263; swój prosty &#347;wiat. Niektóre takie projekty zu&#380;y&#322;y tysi&#261;ce godzin pracy
wolontariuszy, &#380;eby zwi&#281;kszy&#263; pojemno&#347;&#263; baz danych na temat &#347;wiata, z
nadziej&#261;, &#380;e je&#347;li uchwyc&#261; ich wystarczaj&#261;c&#261; ilo&#347;&#263;, to te systemy b&#281;d&#261; mog&#322;y
rozumowa&#263; jak ludzie. Okazuje si&#281;, jednak &#380;e nikt nie mówi nam nigdy, co si&#281;
stanie, je&#347;li b&#281;dziemy biec ulic&#261; z pe&#322;nym wiadrem wody, a jednak wiemy, &#380;e
nasze nogi b&#281;d&#261; mokre. Z tego i innych powodów, miliony relacji pó&#378;niej ten
wysi&#322;ek zdaje si&#281; bezowocny. Ignorowanie motywacji, uczu&#263;, emocji i stanów
umys&#322;u mog&#322;o by&#263; fundamentalnym powodem pora&#380;ki tych wysi&#322;ków. Jest
jednak bardziej podstawowy problem z takim podej&#347;ciem. Tworzenie du&#380;ego
systemu z wielu wcze&#347;niej zdefiniowanych zasad nie jest proste ze wzgl&#281;du na
wyst&#281;puj&#261;ce mi&#281;dzy nimi interakcje. Wyobra&#378; sobie, &#380;e próbujesz zbudowa&#263;
samochód od podstaw, nie wiedz&#261;c nawet jakie systemy i funkcjonalno&#347;ci powinny
zosta&#263; dodane. Ta metafora oddaje bezsens próby skonstruowania kopii mózgu od
podstaw bez posiadania planu. To podej&#347;cie nie pozwala na testowanie cz&#281;&#347;ci przed
dodaniem ich do wi&#281;kszego systemu i nieprawid&#322;owe dzia&#322;anie jednej z nich oznacza,
&#380;e ca&#322;o&#347;&#263; nadaje si&#281; do wyrzucenia, poniewa&#380; nie wiemy która cz&#281;&#347;&#263; jest
odpowiedzialna za niepowodzenie. Pracuj&#261;c obok tych wysi&#322;ków byli naukowcy tacy
jak Richard Sutton, którzy próbowali odkry&#263; podstawowe zasady kieruj&#261;ce
zachowaniem inteligentnych systemów. Powzi&#281;li oni podej&#347;cie matematyczne,
patrz&#261;c si&#281; na umys&#322; tylko w celu inspiracji. Te wysi&#322;ki okazuj&#261; si&#281; dzisiaj du&#380;o
bardziej skuteczne. Niektóre z nich zdaj&#261; si&#281; nawet wyja&#347;nia&#263; niektóre zjawiska
wyst&#281;puj&#261;ce w naszej czaszce, jak np. uczenie TD, które zosta&#322;o po&#322;&#261;czone z dzia&#322;aniem
                                                                                    
                                                                                    
systemu dopaminergicznego. Du&#380;&#261; przewag&#261; tego podej&#347;cia jest równie&#380; to, &#380;e
uczenie ze wzmocnieniem, poniewa&#380; u&#380;ywa pewnych poj&#281;&#263; wyst&#281;puj&#261;cych w
innych dziedzinach sztucznej inteligencji, mo&#380;e by&#263; do&#347;&#263; &#322;atwo po&#322;&#261;czone do
innych odkry&#263; takich jak sieci neuronowe. To oferuje efekt synergii i &#322;atwo&#347;&#263;
konceptualn&#261;.
<a 
 id="x1-28001r27"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">5.1   </span> <a 
 id="x1-290001"></a>Problem uczenia ze wzmocnieniem</h3>
<!--l. 9--><p class="noindent" >Jak jednak mo&#380;emy zdefiniowa&#263; dzia&#322;anie ca&#322;ego inteligentnego systemu, jakim jest nasz
mózg za pomoc&#261; kilku prostych zasad? Uczenie ze wzmocnieniem (ang. reinforcement
learning albo RL w skrócie) identyfikuje kilka niezb&#281;dnych sk&#322;adników koniecznych dla
inteligentnego zachowania. Na pocz&#261;tek potrzebujemy pewnych informacji koniecznych,
&#380;eby podj&#261;&#263; decyzj&#281;. Ta w&#322;a&#347;ciwo&#347;&#263; jest nazywana <span 
class="aeb10-x-x-120">stanem</span>. Nast&#281;pnie potrzebujemy
aktora. Aktor jest osob&#261;, zwierz&#281;ciem, robotem, który u&#380;ywa informacji o stanie, &#380;eby
podejmowa&#263; decyzje. Aktor otrzymuje <span 
class="aeb10-x-x-120">nagrod&#281; </span>po ka&#380;dej zmianie stanu lub po pewnej
serii stanów. Nagroda jest podobna do zjawiska przyjemno&#347;ci i bólu, tak wi&#281;c aktor lubi
zwi&#281;ksza&#263; ilo&#347;&#263; nagrody. Ostatecznie aktor mo&#380;e podejmowa&#263; pewne <span 
class="aeb10-x-x-120">akcje </span>które
wp&#322;ywaj&#261; w jaki&#347; sposób na stan. Te akcje mog&#261; by&#263;: przesuni&#281;ciem bierki
w szachach, kierunek ruchu ramienia robota lub mo&#380;e wybranie problemu, nad
którym powinno si&#281; pracowa&#263;. Ten proces mo&#380;e by&#263; zwizualizowany jako
pewnego rodzaju okr&#261;g, w którym informacje p&#322;yn&#261; od &#347;rodowiska do aktora i do
aktora do &#347;rodowiska. Akcje aktora s&#261; modyfikowane przez nap&#322;ywaj&#261;cy sygna&#322;
nagrody.<br 
class="newline" />
</p><!--l. 11--><p class="noindent" >S&#261; jeszce dwa inne kluczowe elementy problemu RL. Tak zwany <span 
class="aeb10-x-x-120">zbi</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">r zasad </span>(ang. policy)
jest pierwsz&#261; z nich. Zbiór zasad okre&#347;la dla ka&#380;dego stanu akcje, które zostan&#261; podj&#281;te
przez aktora. Tak wi&#281;c mo&#380;na my&#347;le&#263; o zbiorze zasad, jak o wyniku dzia&#322;ania
mózgu.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-29001r1"></a>
<!--l. 13--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                       <mi 
>p</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-rel">|</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.1)</td></tr></table>
                                                                                    
                                                                                    
<!--l. 17--><p class="noindent" >Zbiór zasad <!--l. 17--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>p</mi></mstyle></mstyle></math> dla
danego stanu <!--l. 17--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>s</mi></mstyle></mstyle></math> przy
podj&#281;ciu akcji <!--l. 17--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>a</mi></mstyle></mstyle></math>.<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-29002r1"></a>
                                                                                    
                                                                                    
<!--l. 22--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 22--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-29003"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;5.1:</span><span  
class="content">Problem uczenia ze wzmocnieniem</span></figcaption><!--tex4ht:label?: x1-29002r5 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 27--><p class="noindent" >Mo&#380;emy te&#380; zidentyfikowa&#263; funkcj&#281; warto&#347;ci. Poprzednio mówili&#347;my o funkcji
warto&#347;ci, ale dla problemu RL mo&#380;emy okre&#347;li&#263; pewne jej dodatkowe w&#322;a&#347;ciwo&#347;ci.
Funkcja warto&#347;ci jest sum&#261; wszystkich sygna&#322;ów nagrody od teraz od ostatniego
wyst&#281;puj&#261;cego stanu. Mo&#380;emy to zapisa&#263; jako:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-29004r2"></a>
<!--l. 29--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                         <mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>a</mi><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>&#x2026;</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.2)</td></tr></table>
<!--l. 33--><p class="noindent" >Gdzie <!--l. 33--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> jest funkcj&#261; warto&#347;ci,
<!--l. 33--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math> s&#261; akcjami, które
podejmuje aktor, a <!--l. 33--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>n</mi></mrow></msub 
></mstyle></mstyle></math> jest
sygna&#322;em nagrody w kroku <!--l. 33--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>.
Wa&#380;ne jest, &#380;eby zobaczy&#263;, &#380;e chcieliby&#347;my zna&#263; funkcj&#281; warto&#347;ci, poniewa&#380;
powiedzia&#322;aby nam ona, ile nagrody otrzymamy w przysz&#322;o&#347;ci.
<a 
 id="x1-29005r29"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">5.2   </span> <a 
 id="x1-300002"></a>Wielor&#281;czny bandyta</h3>
<!--l. 38--><p class="noindent" >Wyja&#347;nili&#347;my, &#380;e ca&#322;e my&#347;lenie aktora mo&#380;e by&#263; podsumowane jako zbiór zasad.
Je&#347;li znaliby&#347;my optymalny zbiór zasad, to mogliby&#347;my osi&#261;gn&#261;&#263; najwy&#380;sze
mo&#380;liwe nagrody od teraz do ko&#324;ca wszech&#347;wiata. Problemem jest jednak to, &#380;e
wi&#281;kszo&#347;&#263; aktorów wie, na pocz&#261;tku, bardzo ma&#322;o o funkcjonowaniu &#347;rodowiska, w
którym si&#281; znajduj&#261;, wi&#281;c nie s&#261; w stanie powiedzie&#263;, co jest dla nich najkorzystniejsze. Co
powinien zrobi&#263; taki aktor, &#380;eby sta&#263; si&#281; lepszym w poszukiwaniu nagrody? Wyobra&#378;
sobie bycie w ogromnym kasynie, gdzie znajduje si&#281; wiele automatów do gier zwanych
powszechnie jednor&#281;cznymi bandytami (prawdopodobnie dlatego, &#380;e ka&#380;dy, kto wchodzi w
bliski kontakt z tak&#261; maszyn&#261;, zostaje ograbiony). W tym kasynie jest wiele ró&#380;nych
maszyn, ka&#380;da daj&#261;ca inn&#261; spodziewan&#261; wygran&#261;. My chcemy znale&#378;&#263; tak&#261;, która da
nam wygra&#263; lub nie przegra&#263;, jak najwi&#281;ksz&#261; ilo&#347;&#263; pieni&#281;dzy. Mo&#380;e brzmi
to tylko jak &#322;adna metafora, ale tak opisany problem nazywany jest problemem
<span 
class="aeb10-x-x-120">wielor&#281;cznego bandyty </span>(ang. multi-armed bandit). Zastanówmy si&#281; teraz nad najlepsz&#261;
strategi&#261; dzia&#322;ania w takim kasynie. Na pocz&#261;tku nic nie wiemy o maszynach,
                                                                                    
                                                                                    
tak&#380;e konieczne jest, &#380;eby&#347;my dokonali pewnej ilo&#347;ci eksploracji, to znaczy, &#380;e
koniecznym jest aby poci&#261;gn&#261;&#263; wajchy nale&#380;&#261;ce do wielu jednor&#281;cznych bandytów w
poszukiwaniu takiego, który daje dobre nagrody. W ten sposób mo&#380;emy znale&#378;&#263;
najbardziej op&#322;acaln&#261; maszyn&#281;, ale je&#347;li tylko eksplorujemy, to nie otrzymamy
korzy&#347;ci wynikaj&#261;cych z wykorzystania takiej maszyny, czyli eksploatacji. Strategia,
która zawiera te dwie korzy&#347;ci, czyli eksploracj&#281; i eksploatacj&#281; nazywana jest
<span 
class="aeb10-x-x-120">epsilon-chciwa </span>(ang. epsilon greedy). Okre&#347;la ona, &#380;e powinni&#347;my eksplorowa&#263; przez
<!--l. 38--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>e</mi></mstyle></mstyle></math>
ilo&#347;&#263; czasu i eksploatowa&#263; to, czego si&#281; nauczyli&#347;my przez
<!--l. 38--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mn>1</mn> <mo 
class="MathClass-bin">-</mo> <mi 
>e</mi></mstyle></mstyle></math> ilo&#347;&#263;
czasu. U&#380;ywaj&#261;c strategii epsilon-chciwej, b&#281;dziemy otrzymywa&#263; wy&#380;sze nagrody, wraz z
tym, jak b&#281;dziemy si&#281; stawa&#263; lepsi w danym zadaniu. Wynika to oczywi&#347;cie z faktu, &#380;e
wykonujemy co jaki&#347; czas faz&#281; eksploatacji, w ci&#261;gu której wykorzystujemy najlepszy automat.
Jak ustali&#263; przez ile czasu powinno si&#281; to jednak odbywa&#263;? Zazwyczaj ustawiliby&#347;my
<!--l. 38--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>e</mi></mstyle></mstyle></math>
tak, &#380;eby równa&#322;a si&#281; pewnej ma&#322;ej warto&#347;ci takiej, jak
<!--l. 38--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>e</mi></mstyle></mstyle></math>=0.1.
To oznacza, &#380;e eksplorujemy przez tylko 10% czasu. W d&#322;ugim okresie wystarczy to jednak
do znalezienia optymalnego rozwi&#261;zania. Jednym problemem tego podej&#347;cia jest
to, &#380;e nawet je&#347;li znamy spodziewan&#261; warto&#347;&#263; ka&#380;dej z maszyn z wielk&#261;
dok&#322;adno&#347;ci&#261;, to nadal b&#281;dziemy zmuszeni po&#347;wi&#281;ca&#263; 10% czasu na eksplorowanie, co
b&#281;dzie nas powstrzymywa&#263; przed otrzymaniem najwy&#380;szej mo&#380;liwej nagrody. Tu
pojawia si&#281; modyfikacja strategii epsilon-chciwej. W niej b&#281;dziemy zmniejsza&#263;
<!--l. 38--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>e</mi></mstyle></mstyle></math> po pewnej
ilo&#347;ci <!--l. 38--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi></mstyle></mstyle></math>
prób. Za ka&#380;dym razem, gdy wykonali&#347;my wielokrotno&#347;&#263;
<!--l. 38--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi></mstyle></mstyle></math> prób
zmniejszymy epsilon, u&#380;ywaj&#261;c równania:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-30001r3"></a>
<!--l. 40--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                      <mi 
>e</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>y</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>e</mi>
</math></td><td class="eq-no">(5.3)</td></tr></table>
<!--l. 44--><p class="noindent" >Gdzie <!--l. 44--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>y</mi></mstyle></mstyle></math>
                                                                                    
                                                                                    
jest pewn&#261; warto&#347;ci&#261; pomi&#281;dzy 0 a 1.<br 
class="newline" />
</p><!--l. 46--><p class="indent" >   To pozwoli nam wykonywa&#263; mniej i mniej eksploracji, w miar&#281; tego, jak stajemy si&#281; lepsi w
wykonywaniu zadania, jednocze&#347;nie zwi&#281;kszaj&#261;c nasz&#261; nagrod&#281; albo jak w przypadku
jednor&#281;cznych bandytów &#8211; zyski. Jest jeszcze jedna rzecz, któr&#261; mogliby&#347;my zrobi&#263;.
Je&#347;li znamy najwy&#380;sz&#261; mo&#380;liw&#261; warto&#347;&#263; funkcji warto&#347;ci, to mo&#380;emy zmniejsza&#263;
parametr <!--l. 46--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>e</mi></mstyle></mstyle></math>
proporcjonalnie do poprawy w funkcji warto&#347;ci. Jest to pewnego rodzaju strategia
równowa&#380;enia ilo&#347;ci eksploracji z wielko&#347;ci&#261; funkcji warto&#347;ci. To pozwoli nam
przeznacza&#263; na eksploracj&#281; ilo&#347;&#263; czasu równ&#261; procentowi nieosi&#261;gni&#281;tej maksymalnej
warto&#347;ci. Je&#347;li funkcja warto&#347;ci osi&#261;gn&#281;&#322;a np. 30%, to eksplorujemy przez 70% czasu.
Kiedy poprawimy si&#281;, w tym co robimy, to zmniejszymy ilo&#347;&#263; eksploracji, bo
b&#281;dzie ona mniej korzystna, jako &#380;e cz&#281;&#347;ciowo wiemy ju&#380; jak osi&#261;ga&#263; pewien
procent warto&#347;ci. Przed wprowadzeniem jeszcze jednego sposobu powtórzmy to,
czego ju&#380; si&#281; nauczyli&#347;my, a mianowicie, &#380;e funkcja warto&#347;ci jest zdefiniowana
jako:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-30002r4"></a>
<!--l. 48--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                         <mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>a</mi><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>&#x2026;</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.4)</td></tr></table>
<!--l. 52--><p class="noindent" >Podane równanie, &#380;eby otrzyma&#263; funkcj&#281; warto&#347;ci, sumuje wszystkie
nagrody od teraz do niesko&#324;czono&#347;ci z równ&#261; wag&#261;. Jednak w
prawdziwym &#380;yciu troszczymy si&#281; du&#380;o bardziej o nagrod&#281; w momencie
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
></mstyle></mstyle></math> ni&#380; t&#261; w
momencie <!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn></mrow></msub 
></mstyle></mstyle></math>
Dlaczego tak si&#281; dzieje? Jednym z powodów jest zapewne fakt, &#380;e przysz&#322;o&#347;&#263; nie jest
tak pewna, jak tera&#378;niejszo&#347;&#263;, wi&#281;c z ch&#281;ci&#261; zamienimy nagrod&#281; daleko na horyzoncie na
mniej oddalon&#261;, bo ta odleg&#322;a mo&#380;e nigdy nie nadej&#347;&#263;. Dlatego powinni&#347;my
doda&#263; pewien parament okre&#347;laj&#261;cy pewno&#347;&#263; co do przysz&#322;o&#347;ci. Nazwijmy go
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi></mstyle></mstyle></math>
tak jak we wspó&#322;czynniku dyskontowym. Pomnó&#380;my
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
></mstyle></mstyle></math> przez
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi></mstyle></mstyle></math>,
                                                                                    
                                                                                    
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>2</mn></mrow></msub 
></mstyle></mstyle></math> przez
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi></mstyle></mstyle></math>,
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>3</mn></mrow></msub 
></mstyle></mstyle></math> przez
<!--l. 52--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi></mstyle></mstyle></math>
itd.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-30003r5"></a>
<!--l. 54--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                      <mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>a</mi><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>1</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <mi 
>d</mi><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-bin">+</mo><mn>2</mn></mrow></msub 
> <mo 
class="MathClass-bin">*</mo> <msup><mrow 
><mi 
>d</mi></mrow><mrow 
><mn>2</mn></mrow></msup 
><mo 
class="MathClass-punc">,</mo><mi 
>&#x2026;</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.5)</td></tr></table>
<!--l. 58--><p class="indent" >   To jest bardziej realistyczny pogl&#261;d na nasz&#261; funkcj&#281; warto&#347;ci. Teraz pami&#281;taj&#261;c o tym,
mo&#380;emy stworzy&#263; sie&#263; neuronow&#261;, która b&#281;dzie przybli&#380;a&#263; t&#281; funkcj&#281; warto&#347;ci.
Maj&#261;c t&#281; sie&#263;, b&#281;dziemy eksploatowa&#263; wielor&#281;cznego bandyt&#281;, u&#380;ywaj&#261;c sieci neuronowej
do aproksymacji jako&#347;ci ka&#380;dego jednor&#281;cznego bandyty. To podej&#347;cie jednak nie
zadzia&#322;a, poniewa&#380; nie dali&#347;my naszej sieci &#380;adnych przyk&#322;adów do trenowania. Dlatego
nadal potrzebujemy eksplorowa&#263;, &#380;eby uzyska&#263; przyk&#322;ady, na których b&#281;dziemy
trenowa&#263;. Wytrenujemy tak&#261; sie&#263;, podaj&#261;c przyk&#322;ady sytuacji, które napotkali&#347;my i
odpowiadaj&#261;c&#261; im sum&#281; nagród jak pokazano wy&#380;ej. &#379;eby wybra&#263; pomi&#281;dzy stanem
eksploracji i eksploatacji, u&#380;yjemy formu&#322;y UCT takiej jak w podrozdziale 4.6
dotycz&#261;cym MCTS. Dla ka&#380;dego "bandyty" obliczymy i wybierzemy tego z najwy&#380;sz&#261;
warto&#347;ci&#261;:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-30004r6"></a>
<!--l. 60--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                            <mi 
>U</mi><mi 
>C</mi><mi 
>B</mi><mn>1</mn> <mo 
class="MathClass-rel">=</mo> <mi 
>v</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>c</mi> <mo 
class="MathClass-bin">*</mo><msqrt><mrow><mi 
>l</mi><mi 
>n</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>N</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>n</mi></mrow></msqrt>
</math></td><td class="eq-no">(5.6)</td></tr></table>
<!--l. 64--><p class="noindent" >Gdzie <!--l. 64--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> b&#281;dzie rezultatem
otrzymanym z naszej sieci, <!--l. 64--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>c</mi></mstyle></mstyle></math>
                                                                                    
                                                                                    
sta&#322;&#261; eksploracji, <!--l. 64--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi></mstyle></mstyle></math>
ca&#322;kowit&#261; liczb&#261; prób, a <!--l. 64--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
ilo&#347;ci&#261; prób wykonanych na konkretnym automacie.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-30005r2"></a>
                                                                                    
                                                                                    
<!--l. 69--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 69--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-30006"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;5.2:</span><span  
class="content">Wielor&#281;czny bandyta</span></figcaption><!--tex4ht:label?: x1-30005r5 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-30007r30"></a>
<h3 class="sectionHead"><span class="titlemark">5.3   </span> <a 
 id="x1-310003"></a>MDP</h3>
<!--l. 76--><p class="noindent" >&#321;a&#324;cuch Markowa jest modelem &#347;rodowiska, w którym nast&#281;pny stan zale&#380;y tylko od
obecnego stanu i od prawdopodobie&#324;stwa zmiany tego stanu. Z tego powodu jest nazywany
procesem stochastycznym. Wyobra&#378;my sobie, dla przyk&#322;adu, przewidywanie pogody. Nasz
model mo&#380;e pokazywa&#263;, &#380;e je&#347;li mamy &#322;adn&#261; pogod&#281; to wyst&#281;puje 7% szansy na to, &#380;e
jutro b&#281;dzie pada&#263;. Je&#347;li jednak ju&#380; dzisiaj pada, to wyst&#281;puje 13% szansy, &#380;e pojawi
si&#281; burza, 36% szansy, &#380;e jutro te&#380; b&#281;dzie pada&#263; i 51% szans, &#380;e jutro si&#281; rozpogodzi.
Taki model jest w&#322;a&#347;nie nazywany &#322;a&#324;cuchem Markowa. Mo&#380;e on si&#281; jednak sk&#322;ada&#263; z
wielu wi&#281;cej stanów i przej&#347;&#263; mi&#281;dzy nimi. Mo&#380;emy zaprezentowa&#263; taki
model graficznie jako graf z w&#281;z&#322;ami stanu po&#322;&#261;czonymi kraw&#281;dziami zwi&#261;zanymi z
prawdopodobie&#324;stwem.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-31001r7"></a>
<!--l. 78--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                       <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>S</mi><mo 
class="MathClass-punc">,</mo><mi 
>P</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.7)</td></tr></table>
<!--l. 82--><p class="noindent" ><!--l. 82--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>S</mi></mstyle></mstyle></math> jest
stanem, <!--l. 82--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>P</mi></mstyle></mstyle></math>
jest prawdopodobie&#324;stwem zmiany stanu.<br 
class="newline" />
</p><!--l. 84--><p class="noindent" ><span 
class="aeb10-x-x-120">Problem decyzyjny Markowa </span>(ang. Markov decision process, MDP dla krótko&#347;ci zapisu)
jest rozszerzeniem pomys&#322;u &#322;a&#324;cucha Markowa, które dodaje akcje i nagrody. Ten model
jest wyj&#261;tkowo podatny na idee uczenia ze wzmocnieniem. W MDP mamy stany, które
prowadz&#261; z pewnym prawdopodobie&#324;stwem do akcji, które znów prowadz&#261;
z innymi prawdopodobie&#324;stwami do pewnych stanów. Ka&#380;da zmiana stanu
zwi&#261;zana jest z nagrod&#261;. Rozszerzmy nas przyk&#322;ad dot. pogody o jej przewidywanie.
Powiedzmy, &#380;e je&#347;li jest &#322;adna pogoda i poprawnie przewidzimy, &#380;e jutro te&#380;
b&#281;dzie &#322;adna, to otrzymujemy nagrod&#281; +1. Je&#347;li jednak przewidzimy, &#380;e b&#281;dzie
&#322;adnie, a w rzeczywisto&#347;ci b&#281;dzie pada&#263;, to otrzymujemy nagrod&#281; -2. Nast&#281;pnie
przechodzimy do kolejnego stanu, w zale&#380;no&#347;ci od tego, co rzeczywi&#347;cie si&#281; sta&#322;o i tak,
je&#347;li trafimy np. na deszcz, to otrzymujemy nagrod&#281; -2, przesuwamy si&#281; do w&#281;z&#322;a
                                                                                    
                                                                                    
z deszczem. Teraz mamy 3 przewidywania: &#322;adna pogoda, deszcz, burza. Je&#347;li
przewidzimy &#322;adn&#261; pogod&#281;, to otrzymujemy +2, je&#347;li to samo zrobimy z deszczem
to +3, je&#347;li przewidzimy burz&#281; +5. Jednak je&#347;li nie uda si&#281; nam przewidzie&#263;
sytuacji, to otrzymamy -1 za &#378;le przewidzian&#261; &#322;adn&#261; pogod&#281;, -2 za deszcz i -5
za burz&#281;. Nast&#281;pnie przechodzimy do kolejnego w&#281;z&#322;a, wed&#322;ug tego, co naprawd&#281;
si&#281; wydarzy&#322;o. Je&#347;li zdarzy&#322;a si&#281; akurat burza, to ko&#324;czymy, bo od burzy, w
naszym przyk&#322;adzie, nie prowadz&#261; &#380;adne strza&#322;ki. Oznacza to, &#380;e jest ona w&#281;z&#322;em
ko&#324;cowym.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-31002r8"></a>
<!--l. 86--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                    <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>S</mi><mo 
class="MathClass-punc">,</mo><mi 
>A</mi><mo 
class="MathClass-punc">,</mo><mi 
>P</mi><mo 
class="MathClass-punc">,</mo><mi 
>R</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.8)</td></tr></table>
<!--l. 90--><p class="noindent" ><!--l. 90--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>S</mi></mstyle></mstyle></math> jest
stanem, <!--l. 90--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>P</mi></mstyle></mstyle></math>
jest prawdopodobie&#324;stwem zmiany stanu, tak jak w &#322;a&#324;cuchu Markowa,
<!--l. 90--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>A</mi></mstyle></mstyle></math> s&#261; akcjami, które
aktor mo&#380;e wybra&#263;, a <!--l. 90--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>R</mi></mstyle></mstyle></math>
s&#261; nagrodami zwi&#261;zanymi z przesz&#322;ym i obecnym stanem.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-31003r3"></a>
                                                                                    
                                                                                    
<!--l. 95--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 95--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-31004"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;5.3:</span><span  
class="content">Przyk&#322;adowe przej&#347;cia mi&#281;dzy stanami MDP</span></figcaption><!--tex4ht:label?: x1-31003r5 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-31005r31"></a>
<h3 class="sectionHead"><span class="titlemark">5.4   </span> <a 
 id="x1-320004"></a>Uczenie Monte-Carlo</h3>
<!--l. 102--><p class="noindent" >Jedn&#261; z metod uczenia zbioru zasad oraz funkcji warto&#347;ci jest <span 
class="aeb10-x-x-120">uczenie Monte-Carlo</span>.
Dzia&#322;a ono poprzez patrzenie si&#281; jak&#261; kumulatywn&#261; nagrod&#281; nast&#281;puj&#261;c&#261; po stanie
<!--l. 102--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>s</mi></mstyle></mstyle></math>
otrzyma&#322; aktor. Jest to niedok&#322;adne przybli&#380;enie funkcji warto&#347;ci. Jak pami&#281;tamy, suma
wszystkich nagród jest równa funkcji warto&#347;ci. Mog&#322;oby si&#281; nam wydawa&#263;, &#380;e suma
nagród b&#281;dzie dok&#322;adnie odzwierciedla&#263; funkcj&#281; warto&#347;ci i mo&#380;emy uczy&#263; na tych
pojedynczych przyk&#322;adach z powodzeniem. Tak jednak nie jest, poniewa&#380; po nast&#261;pieniu
wydarzenia, które &#347;ledzimy, nast&#281;puj&#261; te&#380; inne wydarzenia, które maj&#261; wp&#322;yw na wynik
sumy nagród. Dlatego bierzemy &#347;redni&#261; z wielu takich wydarze&#324;, aby otrzyma&#263;
przybli&#380;ony wynik funkcji warto&#347;ci. Je&#347;li we&#378;miemy wiele przyk&#322;adów to wydarzenia
nast&#281;puj&#261;ce po naszym wydarzeniu, którym jeste&#347;my zainteresowani, si&#281; u&#347;redni&#261;. To
sprawi, &#380;e przewidywanie b&#281;dzie bli&#380;sze rzeczywistej oczekiwanej warto&#347;ci wydarzenia.
Dodawanie kolejnych przyk&#322;adów do naszego przewidywania na temat jednego
wydarzenia daje nam lepsze i lepsze prognozy na temat rzeczywistej funkcji warto&#347;ci.
Jest jednak pewien problem z tym podej&#347;ciem. Chodzi tu o sposób sumowania
nagród. Jak mo&#380;emy zsumowa&#263; nieko&#324;cz&#261;ce si&#281; nagrody? Jednym z problemów
uczenia Monte-Carlo jest to, &#380;e historia potrzebuje mie&#263; punkt ko&#324;cowy. Dzieje
si&#281; tak, poniewa&#380; nie mo&#380;emy sumowa&#263; niesko&#324;czonej liczby nagród bez
ucinania reszty w jakim&#347; arbitralnym punkcie, &#380;eby by&#263; w stanie nauczy&#263; si&#281;
czegokolwiek.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-32001r9"></a>
<!--l. 104--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                              <mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>A</mi><mi 
>V</mi> <mi 
>G</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mn>3</mn></mrow></msub 
><mo 
class="MathClass-punc">,</mo><mi 
>&#x2026;</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.9)</td></tr></table>
<!--l. 108--><p class="noindent" >Uczenie Monte-Carlo, gdzie <!--l. 108--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mn>1</mn></mrow></msub 
></mstyle></mstyle></math>,
<!--l. 108--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mn>2</mn></mrow></msub 
></mstyle></mstyle></math> itd. s&#261; sumami nagród w
konkretnym epizodzie, a <!--l. 108--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math>
jest funkcj&#261; warto&#347;ci otrzyman&#261; przez wzi&#281;cie &#347;redniej z tych sum.<br 
class="newline" />
                                                                                    
                                                                                    
</p><!--l. 110--><p class="indent" >   Powiedzmy, jak mogliby&#347;my zaimplementowa&#263; uczenie Monte-Carlo. Mo&#380;emy sobie
wyobrazi&#263; posiadanie wielkiej tablicy z osobnym rekordem dla ka&#380;dego stanu
<!--l. 110--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>s</mi></mstyle></mstyle></math>. W
ka&#380;dej komórce umieszczaliby&#347;my t&#261; &#347;redni&#261;. Teraz, aby aktualizowa&#263; warto&#347;&#263;
ka&#380;dej z tych komórek, potrzebujemy zasady aktualizacji. Mogliby&#347;my j&#261; otrzyma&#263;,
utrzymuj&#261;c w pami&#281;ci dwie informacje: jedn&#261; z sum&#261; wszystkich nagród w ró&#380;nych
epizodach i drug&#261; z ilo&#347;ci&#261; epizodów, które sprawdzili&#347;my. Dziel&#261;c pierwsz&#261; warto&#347;&#263;
przez drug&#261;, otrzymaliby&#347;my wynik. Jest jednak inna metoda daj&#261;ca ten sam
wynik:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-32002r10"></a>
<!--l. 112--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                             <msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>a</mi><mi 
>v</mi><mi 
>g</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mfrac><mrow 
><mi 
>x</mi> <mo 
class="MathClass-bin">+</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>k</mi> <mo 
class="MathClass-bin">-</mo> <mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>o</mi><mi 
>l</mi><mi 
>d</mi><mi 
>A</mi><mi 
>v</mi><mi 
>g</mi></mrow></msub 
></mrow> 
              <mrow 
><mi 
>k</mi></mrow></mfrac>
</math></td><td class="eq-no">(5.10)</td></tr></table>
<!--l. 116--><p class="noindent" >Gdzie <!--l. 116--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>a</mi><mi 
>v</mi><mi 
>g</mi></mrow></msub 
></mstyle></mstyle></math> jest now&#261;
&#347;redni&#261;, <!--l. 116--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>o</mi><mi 
>l</mi><mi 
>d</mi><mi 
>A</mi><mi 
>v</mi><mi 
>g</mi></mrow></msub 
></mstyle></mstyle></math> bie&#380;&#261;c&#261;
&#347;redni&#261;, <!--l. 116--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>k</mi></mstyle></mstyle></math> jest
liczb&#261; epizodów, a <!--l. 116--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>x</mi></mstyle></mstyle></math>
jest nowym przyk&#322;adem sumy nagród, który napotkali&#347;my.<br 
class="newline" />
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-32003r4"></a>
                                                                                    
                                                                                    
<!--l. 121--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 121--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-32004"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;5.4:</span><span  
class="content">Rozwini&#281;cie Monte-Carlo</span></figcaption><!--tex4ht:label?: x1-32003r5 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<!--l. 126--><p class="indent" >   To podej&#347;cie jest mo&#380;liwe dla ma&#322;ych problemów, jednak kiedy problem ro&#347;nie do
du&#380;ych rozmiarów, jak na przyk&#322;ad podczas gry w szachy, staje si&#281; niemo&#380;liwym, aby
utrzymywa&#263; rekord ka&#380;dego mo&#380;liwego stanu. Jak mogliby&#347;my przybli&#380;y&#263; dzia&#322;anie
takiej tablicy? Tu na pomoc przychodzi generalna <span 
class="aeb10-x-x-120">aproksymacja funkcji</span>. W naszym
przypadku u&#380;yjemy jednego z aproksymatorów jakim jest sie&#263; neuronowa. Sieci
neuronowe s&#261; tak nazywane, poniewa&#380; w teorii mog&#261; reprezentowa&#263; ka&#380;d&#261; mo&#380;liw&#261;
funkcj&#281; z pewn&#261; dok&#322;adno&#347;ci&#261;. Tak wi&#281;c b&#281;dziemy u&#380;ywa&#263; sieci neuronowej do
aproksymowania dzia&#322;ania tabeli przegl&#261;dowej. Jakie b&#281;dzie wej&#347;cie, wyj&#347;cie i nagroda dla
naszej sieci? Wej&#347;ciem b&#281;dzie stan. Wyj&#347;cie okre&#347;limy jako warto&#347;&#263; funkcji
warto&#347;ci dla danego stany wej&#347;ciowego. Tak np. wej&#347;ciem mo&#380;e by&#263; pozycja
szachowa, a wyj&#347;ciem numeryczna ocena pozycji przez arcymistrza szachowego. &#379;eby
przybli&#380;a&#263; wynik otrzymywany przez propagacj&#281; przez sie&#263;, do oceny profesjonalisty,
u&#380;yjemy funkcji warto&#347;ci, która b&#281;dzie u&#380;ywa&#263; ró&#380;nicy mi&#281;dzy wyj&#347;ciem a
sum&#261; nagród dla danego epizodu do swojego uczenia. Nast&#281;pnie odejmiemy ocen&#281;
profesjonalisty od oceny sieci i wszystko to podniesiemy nast&#281;pnie do kwadratu. Taka
funkcja nazywana jest <span 
class="aeb10-x-x-120">&#347;</span><span 
class="aeb10-x-x-120">rednim b&#322;&#281;dem kwadratowym </span>(ang. mean squared error lub
MSE).
</p>
   <table class="equation"><tr><td> <a 
 id="x1-32005r11"></a>
<!--l. 128--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                             <mi 
>M</mi><mi 
>S</mi><mi 
>E</mi> <mo 
class="MathClass-rel">=</mo> <msup><mrow 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>e</mi><mi 
>x</mi><mi 
>p</mi><mi 
>e</mi><mi 
>c</mi><mi 
>t</mi><mi 
>e</mi><mi 
>d</mi></mrow></msub 
> <mo 
class="MathClass-bin">-</mo> <msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mrow 
><mn>2</mn></mrow></msup 
>
</math></td><td class="eq-no">(5.11)</td></tr></table>
<!--l. 132--><p class="noindent" ><!--l. 132--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>U</mi></mrow><mrow 
><mi 
>e</mi><mi 
>x</mi><mi 
>p</mi><mi 
>e</mi><mi 
>c</mi><mi 
>t</mi><mi 
>e</mi><mi 
>d</mi></mrow></msub 
></mstyle></mstyle></math>
jest sum&#261; nagród albo funkcj&#261; warto&#347;ci dla naszego epizodu,
<!--l. 132--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi></mrow></msub 
></mstyle></mstyle></math>
jest wyj&#347;ciem naszej sieci neuronowej. Musimy tylko pami&#281;ta&#263;, &#380;e je&#347;li nasz
epizod jest niesko&#324;czony, b&#281;dziemy musieli w pewnym momencie uci&#261;&#263; reszt&#281;
nagród.<br 
class="newline" />
</p><!--l. 134--><p class="indent" >   Taka funkcja warto&#347;ci zapewni nam dobre uczenie ze wzgl&#281;du na to, &#380;e kara, jak&#261;
b&#281;dzie otrzymywa&#263; sie&#263;, b&#281;dzie zale&#380;e&#263; od odleg&#322;o&#347;ci mi&#281;dzy ocen&#261; sieci a ocen&#261;
spodziewan&#261;. Zamiast oceny profesjonalisty mo&#380;emy wzi&#261;&#263; wynik gry, co jest bardziej
realne, poniewa&#380; zazwyczaj nie mamy zbioru pozycji ocenionych przez profesjonalist&#281;.
Je&#347;li tak w&#322;a&#347;nie jest, to mo&#380;emy wzi&#261;&#263; jak najwi&#281;ksz&#261; liczb&#281; rozegranych gier z ich
                                                                                    
                                                                                    
wynikami. Wybra&#263; spo&#347;ród nich pewn&#261; liczb&#281; pozycji z wynikami i na takiej podstawie
uczy&#263; nasz&#261; sie&#263;. Zauwa&#380;my, &#380;e popularne pozycje takie jak np. 1.e4 2.e5 mog&#261; si&#281;
powtórzy&#263; w naszym zbiorze wielokrotnie. Na dodatek mog&#261; mie&#263; one ró&#380;ne wyniki,
poniewa&#380; niektórzy gracze mogli wygra&#263; a inni przegra&#263; z tej samej pozycji. Nie
przeszkadza to jednak w uczeniu, poniewa&#380; sie&#263; tak jak wcze&#347;niej tablica u&#347;redni te
wyniki.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-32006r5"></a>
                                                                                    
                                                                                    
<!--l. 139--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 139--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-32007"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;5.5:</span><span  
class="content">Propagacja b&#322;&#281;du w TD</span></figcaption><!--tex4ht:label?: x1-32006r5 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-32008r32"></a>
<h3 class="sectionHead"><span class="titlemark">5.5   </span> <a 
 id="x1-330005"></a>Uczenie TD</h3>
<!--l. 146--><p class="noindent" >Alternatyw&#261; dla metody Monte-Carlo jest metoda <span 
class="aeb10-x-x-120">temporalnych r</span><span 
class="aeb10-x-x-120">ó</span><span 
class="aeb10-x-x-120">&#380;</span><span 
class="aeb10-x-x-120">nic </span>(ang. temporal
difference, TD dla krótko&#347;ci zapisu). W metodzie TD szukamy ró&#380;nic pomi&#281;dzy funkcj&#261;
warto&#347;ci dla nast&#281;puj&#261;cych po sobie stanów. Wyobra&#378;my sobie na przyk&#322;ad, &#380;e
gramy w szachy. W tym rodzaju gry nagroda pojawia si&#281; tylko na ko&#324;cu i nie ma
po&#347;rednich nagród, za powiedzmy zbicie pionka. Potrzebujemy ich jednak, &#380;eby
dokonywa&#263; wyboru. To wa&#380;ny problem, na który zwracano uwag&#281; du&#380;o wcze&#347;niej.
Chocia&#380;by Newell mia&#322; w&#261;tpliwo&#347;ci czy w wyniku wygrana, remis, przegrana jest
wystarczaj&#261;ca ilo&#347;&#263; informacji, &#380;eby czegokolwiek by&#263; w stanie si&#281; nauczy&#263;. &#379;eby
rozwi&#261;za&#263; ten problem, mogliby&#347;my w pewnym sensie propagowa&#263; wstecznie
nagrody od ko&#324;ca epizodu do jego pocz&#261;tku. Je&#347;li to zrobimy, to ka&#380;dy stan
poprzedzaj&#261;cy koniec gry b&#281;dzie mie&#263; warto&#347;&#263; równ&#261; wynikowi gry. Pozycji powiedzmy
1.e4 2.e5, przypiszemy warto&#347;&#263; równ&#261; temu, co by&#322;o wynikiem ca&#322;ej gry. Teraz
mogliby&#347;my u&#380;y&#263; tablicy, &#380;eby zapisywa&#263; rezultaty dla kolejnych sprawdzanych
pozycji, ale ju&#380; mówili&#347;my, przy okazji omawiania metody Monte-Carlo, &#380;e
istnieje lepszy sposób. U&#380;yjemy do przewidywania sieci neuronowej. Wej&#347;cie i
wyj&#347;cie b&#281;d&#261; takie same jak poprzednio. Jedynym co ulegnie zmianie, b&#281;dzie
b&#322;&#261;d.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-33001r12"></a>
<!--l. 148--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                              <mi 
>M</mi><mi 
>S</mi><mi 
>E</mi> <mo 
class="MathClass-rel">=</mo> <msup><mrow 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi></mrow></msub 
> <mo 
class="MathClass-bin">-</mo> <msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi><mo 
class="MathClass-bin">-</mo><mn>1</mn></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mrow 
><mn>2</mn></mrow></msup 
>
</math></td><td class="eq-no">(5.12)</td></tr></table>
<!--l. 152--><p class="noindent" >To jest funkcja b&#322;&#281;du dla uczenia TD. <!--l. 152--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi></mrow></msub 
></mstyle></mstyle></math>
jest warto&#347;ci&#261; funkcji warto&#347;ci dla obecnego epizodu a
<!--l. 152--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi><mo 
class="MathClass-bin">-</mo><mn>1</mn></mrow></msub 
></mstyle></mstyle></math> jest
podobnie warto&#347;ci&#261; funkcji warto&#347;ci dla poprzedniego epizodu.<br 
class="newline" />
</p><!--l. 154--><p class="indent" >   Zobaczmy, jak dzia&#322;a to uczenie. Bierzemy obecne przewidywanie co do wyniku, które
zwraca nam sie&#263; i przewidywanie tej sieci ruch wcze&#347;niej. Obliczamy ró&#380;nic&#281; za pomoc&#261;
równania (5.12). Nast&#281;pnie u&#380;ywamy wyniku do uczenia sieci na temat obecnej pozycji.
                                                                                    
                                                                                    
Widzimy wi&#281;c, &#380;e sie&#263; próbuje przewidywa&#263; wynik samej siebie. Mo&#380;esz teraz
powiedzie&#263;, &#380;e ca&#322;e to uczenie nie ma sensu, bo jak nasza sie&#263; ma si&#281; nauczy&#263; od samej
siebie mimo tego, &#380;e nic na pocz&#261;tku nie wie. I masz racj&#281;, na pocz&#261;tku uczenie
nie b&#281;dzie dobre, ale b&#281;dzie wyst&#281;powa&#322;o, poniewa&#380; na ko&#324;cu epizodu zamiast
<!--l. 154--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi></mrow></msub 
></mstyle></mstyle></math>
u&#380;yjemy realnego rezultatu. Jak ju&#380; jednak powiedzieli&#347;my, uczenie to nie b&#281;dzie z
pocz&#261;tku najwy&#380;szej jako&#347;ci. Ten problem nazywany jest z ang. biase&#8217;em uczenia TD.
Mocn&#261; stron&#261; tego podej&#347;cia wobec metody Monte-Carlo jest jednak to, &#380;e nie
musimy czeka&#263; do ko&#324;ca epizodu, aby nauczy&#263; si&#281; czego&#347;, uczenie odbywa si&#281; po
ka&#380;dej zmianie stanu. To jest niezwykle korzystne w sytuacjach, gdy nagroda jest
rzadka tak jak w przyk&#322;adzie z szachami. Kluczowym jednak pytaniem jest to czy
istnieje ró&#380;nica, mi&#281;dzy tym, czego nauczy si&#281; Monte-Carlo a TD? Zobaczmy
przyk&#322;ad:<br 
class="newline" />
</p><!--l. 156--><p class="noindent" >Mamy dwa wydarzenia A i B oraz po&#322;&#261;czone z nimi odpowiednie nagrody. Dane czterech
epizodów wygl&#261;daj&#261; nast&#281;puj&#261;co:
      </p><div class="quote">
      <!--l. 159--><p class="noindent" >A 0, B 0 end</p></div>
      <div class="quote">
      <!--l. 162--><p class="noindent" >B 1 end</p></div>
      <div class="quote">
      <!--l. 165--><p class="noindent" >B 1 end</p></div>
      <div class="quote">
      <!--l. 168--><p class="noindent" >B 0 end</p></div>
<!--l. 171--><p class="noindent" >Teraz chcemy zobaczy&#263; jak&#261; odpowied&#378; dostaniemy od MC i od TD. MC (skrót
od metody Monte-Carlo) wyci&#261;gn&#261;&#322;by &#347;redni&#261; z wszystkich przyk&#322;adów, daj&#261;c
nam:
      </p><div class="quote">
      <!--l. 174--><p class="noindent" >A = 0</p></div>
      <div class="quote">
                                                                                    
                                                                                    
      <!--l. 177--><p class="noindent" >B = 1/2</p></div>
<!--l. 180--><p class="noindent" >Metoda TD da&#322;aby nam inn&#261; odpowied&#378;:
      </p><div class="quote">
      <!--l. 183--><p class="noindent" >A = 1/2</p></div>
      <div class="quote">
      <!--l. 186--><p class="noindent" >B = 1/2</p></div>
<!--l. 189--><p class="noindent" >Wi&#281;c jak TD da&#322;o nam t&#281; odpowied&#378;? Je&#347;li pami&#281;tasz, jak mówili&#347;my o MDP w
rozdziale 5.3, to mo&#380;esz sobie wyobrazi&#263; dzia&#322;anie metody TD jako wybieranie najbardziej
prawdopodobnego MDP zwi&#261;zanego z problemem. W naszym przypadku MDP wygl&#261;da&#322;by
nast&#281;puj&#261;co:
      </p><div class="quote">
      <!--l. 192--><p class="noindent" >A przechodzi w B 100% razy.</p></div>
      <div class="quote">
      <!--l. 195--><p class="noindent" >B daje nam 1 z 50% prawdopodobie&#324;stwem.</p></div>
<!--l. 198--><p class="noindent" >Widzimy, wi&#281;c &#380;e rozwi&#261;zania obu tych metod nie s&#261; takie same. Mówimy, &#380;e MC zbiega
si&#281; do rozwi&#261;zania, które ma najmniejszy b&#322;&#261;d kwadratowy a metody TD do
najprawdopodobniejszego modelu MDP.
                                                                                    
                                                                                    
</p>
   <figure class="figure"> 

                                                                                    
                                                                                    
<a 
 id="x1-33002r6"></a>
                                                                                    
                                                                                    
<!--l. 204--><p class="noindent" >
                                                                                    
                                                                                    
</p><!--l. 204--><p class="noindent" >-422.52342
                                                                                    
                                                                                    
<a 
 id="x1-33003"></a>
</p>
<figcaption class="caption" ><span class="id">Ryc.&#x00A0;5.6:</span><span  
class="content">Propagacja b&#322;&#281;du w TD(<!--l. 205--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x03BB;</mi></math>)</span></figcaption><!--tex4ht:label?: x1-33002r5 -->
                                                                                    
                                                                                    
   </figure>
                                                                                    
                                                                                    
<a 
 id="x1-33004r33"></a>
<h3 class="sectionHead"><span class="titlemark">5.6   </span> <a 
 id="x1-340006"></a>Uczenie TD(lambda)</h3>
<!--l. 211--><p class="noindent" >Poprzednio widzieli&#347;my dwa ró&#380;ne podej&#347;cia do problemu uczenia ze wzmocnieniem, ale
którego powinni&#347;my u&#380;ywa&#263;? Odpowied&#378; brzmi: nie musimy wybiera&#263;, poniewa&#380;
istnieje metoda &#322;&#261;cz&#261;ca te dwa sposoby. Kiedy u&#380;ywali&#347;my metody Monte-Carlo,
patrzyli&#347;my si&#281; na ka&#380;d&#261; nagrod&#281; do ko&#324;ca epizodu. Kiedy natomiast u&#380;ywali&#347;my
metody TD, patrzyli&#347;my si&#281; tylko jeden krok do przodu. Co, jednak je&#347;li mogliby&#347;my si&#281;
popatrze&#263; gdzie&#347; pomi&#281;dzy? Nie do ko&#324;ca epizodu, ale wi&#281;cej ni&#380; jeden krok. To
podej&#347;cie nazywane jest <span 
class="aeb10-x-x-120">n-krokow&#261; </span>metod&#261; TD. &#379;eby otrzyma&#263; nasz&#261; funkcj&#281; nagrody,
do której b&#281;dziemy si&#281; starali dopasowa&#263; dzia&#322;anie aproksymatora, dodamy <span 
class="aeb10-x-x-120">n </span>kroków
nagród tak jak w MC, a na ko&#324;cu zamiast reszty epizodu dodamy funkcj&#281; warto&#347;ci w
kroku <span 
class="aeb10-x-x-120">n+1 </span>tak jak w uczeniu TD. Teraz, je&#347;li wybierzemy <span 
class="aeb10-x-x-120">n </span>= 0 to metoda ta jest
ekwiwalentna do metody TD, a je&#347;li wybierzemy <span 
class="aeb10-x-x-120">n = inf. </span>to jest taka sama jak MC. Wiemy
eksperymentalnie, &#380;e zazwyczaj najlepsze rozwi&#261;zania le&#380;&#261; gdzie&#347; pomi&#281;dzy tymi dwoma
ekstremami. Jak jednak mamy wybra&#263; konkretn&#261; liczb&#281; kroków, której b&#281;dziemy
u&#380;ywa&#263;? Tu znów okazuje si&#281;, &#380;e niekoniecznie musimy wybiera&#263;. A to poniewa&#380;
algorytm <span 
class="aeb10-x-x-120">TD(lambda) </span>&#322;&#261;czy wszystkie warto&#347;ci <span 
class="aeb10-x-x-120">n </span>kroków w jedn&#261; warto&#347;&#263;
docelow&#261;. Dzia&#322;aj&#261;cy tu mechanizm jest bardzo prosty. We&#378;miemy wszystkie
mo&#380;liwe warto&#347;ci dla <span 
class="aeb10-x-x-120">n</span>-kroków, zaczynaj&#261;c na <span 
class="aeb10-x-x-120">n </span>= 0 a ko&#324;cz&#261;c na <span 
class="aeb10-x-x-120">n </span>= inf.
Dodamy je wszystkie, otrzymuj&#261;c now&#261; warto&#347;&#263;. Aby jednak nie bra&#263; pod uwag&#281;
odleg&#322;ych wydarze&#324;, w powiedzmy 100-kroku, z tak&#261; sam&#261; wag&#261; jak np. w 4-kroku
wprowadzono wspó&#322;czynnik lambda. Lambda zawiera si&#281; w przedziale 0 do 1. Okre&#347;la
ona, jak bardzo powinni&#347;my bra&#263; pod uwag&#281; odleg&#322;e konsekwencje. Z jednej
strony przecie&#380; chcemy je bra&#263; pod uwag&#281;, ale z drugie im bardziej odleg&#322;e,
tym mniej pewne jest, co dok&#322;adnie je spowodowa&#322;o. Musimy wi&#281;c ustali&#263;, jak
bardzo zale&#380;y nam na konkretnej w&#322;a&#347;ciwo&#347;ci. Zrobimy wi&#281;c odrobin&#281; inaczej.
We&#378;miemy wszystkie mo&#380;liwe warto&#347;ci dla n-kroków i dodamy je pomno&#380;one przez
<!--l. 211--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msup><mrow 
><mi 
>&#x03BB;</mi></mrow><mrow 
><mi 
>n</mi></mrow></msup 
></mstyle></mstyle></math>.
Ten wspó&#322;czynnik b&#281;dzie zmniejsza&#263; wag&#281; du&#380;ych, a wi&#281;c odleg&#322;ych
<!--l. 211--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>-kroków. Na
ko&#324;cu wynik przez <!--l. 211--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>1</mn> <mo 
class="MathClass-bin">-</mo> <mi 
>&#x03BB;</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math>
dla obliczeniowej konsystencji.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-34001r13"></a>
                                                                                    
                                                                                    
<!--l. 213--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                   <mi 
>G</mi> <mo 
class="MathClass-rel">=</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>1</mn> <mo 
class="MathClass-bin">-</mo> <mi 
>&#x03BB;</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo><munderover accentunder="false" accent="false"><mrow  
><mo  
>&#x2211;</mo>
  </mrow><mrow 
><mi 
>i</mi><mo 
class="MathClass-rel">=</mo><mn>0</mn></mrow><mrow 
><mi 
>n</mi></mrow></munderover 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mrow ><mo 
class="MathClass-open">(</mo><mrow><munderover accentunder="false" accent="false"><mrow  
><mo  
>&#x2211;</mo>
  </mrow><mrow 
><mi 
>j</mi><mo 
class="MathClass-rel">=</mo><mn>0</mn></mrow><mrow 
><mi 
>i</mi></mrow></munderover 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>r</mi></mrow><mrow 
>
<mi 
>j</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">+</mo> <mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>i</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo> <msup><mrow 
><mi 
>&#x03BB;</mi></mrow><mrow 
><mi 
>i</mi></mrow></msup 
></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(5.13)</td></tr></table>
<!--l. 217--><p class="noindent" >Gdzie <!--l. 217--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><msub><mrow 
><mi 
>r</mi></mrow><mrow 
><mi 
>j</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> oznacza sum&#281;
nagród w <!--l. 217--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>j</mi></mstyle></mstyle></math> krokach,
<!--l. 217--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>i</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> funkcja warto&#347;ci
w <span 
class="aeb10-x-x-120">i</span>-tym kroku, a <!--l. 217--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>G</mi></mstyle></mstyle></math>
jest warto&#347;ci&#261; docelow&#261;, któr&#261; chcemy przybli&#380;a&#263;, u&#380;ywamy jej wi&#281;c w równaniu
MSE.<br 
class="newline" />
</p><!--l. 219--><p class="noindent" >Mo&#380;emy teraz u&#380;y&#263; G w równaniu na MSE:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-34002r14"></a>
<!--l. 221--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                <mi 
>M</mi><mi 
>S</mi><mi 
>E</mi> <mo 
class="MathClass-rel">=</mo> <msup><mrow 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>G</mi> <mo 
class="MathClass-bin">-</mo> <msub><mrow 
><mi 
>u</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi></mrow></msub 
></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mrow 
><mn>2</mn></mrow></msup 
>
</math></td><td class="eq-no">(5.14)</td></tr></table>
<!--l. 225--><p class="noindent" ><!--l. 225--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>U</mi></mrow><mrow 
><mi 
>n</mi><mi 
>e</mi><mi 
>t</mi></mrow></msub 
></mstyle></mstyle></math> jest tu
oczywi&#347;cie wynikiem dzia&#322;ania naszej sieci.<br 
class="newline" />
</p><!--l. 227--><p class="indent" >   Ten algorytm zosta&#322; wykorzystany w s&#322;ynnym programie TD-Gammon stworzonym w
1992 roku przez Geralda Tesauro. Nazwa programu pochodzi&#322;a w&#322;a&#347;nie od uczenia TD oraz
od nazwy gry, w której ten program konkurowa&#322;, a mianowicie Tryktraka (ang.
backgammon). Gra ta w wielkim uproszczeniu polega na podró&#380;y wokó&#322; planszy
w kierunku przeciwnym do konkurenta swoimi pionami. Celem gry jest zdj&#281;cie
wszystkich swoich pionów z planszy. Aby to uczyni&#263;, obaj gracze rzucaj&#261; dwoma
ko&#347;&#263;mi i poruszaj&#261; si&#281; o wyrzucon&#261; liczb&#281; pól. W czasie gry piony wchodz&#261; ze sob&#261;
w interakcje. Co ciekawe mo&#380;na wygra&#263; normalnie lub poprzez zdobycie tzw.
gammonu. Ze wzgl&#281;du na losowo&#347;&#263; wyst&#281;puj&#261;c&#261; w grze, która powoduje szybkie
rozga&#322;&#281;zianie, a wi&#281;c powstanie wielu mo&#380;liwych historii, g&#322;&#281;boko&#347;&#263; drzewa
poszukiwa&#324; jest z konieczno&#347;ci ograniczona. W programie TD-Gammon by&#322;a ona
ograniczona do ruchów i odpowiedzi przeciwnika. Nast&#281;pnie pozycje by&#322;y oceniane przez
sie&#263; neuronow&#261;. Sie&#263; neuronowa programu by&#322;a nauczona za pomoc&#261; algorytmu
                                                                                    
                                                                                    
TD(<!--l. 227--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mi 
>&#x03BB;</mi></math>).
Program nie wykorzystywa&#322; wiedzy zdobytej przez ludzi, a uczy&#322; si&#281; bezpo&#347;rednio ze swoich
gier. W wyniku powstania programu TD-Gammon zmieni&#322;a si&#281; teoria grania w tryktroka.
Gra pozycyjna programu jest oceniana przez niektórych ekspertów jako wy&#347;mienita,
przewy&#380;szaj&#261;ca nawet ich w&#322;asn&#261;.
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    
</p>
   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;6</span><br /><a 
 id="x1-350006"></a>Gry i wi&#281;cej</h2>
<!--l. 5--><p class="noindent" >Pokryli&#347;my w tym momencie szeroki zakres tematów, zaczynaj&#261;c na sieciach neuronowych
i optymalizowaniu ich dzia&#322;ania, co daje nam moc znajdywania relacji mi&#281;dzy strumieniami
danych. Patrzyli&#347;my si&#281; na drzewa poszukiwa&#263;, które utrzymuj&#261; w pami&#281;ci
rozwi&#261;zania, których próbowali&#347;my i pomagaj&#261; nam eksplorowa&#263; przestrze&#324;
mo&#380;liwo&#347;ci. Widzieli&#347;my tak&#380;e, w jaki sposób uczenie ze wzmocnieniem daje nam
unifikuj&#261;cy pogl&#261;d na aktorów ucz&#261;cych si&#281; w rzeczywistych &#347;rodowiskach i
zobaczyli&#347;my problemy, które w nich napotykaj&#261;. Wspomnieli&#347;my te&#380; czasami o
historycznych wydarzeniach wa&#380;nych dla dziedziny sztucznej inteligencji. W tym rozdziale
przegl&#261;dniemy kilka prac badawczych od firmy Deepmind, maj&#261;c na uwadze to, czego
nauczyli&#347;my si&#281; do tej pory. Po przeczytaniu tego rozdzia&#322;u powiniene&#347; by&#263;
zapoznany, przynajmniej na wysokim poziomie z najnowszymi badaniami w tej
dziedzinie. Pospekulujemy równie&#380; na ko&#324;cu tego rozdzia&#322;u nad przysz&#322;ymi
mo&#380;liwymi podej&#347;ciami do tak zwanej generalnej sztucznej inteligencji tj. <span 
class="aeb10-x-x-120">AGI</span>.
Ta cz&#281;&#347;&#263; tekstu jest mo&#380;e najwa&#380;niejsza ze wszystkich. Buduj&#261;c na tym, co
zosta&#322;o powiedziane wcze&#347;niej, daje nietechnicznemu czytelnikowi wgl&#261;d w to, co
dzieje si&#281; pod mask&#261; sztucznej inteligencji, uczenia maszynowego oraz g&#322;&#281;bokich
sieci neuronowych. Odbiegaj&#261;c od tematu, zwrot g&#322;&#281;boka sie&#263; neuronowa (ang.
deep neural network) znaczy tylko tyle &#380;e sie&#263; ma wi&#281;cej ni&#380; jedn&#261; warstw&#281;
neuronów. To tyle. Jednak kto&#347; niezaznajomiony z tematem móg&#322;by by&#263; pod
wra&#380;eniem, kiedy us&#322;ysza&#322;by o g&#322;&#281;bokich sieciach neuronowych. Mam nadziej&#281;, &#380;e teraz
rozumiesz g&#322;&#281;biej, jak wygl&#261;da rzeczywisto&#347;&#263; i nie b&#281;dziesz tak &#322;atwo manipulowany
przez medialne próby &#322;apania twojej uwagi. Mamy tak&#380;e nadziej&#281;, &#380;e niektóre
obawy zwi&#261;zane ze sztuczn&#261; inteligencj&#261; zosta&#322;y przez nas rozwiane i mo&#380;esz
krytykowa&#263; rozwi&#261;zania AI na wy&#380;szym poziomie zrozumienia. Mamy nadziej&#281;, &#380;e
b&#281;dziesz w stanie wyja&#347;ni&#263; kilka rzeczy swoim znajomym. Ostatecznie mamy
nadziej&#281;, &#380;e b&#281;dziesz w stanie podejmowa&#263; lepsze decyzje, u&#380;ywaj&#261;c tej wiedzy.
Czy to b&#281;dzie poprzez dalsze pog&#322;&#281;bianie wiedzy i tworzenie nowych rozwi&#261;za&#324;,
przygotowanie lepszego planu dla swojej firmy, inwestowanie w przedsi&#281;wzi&#281;cia zwi&#261;zane z
technologi&#261;, czy nawet decyzje dotycz&#261;ce &#380;ycia osobistego takie jak wybór platform
spo&#322;eczno&#347;ciowych, z których chcesz korzysta&#263;, ze wzgl&#281;du na wykorzystywanie w
nich tych metod. Jeste&#347;my g&#322;&#281;boko przekonani, &#380;e wi&#281;ksza wiedza mo&#380;e ci&#281;
prowadzi&#263; do lepszego &#380;ycia dla ciebie i innych. Popatrzmy teraz na obecny stan
bada&#324;.
<a 
 id="x1-35001r34"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">6.1   </span> <a 
 id="x1-360001"></a>AlphaGo (rok 2016)</h3>
<!--l. 9--><p class="noindent" ><span 
class="aeb10-x-x-120">AlphaGo </span>jest algorytmem, który zosta&#322; stworzony z my&#347;l&#261; o pokonaniu gry planszowej,
                                                                                    
                                                                                    
która nie poddawa&#322;a si&#281; technikom sztucznej inteligencji przez najd&#322;u&#380;szy czas,
mowa tu o Go. W tamtym czasie naukowcy my&#347;leli, &#380;e znacz&#261;cy prze&#322;om w
dziedzinie jest konieczny, aby osi&#261;gn&#261;&#263; ten cel oraz &#380;e jest on odleg&#322;y o przynajmniej
dekad&#281;. W tym czasie brytyjska firma Deepmind przej&#281;ta przez Google ci&#281;&#380;ko
pracowa&#322;a, aby udowodni&#263; co&#347; przeciwnego. Sprawdzili oni najlepsze w tamtym
czasie podej&#347;cia do tej gry, które u&#380;ywa&#322;y MCTS wzmocnionego przez sie&#263;
zbioru zasad, która mia&#322;a przewidywa&#263; ruchy, które zagra&#322;by cz&#322;owiek. Badzacze
zaproponowali ich w&#322;asny sposób, który mia&#322; u&#380;ywa&#263; sieci zbioru zasad i funkcji
warto&#347;ci po&#322;&#261;czonych z MCTS, a to wszystko wytrenowane w cz&#281;&#347;ci przez uczenie ze
wzmocnieniem. Jak pokazuj&#261; w pracy na temat AlphaGo, gra Go ma bardzo du&#380;&#261;
przestrze&#324; mo&#380;liwo&#347;ci, w której trzeba wyszukiwa&#263; rozwi&#261;zanie. Jej szeroko&#347;&#263;
<!--l. 9--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>b</mi></mstyle></mstyle></math>
(ilo&#347;&#263; legalnych ruchów dla danej pozycji) wynosi oko&#322;o 250, a g&#322;&#281;boko&#347;&#263;
<!--l. 9--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi></mstyle></mstyle></math> (d&#322;ugo&#347;&#263; gry),
która wynosi &#347;rednio 150. To jest du&#380;o wi&#281;ksze drzewo mo&#380;liwo&#347;ci ni&#380; np. szachy, które maj&#261;
<!--l. 9--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>b</mi></mstyle></mstyle></math> równe mniej
wi&#281;cej 35, a <!--l. 9--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>d</mi></mstyle></mstyle></math>
równe oko&#322;o 80. Z tego w&#322;a&#347;nie powodu proste wyszukiwanie alfa-beta nie jest
wystarczaj&#261;ce, aby rozwi&#261;za&#263; problem gry Go. Nie mo&#380;emy popatrze&#263; si&#281; wystarczaj&#261;co
g&#322;&#281;boko i nie mamy prostej funkcji warto&#347;ci, tak jak w szachach gdzie ka&#380;dej figurze
mo&#380;emy przypisa&#263; pewn&#261; warto&#347;&#263;. W Go warto&#347;&#263; ka&#380;dego ruchu zale&#380;y g&#322;ównie
od innych ruchów, które zosta&#322;y wcze&#347;niej wykonane. &#379;eby nauczy&#263; AlphaGo,
Deepmind wytrenowa&#322; kilka sieci neuronowych. Na pocz&#261;tku zebrali zbiór danych
zawieraj&#261;cy gry profesjonalistów. Nast&#281;pnie wytrenowali co&#347;, co nazwali sieci&#261; &#8216;SL policy&#8217;
&#380;eby przewidywa&#322;a ruchy zrobione przez tych graczy. Ta sie&#263; mia&#322;a 13 warstw i trenowa&#322;a
na 30 milionach przyk&#322;adów. Naukowcy wytrenowali dodatkowo mniejsz&#261; i szybsz&#261; sie&#263; do
wykonywania tego samego zadania. &#8216;SL policy&#8217; uda&#322;o si&#281; otrzyma&#263; wynik 57% poprawnie
przewidzianych ruchów, a mniejszej sieci uda&#322;o si&#281; to w 24.2% przypadków. Kolejno
wytrenowano &#8216;SL policy&#8217; sposobem uczenia przez wzmacnianie. Pozwolono sieci
wybiera&#263; ruchy i na ko&#324;cu gry, gdy znana jest nagroda, dokonywano uczenia ze
wzmocnieniem. U&#380;yta metoda opiera&#322;a si&#281; o podobne mechanizmy jak te, na
które patrzyli&#347;my tylko dla sieci zbioru zasad zamiast dla funkcji warto&#347;ci.
Wytrenowana w ten sposób sie&#263; RL by&#322;a w stanie pokona&#263; sie&#263; SL w 80%
przypadków. Ludzie pracuj&#261;cy nad projektem chcieli jednak aby u&#380;y&#263; tak&#380;e funkcji
warto&#347;ci. &#379;eby otrzyma&#263; zbiór danych, pozwolili gra&#263; sieci RL wiele gier ze sam&#261;
sob&#261; a&#380; do momentu ich zako&#324;czenia. Nast&#281;pnie wybierali niektóre pozycje
spo&#347;ród tego zbioru danych, &#380;eby unikn&#261;&#263; nadmiernego dopasowania ze wzgl&#281;du na
korelacje pomi&#281;dzy pozycjami wewn&#261;trz jednej gry. Funkcj&#261; b&#322;&#281;du by&#322;a MSE wzgl&#281;dem
wyniku gry, który by&#322; równy +1 dla wygranej i -1 dla przegranej (w grze Go nie
ma remisów). Architektura sieci symuluj&#261;cej funkcj&#281; warto&#347;ci by&#322;a podobna
                                                                                    
                                                                                    
do sieci &#8216;SL policy&#8217;. Oczywista ró&#380;nica, jaka mi&#281;dzy nimi wyst&#281;powa&#322;a to fakt,
&#380;e &#8216;SL policy&#8217; zwraca&#322;a dystrybucj&#281; prawdopodobie&#324;stwa a funkcja warto&#347;ci
jedn&#261; liczb&#281;. Sie&#263; &#8216;policy&#8217; by&#322;a przydatna w zmniejszaniu szeroko&#347;ci drzewa, a
funkcja warto&#347;ci w zmniejszaniu g&#322;&#281;boko&#347;ci drzewa poszukiwa&#324;. W pracy na
temat AlphaGo badacze zwracaj&#261; uwag&#281;, &#380;e funkcja warto&#347;ci mia&#322;a podobn&#261;
si&#322;&#281; do sieci RL u&#380;ywaj&#261;cej rozwini&#281;&#263; Monte-Carlo, ale u&#380;ywa&#322;a 15 000 razy
mniej mocy obliczeniowej. Ostatecznie po&#322;&#261;czyli oni sieci neuronowe z drzewem
poszukiwa&#324;, a mianowicie algorytmem MCTS wcze&#347;niej opisanym w rozdziale 4.6.
Zamiast u&#380;ywa&#263; formu&#322;y UCB, wybieraj&#261; oni w&#281;ze&#322; za pomoc&#261; nast&#281;puj&#261;cego
równania:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-36001r1"></a>
<!--l. 11--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                          <msub><mrow 
><mi 
>a</mi></mrow><mrow 
><mi 
>t</mi></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>a</mi><mi 
>r</mi><mi 
>g</mi><mi 
>m</mi><mi 
>a</mi><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>a</mi></mrow></msub 
><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>Q</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-punc">,</mo> <mo 
class="MathClass-bin">+</mo><mi 
>u</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(6.1)</td></tr></table>
<!--l. 15--><p class="noindent" >Gdzie <!--l. 15--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>s</mi></mstyle></mstyle></math> jest
stanem, <!--l. 15--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>a</mi></mstyle></mstyle></math> akcj&#261;, a
<!--l. 15--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>a</mi><mi 
>r</mi><mi 
>g</mi><mi 
>m</mi><mi 
>a</mi><msub><mrow 
><mi 
>x</mi></mrow><mrow 
><mi 
>a</mi></mrow></msub 
></mstyle></mstyle></math> oznacza wybór
<!--l. 15--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>a</mi></mstyle></mstyle></math> z najwi&#281;ksz&#261; warto&#347;ci&#261;
<!--l. 15--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>Q</mi> <mo 
class="MathClass-bin">+</mo> <mi 
>u</mi></mstyle></mstyle></math> które s&#261; opisane
poni&#380;ej. Wyra&#380;enie <!--l. 15--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>Q</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math>
jest zdefiniowane jako:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-36002r2"></a>
<!--l. 17--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                      <mi 
>Q</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mn>1</mn><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>N</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo> <mi 
>&#x03A3;</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>1</mn><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi><mo 
class="MathClass-punc">,</mo><mi 
>i</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo> <mi 
>V</mi> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(6.2)</td></tr></table>
                                                                                    
                                                                                    
<!--l. 21--><p class="noindent" >Gdzie <!--l. 21--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mn>1</mn><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi><mo 
class="MathClass-punc">,</mo><mi 
>i</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> jest
funkcj&#261; charakterystyczn&#261; zbioru, która okre&#347;la czy w&#281;ze&#322; by&#322; odwiedzony podczas <span 
class="aeb10-x-x-120">i-tej </span>symulacji.
<!--l. 21--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>V</mi> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> jest funkcj&#261;
warto&#347;ci, a <!--l. 21--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math>
jest liczb&#261; wizyt w danym w&#281;&#378;le.<br 
class="newline" />
</p><!--l. 23--><p class="noindent" >Drugie wyra&#380;enie w równaniu (6.1) jest zdefiniowane:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-36003r3"></a>
<!--l. 25--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                     <mi 
>u</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mi 
>c</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>P</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo><msqrt><mrow><munderover accentunder="false" accent="false"><mrow  
><mo  
>&#x2211;</mo>
  </mrow><mrow 
></mrow><mrow 
><mi 
>b</mi></mrow></munderover 
><mi 
>N</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>b</mi></mrow><mo 
class="MathClass-close">)</mo></mrow><mo 
class="MathClass-bin">&#x2215;</mo><mi 
>N</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mrow></msqrt>
</math></td><td class="eq-no">(6.3)</td></tr></table>
<!--l. 29--><p class="noindent" >Gdzie <!--l. 29--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>c</mi></mstyle></mstyle></math> jest sta&#322;&#261;
eksploracji, <!--l. 29--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>P</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> jest
wcze&#347;niejszym prawdopodobie&#324;stwem, które otrzymali&#347;my za pomoc&#261; policy u&#380;ytej na w&#281;&#378;le
nadrz&#281;dnym, i <!--l. 29--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>b</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math>
jest liczba wizyt do mo&#380;liwych ruchów z naszego w&#281;z&#322;a, a
<!--l. 29--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> jest
liczb&#261; wizyt w naszym w&#281;&#378;le.<br 
class="newline" />
</p><!--l. 31--><p class="noindent" >Warto&#347;&#263; <!--l. 31--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>V</mi> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math>
z równania (6.2) jest kombinacj&#261; warto&#347;ci wyj&#347;cia z sieci
<!--l. 31--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mi 
>&#x03B8;</mi></mrow></msub 
></mstyle></mstyle></math> oraz warto&#347;ci
rozwini&#281;cia (ang. rollout) <!--l. 31--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>z</mi></mstyle></mstyle></math>
które s&#261; po&#322;&#261;czone w nast&#281;puj&#261;cy sposób:
</p>
   <table class="equation"><tr><td> <a 
 id="x1-36004r4"></a>
                                                                                    
                                                                                    
<!--l. 33--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                             <mi 
>V</mi> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-rel">=</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>1</mn> <mo 
class="MathClass-bin">-</mo> <mi 
>&#x03BB;</mi></mrow><mo 
class="MathClass-close">)</mo></mrow> <mo 
class="MathClass-bin">*</mo> <msub><mrow 
><mi 
>v</mi></mrow><mrow 
><mi 
>&#x03B8;</mi></mrow></msub 
> <mo 
class="MathClass-bin">+</mo> <mi 
>&#x03BB;</mi> <mo 
class="MathClass-bin">*</mo> <mi 
>z</mi>
</math></td><td class="eq-no">(6.4)</td></tr></table>
<!--l. 37--><p class="noindent" >Gdzie <!--l. 37--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>&#x03BB;</mi></mstyle></mstyle></math>
jest parametrem mieszania.<br 
class="newline" />
</p><!--l. 39--><p class="indent" >   W równaniu (6.1) podobnie jak w MCTS
<!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>u</mi></mstyle></mstyle></math>
jest cz&#281;&#347;ci&#261; równania odpowiadaj&#261;c&#261; za eksploracj&#281;, natomiast
<!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>Q</mi></mstyle></mstyle></math>
jest cz&#281;&#347;ci&#261; równania okre&#347;laj&#261;c&#261; warto&#347;&#263; w&#281;z&#322;a.
<!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>Q</mi></mstyle></mstyle></math> jest po prostu
warto&#347;ci&#261; <!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>V</mi> </mstyle></mstyle></math>
znormalizowan&#261; przez ilo&#347;&#263; rozwini&#281;&#263;, tak &#380;eby ich ilo&#347;&#263; nie wp&#322;ywa&#322;a na wynik. Je&#347;li
chodzi o <!--l. 39--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>u</mi></mstyle></mstyle></math>
(6.3) to, zamiast okre&#347;la&#263; nasz brak wiedzy na temat w&#281;z&#322;a tylko przy pomocy ilo&#347;ci
rozwini&#281;&#263;, u&#380;ywana do okre&#347;lenia tej potencjalnej warto&#347;ci jest równie&#380;
warto&#347;&#263; otrzymana z sieci zbioru zasad. To ona szybko, za jednym razem, okre&#347;la
warto&#347;&#263; wszystkich ruchów na planszy. W równaniu (6.4) widzimy, &#380;e zamiast
wykorzystywa&#263; sam&#261; warto&#347;&#263; rozwini&#281;cia, jak to mia&#322;o miejsce w klasycznym MCTS,
wykorzystywana jest równie&#380; informacja na temat pozycji pozyskana z sieci funkcji
warto&#347;ci.<br 
class="newline" />
</p><!--l. 41--><p class="indent" >   Po fazie rozwini&#281;cia wszystkie parametry i niektóre ukryte parametry musz&#261;
by&#263; przes&#322;ane do nadrz&#281;dnych w&#281;z&#322;ów. Nie b&#281;dziemy tu wchodzi&#263; w szczegó&#322;y.
Jedyn&#261; rzecz&#261;, któr&#261; musimy teraz doda&#263;, jest odpowied&#378; na pytanie, kiedy
rozwija&#263; w&#281;ze&#322;. Ekspansja jest wykonywana, kiedy warto&#347;&#263; wizyt w w&#281;zle
<!--l. 41--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>N</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi><mo 
class="MathClass-punc">,</mo><mi 
>a</mi></mrow><mo 
class="MathClass-close">)</mo></mrow></mstyle></mstyle></math> jest wi&#281;ksza ni&#380;
pewna warto&#347;&#263; <!--l. 41--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><msub><mrow 
><mi 
>n</mi></mrow><mrow 
><mi 
>t</mi><mi 
>h</mi><mi 
>r</mi><mi 
>e</mi><mi 
>s</mi><mi 
>h</mi><mi 
>o</mi><mi 
>l</mi><mi 
>d</mi></mrow></msub 
></mstyle></mstyle></math>.
Jako najlepszy w&#281;ze&#322; jest wybierany w&#281;ze&#322; z najwi&#281;ksz&#261; ilo&#347;ci&#261; wizyt. Pokrótce to jest
ca&#322;o&#347;&#263; algorytmu AlphaGo. Zosta&#322; on u&#380;yty w Marcu 2016, &#380;eby pokona&#263; by&#322;ego
mistrza &#347;wiata Lee Sedola w serii pi&#281;ciu meczów. Jedyna gra wygrana przez cz&#322;owieka, gra
czwarta, zosta&#322;a wygrana dzi&#281;ki specjalnej taktyce Sedola, która mia&#322;a na celu
skomplikowanie gry. Podczas tego wysi&#322;ku znalaz&#322; on ruch nazywany &#8222;boskim ruchem&#8221;.
AlphaGo ocenia&#322;a go jako bardzo ma&#322;o prawdopodobny. Prawdopodobnie z powodu tego
b&#322;&#281;du komputer zagra&#322; poni&#380;ej oczekiwa&#324; w kolejnych kilku posuni&#281;ciach, trac&#261;c w
efekcie wiele punktów na rzecz cz&#322;owieka i w konsekwencji przegrywaj&#261;c ca&#322;&#261; gr&#281;.
Pó&#378;niej zespó&#322; AlphaGo znalaz&#322; i poprawi&#322; b&#322;&#261;d, który powodowa&#322; dziwne
                                                                                    
                                                                                    
zachowanie.
<a 
 id="x1-36005r36"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">6.2   </span> <a 
 id="x1-370002"></a>AlphaZero (rok 2017)</h3>
<!--l. 45--><p class="noindent" >W 2017 roku zespó&#322; Deepmind wzi&#261;&#322; si&#281; za rozwi&#261;zywanie szachów i gry Shogi u&#380;ywaj&#261;c
podobnych technik do tych u&#380;ytych w AlphaGo, tym razem jednak miano nie
wykorzystywa&#263; wiedzy ludzi do nauki, a zamiast tego programy mia&#322;y si&#281; nauczy&#263; gra&#263;
od podstaw na ponadludzkim poziomie. Normalne silniki szachowe u&#380;ywaj&#261; techniki
wyszukiwania alfa-beta wraz z bardzo dok&#322;adnie r&#281;cznie dopasowan&#261; funkcj&#261; warto&#347;ci,
ksi&#261;&#380;k&#261; otwar&#263; i ko&#324;cówek oraz korzystaj&#261; z wielu heurystyk, które poprawiaj&#261;
dzia&#322;anie systemu w wielu ma&#322;ych okoliczno&#347;ciach. AlphaZero przynios&#322;a zupe&#322;nie nowy
sposób my&#347;lenia o problemie, pozwalaj&#261;c na stworzenie silnika szachowego Lc0, który jest
w stanie konkurowa&#263; z najlepszym klasycznym silnikiem szachowym, mianowicie
Stockfishem. Leela Zero by&#322;a w stanie osi&#261;gn&#261;&#263; to w bardzo krótkim czasie rozwoju i w
przysz&#322;o&#347;ci b&#281;dzie prawdopodobnie w stanie przekonywaj&#261;co pokona&#263; Stockfisha.
<span 
class="aeb10-x-x-120">AlphaZero </span>korzysta z architektury pod wieloma wzgl&#281;dami podobnej do programu AlphaGo.
U&#380;ywa sieci &#8216;policy&#8217;, sieci warto&#347;ci oraz algorytmu MCTS. Najwi&#281;ksz&#261; ró&#380;nic&#261;
pomi&#281;dzy nimi jest metoda trenowania obu modeli. Kiedy AlphaGo by&#322;o trenowane przy
u&#380;yciu gier pochodz&#261;cych od ludzi, AlphaZero uczy si&#281; tabula rasa, znaj&#261;c na pocz&#261;tku
tylko zasady gry. Wyszukiwanie jest wg autorów zaimplementowane podobnie
jak w AlphaGo. &#379;eby sta&#263; si&#281; lepszym, AlphaZero gra&#322;o przeciwko sobie i by&#322;o
wzmacniane -1 dla przegranej, 0 dla remisu i +1 dla wygranej. Parametry sieci by&#322;y
uczone przy u&#380;yciu MSE + Cross entropy (inny typ funkcji b&#322;&#281;du) + regularyzacja
<!--l. 45--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msup><mrow 
><mi 
>L</mi></mrow><mrow 
><mn>2</mn></mrow></msup 
></math>,
która zosta&#322;a opisana w rozdziale 3.6. Najbardziej interesuj&#261;cym pomys&#322;em jest
to, &#380;e parametry w sieci zbioru zasad s&#261; aktualizowane tak, aby zbli&#380;y&#263; je
do prawdopodobie&#324;stwa po u&#380;yciu wyszukiwania, wi&#281;c w pewnym sensie sie&#263;
zbioru zasad stara si&#281; przewidzie&#263; co stanie si&#281; podczas wyszukiwania. Dzi&#281;ki temu
przy wykorzystaniu, sie&#263; zbioru zasad jest w stanie zredukowa&#263; sprawdzane
przypadki do tylko do tych najbardziej obiecuj&#261;cych. AlphaZero wyszukuje 80 tys.
pozycji na sekund&#281; w porównaniu do 70 milionów, które sprawdza Stockfish.
Jednak mimo tego AlphaZero by&#322;a w stanie pokona&#263; Stockfisha w meczu 1000
gier. Rezultat wyniós&#322; 155 zwyci&#281;stw dla AlphaZero, 6 dla Stockfisha, reszta to
remisy.
<a 
 id="x1-37001r37"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">6.3   </span> <a 
 id="x1-380003"></a>MuZero (rok 2019)</h3>
<!--l. 49--><p class="noindent" >Architektura <span 
class="aeb10-x-x-120">MuZero </span>jest pod pewnymi wzgl&#281;dami podobna do AlphaZero, ale w
niektórych znacz&#261;co si&#281; ró&#380;ni. MuZero u&#380;ywa podobnej wersji MCTS. &#321;&#261;czy te&#380;
                                                                                    
                                                                                    
&#8216;policy&#8217; i funkcj&#281; warto&#347;ci w jedn&#261; sie&#263; z dwoma wyj&#347;ciami.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-38001r5"></a>
<!--l. 51--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                  <mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>6</mn><mo 
class="MathClass-punc">.</mo><mn>3</mn><mo 
class="MathClass-punc">.</mo><mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow><mi 
>p</mi><mo 
class="MathClass-punc">,</mo><mi 
>v</mi> <mo 
class="MathClass-rel">=</mo> <mi 
>f</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>s</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(6.5)</td></tr></table>
<!--l. 55--><p class="noindent" >Gdzie <!--l. 55--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>p</mi></mstyle></mstyle></math> jest
policy, <!--l. 55--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>v</mi></mstyle></mstyle></math> funkcj&#261;
warto&#347;ci, <!--l. 55--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>f</mi></mstyle></mstyle></math> sieci&#261;
neuronow&#261;, a <!--l. 55--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>s</mi></mstyle></mstyle></math>
jej wej&#347;ciem. Najwi&#281;ksz&#261; zmian&#261; s&#261; nowe funkcje dynamiki i reprezentacji. Funkcja
dynamiki jest u&#380;ywana do przewidywania nagrody w nast&#281;pnym kroku. Stan jest ustawiony
na równy funkcji reprezentacji.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-38002r6"></a>
<!--l. 58--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                           <mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>6</mn><mo 
class="MathClass-punc">.</mo><mn>3</mn><mo 
class="MathClass-punc">.</mo><mn>2</mn></mrow><mo 
class="MathClass-close">)</mo></mrow><msub><mrow 
><mi 
>s</mi></mrow><mrow 
><mn>0</mn></mrow></msub 
> <mo 
class="MathClass-rel">=</mo> <mi 
>h</mi><mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>o</mi><mstyle 
class="text"><mtext  >_</mtext></mstyle><mn>1</mn><mo 
class="MathClass-punc">,</mo><mi 
>o</mi><mstyle 
class="text"><mtext  >_</mtext></mstyle><mn>2</mn><mo 
class="MathClass-punc">,</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">.</mo><mo 
class="MathClass-punc">,</mo><mi 
>o</mi><mstyle 
class="text"><mtext  >_</mtext></mstyle><mi 
>t</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(6.6)</td></tr></table>
<!--l. 62--><p class="noindent" >Zamiast u&#380;ywa&#263; danych jako wej&#347;cia, u&#380;ywana jest funkcja reprezentacji
<!--l. 62--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>h</mi></mstyle></mstyle></math> która bierze jako
wej&#347;cie dane wej&#347;ciowe <!--l. 62--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>o</mi><mstyle 
class="text"><mtext  >_</mtext></mstyle><mi 
>t</mi></mstyle></mstyle></math>
z poprzednich <!--l. 62--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>t</mi></mstyle></mstyle></math>
kroków.<br 
class="newline" />
</p><!--l. 64--><p class="indent" >   To jest najbardziej ekscytuj&#261;ca idea w MuZero. Oznacza ona w&#322;a&#347;ciwie, &#380;e mo&#380;emy
wykonywa&#263; wyszukiwanie w sytuacjach, w których by&#322;o to poprzednio niemo&#380;liwe, takich
jak np. gry Atari. W grach Atari nie posiadamy zasad pozwalaj&#261;cych nam na generowanie
nast&#281;pnej pozycji z pozycji obecnej i wybranego ruchu. To jest miejsce, gdzie funkcja
                                                                                    
                                                                                    
reprezentacji jest wykorzystywana. Raczej ni&#380; polega&#263; na zasadach do generowania
przysz&#322;ych pozycji, wykorzystujemy do tego celu funkcj&#281; reprezentacji. To pozwala na
wyszukiwanie w sytuacjach, w których generowanie drzewa poszukiwa&#324; by&#322;o poprzednio
niemo&#380;liwym. &#379;eby doceni&#263; to podej&#347;cie, pomy&#347;lmy o sytuacji, w której gramy np. w
gr&#281; komputerow&#261;. Nie znamy nigdy dok&#322;adnych zasad, na których opiera si&#281; ta gra. Jedyne
co wiemy na pocz&#261;tku to kilka komend kontrolnych, które poda&#322; nam twórca
gry. Reszty musimy si&#281; domy&#347;li&#263;, opieraj&#261;c si&#281; na naszej wiedzy o prawdziwym
&#347;wiecie, a mo&#380;e tak&#380;e o innych grach, które napotkali&#347;my wcze&#347;niej. T&#281;
funkcj&#281; spe&#322;nia funkcja reprezentacji. Maj&#261;c tak&#261; funkcj&#281; reprezentacji, mo&#380;emy
przeprowadza&#263; planowanie za pomoc&#261; drzewa poszukiwa&#324; w sutuacji, w której
poprzednio nie by&#322;o to mo&#380;liwe. Mo&#380;emy np. wyobrazi&#263; sobie, &#380;e je&#347;li strzelimy
do stra&#380;nika, to inni stra&#380;nicy zostan&#261; poinformowani o czyhaj&#261;cym na nich
zagro&#380;eniu. Tak wi&#281;c wybieramy inn&#261; &#347;cie&#380;k&#281; dost&#281;pn&#261; na drzewie poszukiwa&#324;,
które zosta&#322;o wygenerowanie dzi&#281;ki funkcji reprezentacji. To podej&#347;cie osi&#261;gn&#281;&#322;o
nowy rekord w rozwi&#261;zywaniu gier Atari, jak jest to wyja&#347;nione w pracy na temat
MuZero. Jedynym pytaniem pozostaje jak wytrenowa&#263; taki model. Jak mo&#380;emy
przeczyta&#263;, wszystkie parametry funkcji reprezentacji, dynamiki i predykcji s&#261;
trenowane razem. B&#322;&#261;d z wszystkich sieci jest sumowany i dodawana jest regularyzacja
<!--l. 64--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><msup><mrow 
><mi 
>L</mi></mrow><mrow 
><mn>2</mn></mrow></msup 
></math>. MuZero
u&#380;ywa drzewa poszukiwa&#324; MCTS, u&#380;ywaj&#261;c funkcji predykcji, reprezentacji i dynamiki.
Nast&#281;pnie po <!--l. 64--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
= 800 symulacji, ruch jest wybierany. Ta procedura jest wykonywana przez <span 
class="aeb10-x-x-120">K </span>kroków gry.
Nast&#281;pnie, &#380;eby uczenie by&#322;o mo&#380;liwe, najbli&#380;sza ga&#322;&#261;&#378; MCTS jest porównywana do
prawdziwej gry. To porównanie daje nam dane treningowe dla funkcji b&#322;&#281;du. To
porównywanie ga&#322;&#281;zi jest kolejn&#261; ekscytuj&#261;c&#261; ide&#261; w architekturze MuZero. Sprawia to, &#380;e
mo&#380;e si&#281; ono uczy&#263; nie tylko na bezpo&#347;rednio wykonanym ruchu, ale na ca&#322;ej sekwencji
zasymulowanych ruchów. Porównuj&#261;c to, co zosta&#322;o zasymulowane, z tym, co sta&#322;o si&#281;
naprawd&#281;, uzyskujemy b&#322;&#261;d. Ten b&#322;&#261;d z ka&#380;dego z przyk&#322;adów wykorzystujemy do
trenowania sieci. To podej&#347;cie sprawia, &#380;e mo&#380;emy uzyska&#263; du&#380;o wi&#281;cej przyk&#322;adów
testowych. MuZero wydaje si&#281; niezwykle ciekawe, poniewa&#380; zdaje si&#281;, &#380;e mo&#380;e by&#263;
u&#380;yte nie tylko do gier ze znanymi zasadami, ale tak&#380;e do ka&#380;dego innego problemu
uczenia ze wzmocnieniem. MuZero wygl&#261;da jak spojrzenie na to, jak systemy AI b&#281;d&#261;
wygl&#261;da&#263; w przysz&#322;o&#347;ci.
<a 
 id="x1-38003r38"></a>
</p>
<h3 class="sectionHead"><span class="titlemark">6.4   </span> <a 
 id="x1-390004"></a>AGI</h3>
<!--l. 68--><p class="noindent" ><span 
class="aeb10-x-x-120">Generalna sztuczna inteligencja </span>(ang. artificial general intelligence, AGI) jest ide&#261;, któr&#261;
mówi, &#380;e jest mo&#380;liwym stworzy&#263; program, który b&#281;dzie w stanie rozwi&#261;za&#263; dowolny
problem, który mu zaprezentujemy. Cz&#281;&#347;&#263; opisanego post&#281;pu zdaje si&#281; porusza&#263; w
                                                                                    
                                                                                    
stron&#281; wi&#281;kszej ogólno&#347;ci jak na przyk&#322;ad AlphaZero, które mo&#380;na wytrenowa&#263;, aby
gra&#322;o w kilka ró&#380;nych gier. Jest jednak równie&#380; prawd&#261;, &#380;e wielu naukowców ma
du&#380;e w&#261;tpliwo&#347;ci na temat mo&#380;liwo&#347;ci osi&#261;gni&#281;cia AGI w bliskiej przysz&#322;o&#347;ci.
AI posun&#281;&#322;o si&#281; na wielu frontach w czasie ostatnich kilku dekad. Poprawili&#347;my
metody optymalizacji, &#380;eby by&#263; w stanie lepiej odpowiada&#263; na intuicyjne pytania.
Poprawili&#347;my algorytmy wyszukiwania tak, aby mog&#322;y lepiej pracowa&#263; z intuicjami sieci
neuronowych. Zbudowali&#347;my tak&#380;e zaawansowan&#261; formaln&#261; struktur&#281;, dzi&#281;ki
której mo&#380;emy my&#347;le&#263; o problemie uczenia ze wzmocnieniem. Nadal jest jedna
du&#380;a rzecz, która zdaje si&#281; nam ucieka&#263;. Jest ni&#261; j&#281;zyk. Ka&#380;dy cz&#322;owiek na
Ziemi komunikuje si&#281;, u&#380;ywaj&#261;c pewnego rodzaju j&#281;zyka, i mamy trudno&#347;ci z
wyobra&#380;eniem sobie jak wygl&#261;da&#322;oby nasze &#380;ycie bez niego. To jest wed&#322;ug autora
dosy&#263; silny argument za konieczno&#347;ci&#261; j&#281;zyka w naszych systemach. Czym w
ogóle jest <span 
class="aeb10-x-x-120">j&#281;zyk</span>? J&#281;zyk jest zbiorem znaków po&#322;&#261;czonych z pewnymi znaczeniami.
Mo&#380;emy u&#380;ywa&#263; tych znaków, &#380;eby opisywa&#263; sytuacje, przewidywa&#263; kolejno
nast&#281;puj&#261;ce znaki i do generowania odpowiedzi na pytania skonstruowane za pomoc&#261; tych
znaków. Jak jednak wcze&#347;niej widzieli&#347;my, idee o wielkiej mocy musz&#261; by&#263;
dodane do pot&#281;&#380;nych struktur, &#380;eby by&#322;y szeroko aplikowalne. Zobaczmy, jak te
symboliczne pomys&#322;y mog&#322;yby by&#263; u&#380;yte w po&#322;&#261;czeniu z sieciami neuronowymi, &#380;eby
da&#263; najlepsze rezultaty: Czy pami&#281;tasz, jak silnik szachowy wyszukiwa&#322; miliony
przyk&#322;adów na sekund&#281;, ale rozwi&#261;zania oparte o sieci neuronowe wykonywa&#322;y du&#380;o
mniej takich wyszukiwa&#324;, osi&#261;gaj&#261;c mimo tego dobre rezultaty ze wzgl&#281;du na
u&#380;ycie sieci neuronowych do oceny sytuacji? Mo&#380;emy my&#347;le&#263; o drzewach
poszukiwa&#324; jako, w pewnym sensie, bardzo podobnych do j&#281;zyka. Ostatecznie
przecie&#380; w wielu modelach j&#281;zyka zdanie mo&#380;e by&#263; zapisane jako swego rodzaju
drzewo. Je&#347;li we&#378;miemy ten pomys&#322; krok dalej, to mo&#380;emy stwierdzi&#263;, &#380;e te
pomys&#322;y s&#261; dok&#322;adnie takie same. To znaczy&#322;oby, &#380;e ludzie wykonuj&#261; nawet mniej
wyszukiwania w porównaniu do MuZero, jednocze&#347;nie przewy&#380;szaj&#261;c je w wi&#281;kszo&#347;ci
dziedzin. Znaczy&#322;oby to tak&#380;e &#380;e j&#281;zyk jest rodzajem algorytmu poszukiwa&#324;
kieruj&#261;cym nas w wyborze nast&#281;pnego w&#281;z&#322;a do rozwini&#281;cia. Jednak j&#281;zyk ma pewne
w&#322;a&#347;ciwo&#347;ci, których naszym systemom nadal brakuje. Jak mo&#380;emy opisa&#263; j&#281;zyk jako
algorytm, tak jak robili&#347;my to wcze&#347;niej dla ró&#380;nych metod? Na pocz&#261;tku
stwierdziliby&#347;my autorytatywnie, &#380;e s&#322;owa mog&#261; by&#263; reprezentowane jako pewne punkty
w <!--l. 68--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
wymiarowej przestrzeni. To mo&#380;e si&#281; nie wydawa&#263; intuicyjne, poniewa&#380; s&#322;owa wydaj&#261; si&#281;
dyskretnymi bytami, ale mo&#380;e to wynika&#263; z u&#380;ywania tylko pewnych cz&#281;&#347;ci dost&#281;pnej
przestrzeni. Nast&#281;pn&#261; rzecz&#261;, któr&#261; by&#347;my wprowadzili, jest to, &#380;e ka&#380;dy
w&#281;ze&#322; powinien posiada&#263; koresponduj&#261;ce do niego jedno s&#322;owo, które go opisuje.
Oczywi&#347;cie mo&#380;emy da&#263; list&#281; s&#322;ów albo opis sytuacji za pomoc&#261; ca&#322;ego zdania, albo
paragrafu, ale mo&#380;e wyra&#380;a to tylko pierwsze s&#322;owo z wi&#281;ksz&#261; dok&#322;adno&#347;ci&#261;.
S&#322;owa s&#261; te&#380; po&#322;&#261;czone ze sob&#261;. Wszystkie takie relacje mog&#322;yby teoretycznie by&#263;
                                                                                    
                                                                                    
wyt&#322;umaczone jako podrz&#281;dno&#347;&#263;, nadrz&#281;dno&#347;&#263;, równowa&#380;no&#347;&#263; w&#281;z&#322;ów. Tak
wi&#281;c s&#322;owo by&#322;oby okre&#347;lone jako lista zawieraj&#261;ca dwie warto&#347;ci: znaczenie
<!--l. 68--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>m</mi></mstyle></mstyle></math> i jego
relacj&#281; <!--l. 68--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>r</mi></mstyle></mstyle></math>
do jakiego&#347; innego s&#322;owa.
</p>
   <table class="equation"><tr><td> <a 
 id="x1-39001r7"></a>
<!--l. 70--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="block" class="equation">
                                  <mrow ><mo 
class="MathClass-open">(</mo><mrow><mn>6</mn><mo 
class="MathClass-punc">.</mo><mn>4</mn><mo 
class="MathClass-punc">.</mo><mn>1</mn></mrow><mo 
class="MathClass-close">)</mo></mrow><mi 
>w</mi> <mo 
class="MathClass-rel">=</mo> <mrow ><mo 
class="MathClass-open">(</mo><mrow><mi 
>m</mi><mo 
class="MathClass-punc">,</mo><mi 
>r</mi></mrow><mo 
class="MathClass-close">)</mo></mrow>
</math></td><td class="eq-no">(6.7)</td></tr></table>
<!--l. 74--><p class="indent" >   Jak wi&#281;c ta reprezentacja by&#322;aby u&#380;ywana? Wyró&#380;niliby&#347;my cztery g&#322;ówne
sieci. Sie&#263; funkcji warto&#347;ci, która korzystaj&#261;c z wewn&#281;trznej reprezentacji &#8216;X&#8217;,
zwraca&#322;aby spodziewan&#261; warto&#347;&#263; sytuacji opisanej przez wewn&#281;trzn&#261; reprezentacj&#281;.
Ta sie&#263; dzia&#322;a&#322;aby tak jak ka&#380;da poprzednio opisana sie&#263; warto&#347;ci, tylko
wykorzystywa&#322;aby wewn&#281;trzn&#261; reprezentacj&#281; jako wej&#347;cie. Nast&#281;pnie sie&#263; &#8216;P&#8217;
która bra&#322;aby wewn&#281;trzn&#261; reprezentacj&#281; i zwraca&#322;a nast&#281;pne s&#322;owo, które
najlepiej opisuje dan&#261; sytuacj&#281;. Ta sie&#263; by&#322;aby sieci&#261; tworz&#261;c&#261; kolejne s&#322;owa.
Wykorzystywa&#322;aby reprezentacj&#281; wewn&#281;trzn&#261; do okre&#347;lania jakie s&#322;owo powinno
nast&#261;pi&#263; na nast&#281;pnym miejscu. S&#322;owo sk&#322;ada si&#281; ze znaczenia, które jest punktem w
<!--l. 74--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>n</mi></mstyle></mstyle></math>
wymiarowej przestrzeni oraz z relacji, która okre&#347;la miejsce na grafie, które powinno
by&#263; wyszukiwane w nast&#281;pnej kolejno&#347;ci. Tak wi&#281;c sie&#263;&#x00A0;ta wybiera&#322;aby najpierw punkt w
<span 
class="aeb10-x-x-120">n</span>-dim a nast&#281;pnie inne, wcze&#347;niej istniej&#261;ce s&#322;owo, dla którego nowe s&#322;owo b&#281;dzie w relacji
podrz&#281;dnej. Trzecia sie&#263; &#8216;R&#8217; podobna do funkcji reprezentacji z MuZero bra&#322;aby jako
wej&#347;cie list&#281; wszystkich s&#322;ów wypowiedzianych przez &#8216;P&#8217; oraz odpowiadaj&#261;ce im warto&#347;ci
okre&#347;lone przez sie&#263; funkcji warto&#347;ci i zwraca&#322;aby wewn&#281;trzn&#261; reprezentacj&#281;. Te trzy sieci
by&#322;yby trenowane &#322;&#261;cznie. Dodatkowym wej&#347;ciem do sieci funkcji warto&#347;ci by&#322;oby
znaczenie najnowszego wypowiedzianego s&#322;owa, czyli punkt w <span 
class="aeb10-x-x-120">n</span>-dim. To sprawia&#322;oby, &#380;e
funkcja warto&#347;ci wiedzia&#322;aby, z jakiego rodzaju problemem ma do czynienia. Czwart&#261;
ostatni&#261; sieci&#261; by&#322;aby sie&#263; zbioru zasad. Poniewa&#380; wskazywanie kolejnych relacji
<!--l. 74--><math 
 xmlns="http://www.w3.org/1998/Math/MathML"  
display="inline" ><mstyle mathvariant="bold-italic"><mstyle mathvariant="bold"><mi 
>r</mi></mstyle></mstyle></math>
odbywa&#322;oby si&#281; na zasadzie wskazania w&#281;z&#322;a nadrz&#281;dnego, od którego chcemy
przeprowadzi&#263; rozwini&#281;cie (co by&#322;oby osi&#261;gni&#281;te jako dystrybucja prawdopodobie&#324;stwa nad
s&#322;owami), to musieliby&#347;my wybra&#263; spo&#347;ród kilku w&#281;z&#322;ów podrz&#281;dnych do rozwini&#281;cia.
                                                                                    
                                                                                    
W tym zadaniu pomaga&#322;aby w&#322;a&#347;nie sie&#263; zbioru zasad. Mog&#322;aby by&#263; ona trenowana
&#322;&#261;cznie z innymi sieciami lub te&#380; osobno. U&#380;ycie wszystkich tych sieci, je&#347;li wszystko
zadzia&#322;a&#322;oby zgodnie z zamierzeniem, doprowadzi&#322;oby do stworzenia swego rodzaju j&#281;zyka,
którym nauczy&#322;by si&#281; operowa&#263; nasz system.<br 
class="newline" />
</p><!--l. 76--><p class="indent" >   To, co zosta&#322;o opisane w tym rozdziale (6.4), jest czym&#347; przypominaj&#261;cym
Science-Fiction. S&#261; w nim oczywi&#347;cie pewne naukowe pomys&#322;y, ale wzi&#281;te w przysz&#322;o&#347;&#263;,
po to, aby stworzy&#263; przekonywaj&#261;c&#261; histori&#281;. Autorzy nie znaj&#261; &#380;adnej implementacji
pomys&#322;ów zawartych w tym rozdziale i obecnie pozostaj&#261; one tylko spekulacj&#261;.
</p><!--l. 78--><p class="indent" >
                                                                                    
                                                                                    
</p><!--l. 79--><p class="noindent" ><span 
class="aeb10-x-x-120">Podzi&#281;kowania </span><br 
class="newline" />Na ko&#324;cu chcia&#322;bym podzi&#281;kowa&#263; osobom bez których ta ksi&#261;&#380;ka nie wygl&#261;da&#322;aby tak
jak to co mo&#380;ecie czyta&#263;. Po pierwsze dzi&#281;kuj&#281; panu Micha&#322;owi Dyzmie za przygotowanie
pliku LaTeX, dzi&#281;ki czemu powsta&#322;a ca&#322;a cz&#281;&#347;&#263; techniczna, a wi&#281;c odpowiednie
formatowanie i wygl&#261;d tekstu. Dzi&#281;kuj&#281;&#x00A0;mu te&#380; za rady, które pomog&#322;y mi w stworzeniu
tej ksi&#261;&#380;ki. Nast&#281;pnie chcia&#322;bym równie&#380; podzi&#281;kowa&#263;&#x00A0;pani Ninie Szul za wykonanie
ilustracji oraz ok&#322;adki. Mam nadziej&#281; &#380;e dzi&#281;ki nim ksi&#261;&#380;ka jest ja&#347;niejsza oraz
&#322;adniejsza.
                                                                                    
                                                                                    
</p>
    
</body> 
</html>
                                                                                    
                                                                                    
                                                                                    
                                                                                    
                                                                                    


